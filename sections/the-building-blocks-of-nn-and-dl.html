<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>6&nbsp; The Building Blocks of Neural Networks and Deep Learning – Cyber2A: AI for Arctic Research</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../sections/intro-to-pytorch.html" rel="next">
<link href="../sections/hands-on-lab-data-annotation.html" rel="prev">
<link href="../images/index/arcticlogo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-d4d76bf8491c20bad77d141916dc28e1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-292c0866b2e53f8190c286d1fd533ef9.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../sections/the-building-blocks-of-nn-and-dl.html"><b>Day 2: AI Fundamentals and Techniques</b></a></li><li class="breadcrumb-item"><a href="../sections/the-building-blocks-of-nn-and-dl.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The Building Blocks of Neural Networks and Deep Learning</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Cyber2A: AI for Arctic Research</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/cyber2a/cyber2a-course/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Overview</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 1: Introduction to AI and Arctic Science</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/breaking-the-ice-with-ai-in-arctic-science.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Breaking the Ice with AI in Arctic Science</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-for-everyone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI for Everyone</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-ready-data-in-arctic-research.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">AI-Ready Data in Arctic Research</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/data-annotation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Data Annotation: The Foundation of Deep Learning Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-data-annotation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Hands-On Lab: Data Annotation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 2: AI Fundamentals and Techniques</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/the-building-blocks-of-nn-and-dl.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The Building Blocks of Neural Networks and Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/intro-to-pytorch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to PyTorch: Core Functionalities and Advantages</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-pytorch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Hands-On Lab: PyTorch</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/permafrost-discovery-gateway.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Permafrost Discovery Gateway</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-ethics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">AI Ethics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 3: Advanced AI Workflows and Models</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/guest-lecture-yili-arts-dataset.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Guest Lecture - Unveiling the ARTS Dataset for a Thawing Frontier</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/exploring-advanced-neural-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Exploring Advanced Neural Networks: Instance Segmentation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/intro-to-dl-libraries-for-image-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Introduction to Deep Learning Libraries for Image Analysis</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 4: Workflows and Foundation Models</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-workflows-and-mlops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">AI Workflows and MLOps: From Development to Deployment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-ai-workflows.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Hands-On Lab: AI Workflows</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/foundation-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Foundation Models: The Cornerstones of Modern AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-foundation-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Hands-On Lab: Foundation Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/reproducibility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Reproducibility</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 5: AI Frontiers</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/the-fun-and-frontiers-of-ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">The Fun and Frontiers of AI: Innovation, Imagination, Interaction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"><span class="header-section-number">6.1</span> Introduction</a>
  <ul class="collapse">
  <li><a href="#what-does-this-tool-deep-learning-do" id="toc-what-does-this-tool-deep-learning-do" class="nav-link" data-scroll-target="#what-does-this-tool-deep-learning-do"><span class="header-section-number">6.1.1</span> What does this tool (deep learning) do?</a></li>
  <li><a href="#key-questions-and-building-blocks-of-deep-learning" id="toc-key-questions-and-building-blocks-of-deep-learning" class="nav-link" data-scroll-target="#key-questions-and-building-blocks-of-deep-learning"><span class="header-section-number">6.1.2</span> Key questions and building blocks of deep learning</a></li>
  </ul></li>
  <li><a href="#data" id="toc-data" class="nav-link" data-scroll-target="#data"><span class="header-section-number">6.2</span> Data</a>
  <ul class="collapse">
  <li><a href="#inputs" id="toc-inputs" class="nav-link" data-scroll-target="#inputs"><span class="header-section-number">6.2.1</span> Inputs</a></li>
  <li><a href="#outputs" id="toc-outputs" class="nav-link" data-scroll-target="#outputs"><span class="header-section-number">6.2.2</span> Outputs</a></li>
  <li><a href="#quantity-and-quality" id="toc-quantity-and-quality" class="nav-link" data-scroll-target="#quantity-and-quality"><span class="header-section-number">6.2.3</span> Quantity and quality</a></li>
  </ul></li>
  <li><a href="#models" id="toc-models" class="nav-link" data-scroll-target="#models"><span class="header-section-number">6.3</span> Models</a>
  <ul class="collapse">
  <li><a href="#layers" id="toc-layers" class="nav-link" data-scroll-target="#layers"><span class="header-section-number">6.3.1</span> Layers</a></li>
  <li><a href="#models-1" id="toc-models-1" class="nav-link" data-scroll-target="#models-1"><span class="header-section-number">6.3.2</span> Models</a></li>
  <li><a href="#pre-trained-models-and-transfer-learning" id="toc-pre-trained-models-and-transfer-learning" class="nav-link" data-scroll-target="#pre-trained-models-and-transfer-learning"><span class="header-section-number">6.3.3</span> Pre-trained models and transfer learning</a></li>
  <li><a href="#model-customization" id="toc-model-customization" class="nav-link" data-scroll-target="#model-customization"><span class="header-section-number">6.3.4</span> Model customization</a></li>
  </ul></li>
  <li><a href="#loss-functions" id="toc-loss-functions" class="nav-link" data-scroll-target="#loss-functions"><span class="header-section-number">6.4</span> Loss functions</a>
  <ul class="collapse">
  <li><a href="#types-of-loss-functions" id="toc-types-of-loss-functions" class="nav-link" data-scroll-target="#types-of-loss-functions"><span class="header-section-number">6.4.1</span> Types of Loss Functions</a></li>
  <li><a href="#training-and-validation-loss" id="toc-training-and-validation-loss" class="nav-link" data-scroll-target="#training-and-validation-loss"><span class="header-section-number">6.4.2</span> Training and validation loss</a></li>
  </ul></li>
  <li><a href="#optimization-algorithms" id="toc-optimization-algorithms" class="nav-link" data-scroll-target="#optimization-algorithms"><span class="header-section-number">6.5</span> Optimization Algorithms</a>
  <ul class="collapse">
  <li><a href="#introduction-to-gradient-descent" id="toc-introduction-to-gradient-descent" class="nav-link" data-scroll-target="#introduction-to-gradient-descent"><span class="header-section-number">6.5.1</span> Introduction to gradient descent</a></li>
  <li><a href="#variants-of-gradient-descent" id="toc-variants-of-gradient-descent" class="nav-link" data-scroll-target="#variants-of-gradient-descent"><span class="header-section-number">6.5.2</span> Variants of gradient descent</a></li>
  <li><a href="#key-hyperparameters" id="toc-key-hyperparameters" class="nav-link" data-scroll-target="#key-hyperparameters"><span class="header-section-number">6.5.3</span> Key Hyperparameters</a></li>
  <li><a href="#learning-rate-scheduling" id="toc-learning-rate-scheduling" class="nav-link" data-scroll-target="#learning-rate-scheduling"><span class="header-section-number">6.5.4</span> Learning rate scheduling</a></li>
  <li><a href="#adaptive-learning-rates" id="toc-adaptive-learning-rates" class="nav-link" data-scroll-target="#adaptive-learning-rates"><span class="header-section-number">6.5.5</span> Adaptive learning rates</a></li>
  </ul></li>
  <li><a href="#training-and-inference" id="toc-training-and-inference" class="nav-link" data-scroll-target="#training-and-inference"><span class="header-section-number">6.6</span> Training and Inference</a>
  <ul class="collapse">
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training"><span class="header-section-number">6.6.1</span> Training</a></li>
  <li><a href="#inference" id="toc-inference" class="nav-link" data-scroll-target="#inference"><span class="header-section-number">6.6.2</span> Inference</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../sections/the-building-blocks-of-nn-and-dl.html"><b>Day 2: AI Fundamentals and Techniques</b></a></li><li class="breadcrumb-item"><a href="../sections/the-building-blocks-of-nn-and-dl.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The Building Blocks of Neural Networks and Deep Learning</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The Building Blocks of Neural Networks and Deep Learning</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>Welcome to your first step into deep learning! This lession will help you understand deep learning in a simple and friendly way. Think of it as your first journey into an exciting new world of artificial intelligence.</p>
<p>In this session, we’ll explore:</p>
<ul>
<li><strong>Data</strong> and <strong>models</strong>: Learn why data is super important and how models work like smart brains to make sense of information.</li>
<li><strong>Loss functions</strong> and <strong>optimization algorithms</strong>: Discover how computers learn by understanding the mistakes. We’ll explore how loss functions and optimization algorithms help computers get better and smarter.</li>
</ul>
<p>By the end of this lesson, you’ll understand these key ideas. These building blocks will help you see how artificial intelligence works and how you can use these cool skills in real-life situations.</p>
</section>
<section id="introduction" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">6.1</span> Introduction</h2>
<p>Think of <strong>deep learning</strong> as a tool to help us achieve goals and solve problems, similar to how you drive a car to get to your destination. Just as you start driving by learning only the basics (without diving into all the complex mechanics), your journey into deep learning begins with understanding its essential components.</p>
<div style="display: flex; justify-content: center; align-items: center; width: 100%;">
    <div class="tenor-gif-embed" data-postid="1471332848232877888" data-share-method="host" data-aspect-ratio="1" data-width="50%">
        <a href="https://tenor.com/view/balance-wheelie-viralhog-cadillac-lightning-mcqueen-drag-racing-gif-1471332848232877888">Balance Wheelie Viralhog GIF</a>
        from <a href="https://tenor.com/search/balance+wheelie-gifs">Balance Wheelie GIFs</a>
    </div>
</div>
<script type="text/javascript" async="" src="https://tenor.com/embed.js"></script>
<section id="what-does-this-tool-deep-learning-do" class="level3" data-number="6.1.1">
<h3 data-number="6.1.1" class="anchored" data-anchor-id="what-does-this-tool-deep-learning-do"><span class="header-section-number">6.1.1</span> What does this tool (deep learning) do?</h3>
<blockquote class="blockquote">
<p><em>Finding a function automatically that maps given inputs to desired outputs</em> <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
</blockquote>
<p>In everyday terms, deep learning helps computers learn patterns from data to make predictions or decisions without being explicitly programmed with rules. It’s like teaching a child to recognize dogs by showing many dog pictures rather than listing all the details that define a dog.</p>
<p>For example:</p>
<table class="table-striped caption-top table">
<thead>
<tr class="header">
<th>Inputs</th>
<th>Outputs</th>
<th>Functions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>A sentence or prompt</td>
<td>Text completion</td>
<td>LLM (e.g., ChatGPT <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>)</td>
</tr>
<tr class="even">
<td>A caption/description</td>
<td>An image</td>
<td>DALL-E <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></td>
</tr>
<tr class="odd">
<td>Historical weather data</td>
<td>Weather forecasting</td>
<td>GraphCast <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>Think about a real problem you want to solve with deep learning. What information would you put into the system? What would you want to get out of it?</p>
</div>
</div>
</section>
<section id="key-questions-and-building-blocks-of-deep-learning" class="level3" data-number="6.1.2">
<h3 data-number="6.1.2" class="anchored" data-anchor-id="key-questions-and-building-blocks-of-deep-learning"><span class="header-section-number">6.1.2</span> Key questions and building blocks of deep learning</h3>
<p>To find the right function using deep learning, we can break down the process into four key questions and building blocks:</p>
<ol type="1">
<li><strong>What are the inputs and outputs?</strong> This relates to the <strong>data</strong> we use.</li>
<li><strong>What functions can we possibly use?</strong> This relates to the <strong>models</strong> that define how inputs connect to outputs.</li>
<li><strong>How do we evaluate the function?</strong> This is where <strong>loss functions</strong> help us.</li>
<li><strong>How do we find the best possible function?</strong> This is done through <strong>optimization algorithms</strong>.</li>
</ol>
<p>These questions and building blocks create the core of deep learning. Two more important parts — <strong>training</strong> and <strong>inference</strong> — help connect these building blocks and make the models work in real situations.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/dl-pytorch/dl-blocks.png" class="img-fluid figure-img"></p>
<figcaption>Deep learning building blocks</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Remember, the building blocks of deep learning are closely connected. They affect each other, and there are always trade-offs to consider.</p>
</div>
</div>
<p><strong>Let’s begin our exploration into the building blocks of deep learning.</strong></p>
</section>
</section>
<section id="data" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="data"><span class="header-section-number">6.2</span> Data</h2>
<p><em>Data is the start point of deep learning, forming the <strong>inputs</strong> and <strong>outputs</strong> that define the function we want to learn.</em></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Please see the <a href="../sections/ai-ready-data-in-arctic-research.html">AI-ready Data</a> section for discussions on data for Arctic research.</p>
</div>
</div>
<section id="inputs" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="inputs"><span class="header-section-number">6.2.1</span> Inputs</h3>
<p>Building a deep learning application starts with defining and preparing the data. Data is the foundation that helps models discover patterns and make predictions. Before you begin, think about these key questions:</p>
<ul>
<li>What type of data are you working with? (images, text, audio, etc.)</li>
<li>How much data do you have? Is it representative of real-world situations?</li>
<li>Are there any special requirements for your task? (granularity, temporal consistency, spatial coverage, etc.)</li>
<li>Is the data clean and usable? (missing values, unusual data points, background noise)</li>
</ul>
<p><strong>Here are some key steps for preparing input data:</strong></p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Data collection
</div>
</div>
<div class="callout-body-container callout-body">
<p><em>Find and gather data from reliable sources.</em></p>
<ul>
<li>Use public datasets or domain-specific repositories to save time and effort <a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> <a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>.</li>
<li>Include diverse data to cover different scenarios <a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>.</li>
<li>Check data quality by looking for problems like inconsistencies, duplicates, or noise <a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Data preparation
</div>
</div>
<div class="callout-body-container callout-body">
<p><em>Clean and prepare data for training the model.</em></p>
<ul>
<li>Handle missing or unusual data points by filling in values or removing them<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> <a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> <a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> <a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>.</li>
<li>Standardize or normalize data to bring different features to a similar scale. This helps model learn faster <a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Splitting data
</div>
</div>
<div class="callout-body-container callout-body">
<p><em>Divide data into training, validation, and testing sets.</em></p>
<ul>
<li>Ensure each set represents real-world data distribution, avoiding data leakage <a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>.</li>
<li>Consider the types of data you’re working with <a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>:
<ul>
<li><strong>Imbalanced data</strong>: Use stratified sampling to keep the right mix of different classes <a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a> <a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a>.</li>
<li><strong>Temporal data</strong>: Split based on time.</li>
<li><strong>Spatial data</strong>: Split based on geographic areas <a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a> <a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a>.</li>
</ul></li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Data augmentation
</div>
</div>
<div class="callout-body-container callout-body">
<p><em>Apply transformations to the training data to increase the size and variety of your data.</em></p>
<ul>
<li>Use changes that make sense for your data type (e.g., rotate images, but don’t do this with text) <a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a> <a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a>.</li>
<li>Be careful not to create unrealistic data <a href="#fn22" class="footnote-ref" id="fnref22" role="doc-noteref"><sup>22</sup></a>.</li>
<li>Look for special techniques for specific areas like medical imaging or satellite pictures <a href="#fn23" class="footnote-ref" id="fnref23" role="doc-noteref"><sup>23</sup></a>.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>How well do you understand your data? Think about how it’s collected and its quality.</p>
<p>Even famous datasets like ImageNet can have issues <a href="#fn24" class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a>.</p>
</div>
</div>
</section>
<section id="outputs" class="level3" data-number="6.2.2">
<h3 data-number="6.2.2" class="anchored" data-anchor-id="outputs"><span class="header-section-number">6.2.2</span> Outputs</h3>
<p>Defining outputs is just as important as preparing inputs. Outputs show how the model makes predictions and must match your project’s goals. Consider:</p>
<ul>
<li>What type of output do you need? (labels, numbers, detailed results)</li>
<li>How should the outputs look? (probability list, single number, detailed information)</li>
<li>Are there any special requirements for the outputs, e.g., a specific range?</li>
</ul>
<p><strong>Here are some key steps for preparing output data:</strong></p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Identify output type
</div>
</div>
<div class="callout-body-container callout-body">
<p><em>Choose the right type of output based on your specific problem.</em></p>
<ul>
<li>Use classification for tasks like sorting images or checking sentiment.</li>
<li>Use regression to predict exact numbers, like sea ice concentration.</li>
<li>Use structured outputs for complex tasks, like finding objects in an image <a href="#fn25" class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a>.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Format outputs
</div>
</div>
<div class="callout-body-container callout-body">
<p><em>Choose a format that works with your model and loss functions.</em></p>
<ul>
<li>Use one-hot encoding for category-based tasks.</li>
<li>Normalize continuous outputs to match the scale of the model’s inputs.</li>
<li>Consider using embeddings for structured outputs to capture relationships between categories.</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Data labeling
</div>
</div>
<div class="callout-body-container callout-body">
<p><em>Add labels to your data to provide a reference for training.</em></p>
<p>See the <a href="../sections/data-annotation.html">Data annotation</a> section for more details.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Balance the detail of your outputs with the model’s complexity, available data, and computational resources. For example, predict sea ice concentration precisely (0-100%) or use broader categories like low (&lt;15%) and high (&gt;85%).</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>In a classification problem, what’s the difference between one-hot encoding and label encoding?</p>
</div>
</div>
</section>
<section id="quantity-and-quality" class="level3" data-number="6.2.3">
<h3 data-number="6.2.3" class="anchored" data-anchor-id="quantity-and-quality"><span class="header-section-number">6.2.3</span> Quantity and quality</h3>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quantity: <em>Does more data always mean better results?</em>
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/dl-pytorch/dl-data-quantity.png" class="img-fluid figure-img"></p>
<figcaption>Hoﬀmann et al., (2022)</figcaption>
</figure>
</div>
<p>Large datasets often improve performance, but they don’t guarantee success. Research shows that creating compute-optimal models means balancing data size, model complexity, and computational power <a href="#fn26" class="footnote-ref" id="fnref26" role="doc-noteref"><sup>26</sup></a>.</p>
<blockquote class="blockquote">
<p>For various model sizes, we choose the number of training tokens such that the final FLOPs is a constant. The cosine cycle length is set to match the target FLOP count. We find a clear valley in loss, meaning that for a given FLOP budget there is an optimal model to train</p>
</blockquote>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quality: <em>What makes data high-quality?</em>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Quality is often more important than quantity. Common issues include:</p>
<ul>
<li>Incorrect or inconsistent labels</li>
<li>Noise and irrelevant information</li>
<li>Poorly filtered datasets</li>
</ul>
<p>Research highlights the importance of data quality:</p>
<ul>
<li>Rae et al.&nbsp;(2021) <a href="#fn27" class="footnote-ref" id="fnref27" role="doc-noteref"><sup>27</sup></a>.</li>
</ul>
<blockquote class="blockquote">
<p>Our data pipeline (Section A.1.1) includes text quality filtering, removal of repetitious text, deduplication of similar documents, and removal of documents with significant test-set overlap. We find that successive stages of this pipeline improve language model downstream performance (Section A.3.2), emphasising the importance of dataset quality.</p>
</blockquote>
<ul>
<li>Hoffmann et al., (2022) <a href="#fn28" class="footnote-ref" id="fnref28" role="doc-noteref"><sup>28</sup></a>.</li>
</ul>
<blockquote class="blockquote">
<p>Nonetheless, large language models face several challenges, including their overwhelming computational requirements (the cost of training and inference increase with model size) (Rae et al., 2021; Thoppilan et al., 2022) and the need for acquiring more high-quality training data. In fact, in this work we find that larger, high quality datasets will play a key role in any further scaling of language models.</p>
</blockquote>
</div>
</div>
</section>
</section>
<section id="models" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="models"><span class="header-section-number">6.3</span> Models</h2>
<p><em>Models are the foundation of deep learning. They work as <strong>function sets</strong> that transform inputs into outputs.</em></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The exact function is created by first choosing a model architecture and then getting a specific set of parameters by training the model on data.</p>
</div>
</div>
<section id="layers" class="level3" data-number="6.3.1">
<h3 data-number="6.3.1" class="anchored" data-anchor-id="layers"><span class="header-section-number">6.3.1</span> Layers</h3>
<p>Deep learning models are built from layers. A layer works like a step that processes data and sends it to the next layer. Different layer types have different jobs. Here are some examples:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>To get started, don’t get overwhelmed by all the different layer types. Just get a sense of their basic purposes and focus on using complete models for practical tasks. You can always learn more about individual layers later.</p>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Fully-connected (dense) layer
</div>
</div>
<div class="callout-body-container callout-body">
<p><em>A fully-connected layer connects every input to every output through learnable weights, allowing the network to combine features and make predictions.</em></p>
<p><strong>How it works:</strong></p>
<ol type="1">
<li>Each input connects to every output.</li>
<li>Each connection has a weight (a number that can be adjusted).</li>
<li>For each output:
<ul>
<li>The layer multiplies each input by its connection weight.</li>
<li>It adds all these multiplied values together.</li>
</ul></li>
</ol>
<p>Think of it like a voting system: each input “votes” for different outputs with different strengths (weights).</p>
<ul>
<li><strong>Uses</strong>:
<ul>
<li>Adjust the size of your data (dimensionality).</li>
<li>Combine features to make decisions, e.g., identifying classes or predicting values <a href="#fn29" class="footnote-ref" id="fnref29" role="doc-noteref"><sup>29</sup></a>.</li>
</ul></li>
<li><strong>Advantages</strong>:
<ul>
<li>They learn patterns across all features.</li>
<li>They are simple to add to your network.</li>
</ul></li>
<li><strong>Challenges</strong>:
<ul>
<li>They need lots of computing power and memory due to the dense connections.</li>
<li>They don’t understand spatial relationships well (unlike layers designed for images or sequences).</li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interactive visualization of a fully-connected layer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="fully-connected-layer"></div>
<script type="module" src="../_resources/js/vis-fully-connected-layer.js"></script>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Convolutional layer
</div>
</div>
<div class="callout-body-container callout-body">
<p><em>A convolutional layer applies filters to input data to detect patterns like edges, textures, and shapes, making it ideal for processing images and other spatial data <a href="#fn30" class="footnote-ref" id="fnref30" role="doc-noteref"><sup>30</sup></a>.</em></p>
<p><strong>How it works:</strong></p>
<ol type="1">
<li>Small filters (also called <strong>kernels</strong>) slide across the input data.</li>
<li>Each filter looks at a small area at a time.</li>
<li>For each position:
<ul>
<li>The layer multiplies each input value by the corresponding filter value.</li>
<li>It adds all these multiplied values together.</li>
</ul></li>
<li><strong>Stride</strong> controls how many positions the kernel moves each step.</li>
<li><strong>Padding</strong> adds zeros around the input to control output dimensions.</li>
<li><strong>Output size</strong> = (Input size + 2 × Padding - Kernel size) / Stride + 1</li>
</ol>
<p>Think of it like a spotlight that moves across an image, highlighting specific patterns whenever they appear.</p>
<ul>
<li><strong>Uses</strong>:
<ul>
<li>Extract features from spatial data (like images).</li>
<li>Detect patterns regardless of where they appear in the input.</li>
<li>Reduce the data size while keeping important information.</li>
</ul></li>
<li><strong>Advantages</strong>:
<ul>
<li>They need fewer parameters than fully-connected layers.</li>
<li>They preserve spatial relationships in the data.</li>
<li>They can find the same pattern anywhere in the input.</li>
</ul></li>
<li><strong>Challenges</strong>:
<ul>
<li>They may miss global patterns that span the entire input.</li>
<li>Setting the right filter size and number requires careful design.</li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interactive visualization of a convolutional layer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="convolutional-layer"></div>
<script type="module" src="../_resources/js/vis-convolutional-layer.js"></script>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Pooling layer
</div>
</div>
<div class="callout-body-container callout-body">
<p><em>A pooling layer reduces the size of data by keeping only the most important information, making processing faster and helping the network focus on key features.</em></p>
<p><strong>How it works:</strong></p>
<ol type="1">
<li>The layer divides input data into small regions.</li>
<li>For each region, it keeps only one value (e.g., the maximum or average value).</li>
<li>The creates a smaller output with fewer details.</li>
</ol>
<p>Think of it like summarizing a detailed picture by keeping only the brightest point in each region.</p>
<ul>
<li><strong>Uses</strong>:
<ul>
<li>Reduce data size to save memory and computation.</li>
<li>Make the network less sensitive to small input changes.</li>
<li>Focus on the most important features.</li>
</ul></li>
<li><strong>Advantages</strong>:
<ul>
<li>They significantly reduce data size.</li>
<li>They make the network more resistant to small input changes.</li>
<li>They help extract key features regardless of exact position.</li>
</ul></li>
<li><strong>Challenges</strong>:
<ul>
<li>They permanently lose some information.</li>
<li>They might discard details that are important for the task.</li>
</ul></li>
</ul>
<p><strong>Types of pooling layers</strong>:</p>
<ul>
<li><strong>Max pooling</strong>: Keeps the maximum value in a region.</li>
<li><strong>Average pooling</strong>: Calculates the average value in a region.</li>
<li><strong>Global pooling</strong>: Averages information across the entire feature map, often used to reduce each feature map to a single value <a href="#fn31" class="footnote-ref" id="fnref31" role="doc-noteref"><sup>31</sup></a>.</li>
</ul>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-22-contents" aria-controls="callout-22" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interactive visualization of a pooling layer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-22" class="callout-22-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="pooling-layer"></div>
<script type="module" src="../_resources/js/vis-pooling-layer.js"></script>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Activation layer
</div>
</div>
<div class="callout-body-container callout-body">
<p><em>An activation layer adds non-linearity to the network, allowing it to learn complex patterns that go beyond simple calculations.</em></p>
<p><strong>How it works:</strong></p>
<ol type="1">
<li>The layer takes each input value individually.</li>
<li>It applies a mathematical function (like ReLU, sigmoid, or tanh).</li>
<li>This transforms values in a non-linear way.</li>
</ol>
<p>Think of it like adding decision points in the network: “If the value is below 0, ignore it. If above, keep it” (for ReLU).</p>
<ul>
<li><strong>Uses</strong>:
<ul>
<li>Enable to network to learn complex, non-linear relationships.</li>
<li>Control the range of output values.</li>
</ul></li>
<li><strong>Advantages</strong>:
<ul>
<li>They allow networks to learn complicated patterns.</li>
<li>They control how information flows through the network.</li>
<li>Different activations work well for different problems <a href="#fn32" class="footnote-ref" id="fnref32" role="doc-noteref"><sup>32</sup></a>.</li>
</ul></li>
<li><strong>Challenges</strong>:
<ul>
<li>Some activations can cause training problems (like vanishing gradients) <a href="#fn33" class="footnote-ref" id="fnref33" role="doc-noteref"><sup>33</sup></a>.</li>
<li>Choosing the right activation requires understanding the problem.</li>
</ul></li>
</ul>
<p><strong>Some examples</strong>:</p>
<ul>
<li><strong>ReLU</strong>: <span class="math inline">\(f(x) = \max(0, x)\)</span>.</li>
<li><strong>Sigmoid</strong>: <span class="math inline">\(f(x) = \frac{1}{1 + e^{-x}}\)</span>.</li>
<li><strong>Tanh</strong>: <span class="math inline">\(f(x) = \frac{e^{2x} - 1}{e^{2x} + 1}\)</span>.</li>
</ul>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-24-contents" aria-controls="callout-24" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interactive visualization of an activation layer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-24" class="callout-24-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="activation-layer"></div>
<script type="module" src="../_resources/js/vis-activation-layer.js"></script>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Recurrent layer
</div>
</div>
<div class="callout-body-container callout-body">
<p><em>A recurrent layer processes sequences by maintaining a memory of previous inputs, making it suitable for text, speech, and time-series data.</em></p>
<p><strong>How it works:</strong></p>
<ol type="1">
<li>It maintains an internal state (memory) between processing steps.</li>
<li>For each item in a sequence:
<ul>
<li>It combines the current input with its internal state.</li>
<li>It updates its state based on this combination.</li>
</ul></li>
<li>This allows information to persist across the sequence.</li>
</ol>
<p>Think of it like reading a book while keeping track of the story so far, using previous context to understand each new sentence.</p>
<ul>
<li><strong>Uses</strong>:
<ul>
<li>Process sequential data like text or time series.</li>
<li>Remember information from earlier in a sequence.</li>
<li>Generate sequential outputs based on context.</li>
</ul></li>
<li><strong>Advantages</strong>:
<ul>
<li>They can capture dependencies across sequence elements.</li>
<li>They can process sequences of variable length.</li>
<li>Variants like LSTM <a href="#fn34" class="footnote-ref" id="fnref34" role="doc-noteref"><sup>34</sup></a> <a href="#fn35" class="footnote-ref" id="fnref35" role="doc-noteref"><sup>35</sup></a> and GRU <a href="#fn36" class="footnote-ref" id="fnref36" role="doc-noteref"><sup>36</sup></a> can remember information for long periods.</li>
</ul></li>
<li><strong>Challenges</strong>:
<ul>
<li>They can be slow to train due to sequential processing.</li>
<li>They may suffer from vanishing or exploding gradients <a href="#fn37" class="footnote-ref" id="fnref37" role="doc-noteref"><sup>37</sup></a>.</li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-26-contents" aria-controls="callout-26" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Visualization of a LSTM cell
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-26" class="callout-26-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div style="display: flex; justify-content: center; align-items: center; width: 100%;">
    <video src="https://packaged-media.redd.it/afzlbpt2ncg81/pb/m2-res_480p.mp4?m=DASHPlaylist.mpd&amp;v=1&amp;e=1744837200&amp;s=962a50128d5f94aa8b6812f3f6c2d1119d2fa3e2" controls=""></video>
</div>
<div style="text-align: center; font-size: 0.8em; color: #666; margin-top: 0.5em;">
    Source: <a href="https://www.reddit.com/r/TheInsaneApp/comments/smiln0/long_short_term_memory_cell_visualized/" target="_blank">Reddit r/TheInsaneApp</a>
</div>
<p>The key components of an LSTM cell are:</p>
<ul>
<li><strong>Three gates</strong> (shown as X symbols in circles) from left to right:
<ul>
<li><strong>Forget gate</strong>: This decides what information to throw away or keep from memory.</li>
<li><strong>Input gate</strong>: This decides what new information to add to memory.</li>
<li><strong>Output gate</strong>: This decides what information to share with the next cell.</li>
</ul></li>
<li><strong>Inputs</strong>:
<ul>
<li>Current input <span class="math inline">\(x_t\)</span></li>
<li>Previous hidden state <span class="math inline">\(h_{t-1}\)</span></li>
<li>Previous cell state <span class="math inline">\(C_{t-1}\)</span></li>
</ul></li>
<li><strong>Outputs</strong>:
<ul>
<li>Current hidden state <span class="math inline">\(h_t\)</span></li>
<li>Current cell state <span class="math inline">\(C_t\)</span></li>
</ul></li>
<li>The <strong>blue box</strong> represents the <strong>sigmoid function</strong>, which outputs a value between 0 and 1. It controls how much information passes through each gate, like a filter that can be partially open or closed.</li>
<li>The <strong>purple box</strong> represents the <strong>tanh function</strong>, which outputs a value between -1 and 1. It scales the input values.</li>
</ul>
<p>The LSTM cell works as follows:</p>
<ol type="1">
<li><span class="math inline">\(h_{t-1}\)</span> and <span class="math inline">\(x_t\)</span> are combined together and passed through sigmoid functions as gate control signals.</li>
<li>The forget gate determines how much of the previous cell state <span class="math inline">\(C_{t-1}\)</span> (the previous memory) is passed to the next cell. Think of this like deciding which old memories to keep or discard.</li>
<li>The input gate determines how much of the current input <span class="math inline">\(x_t\)</span> is added to the cell state. This is like deciding which new information is worth remembering.</li>
<li>The output gate determines how much of the current cell state <span class="math inline">\(C_t\)</span> is passed to the next hidden state <span class="math inline">\(h_t\)</span>. This is like deciding which parts of your memory to actively think about right now.</li>
</ol>
</div>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-29-contents" aria-controls="callout-29" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Attention layer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-29" class="callout-29-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><em>An attention layer helps a network focus on relevant parts of the input data, similar to how humans concentrate on important details rather than everything at once.</em></p>
<p><strong>How it works:</strong></p>
<ol type="1">
<li>It calculates how important each input element is for the current task.</li>
<li>It assigns attention weights to each element based on this importance.</li>
<li>It creates a weighted combination of the inputs according to these weights.</li>
</ol>
<p>Think of it like reading with a highlighter: marking and focusing on key phrases rather than every word equally.</p>
<ul>
<li><strong>Uses</strong>:
<ul>
<li>Find relationships between different parts of the input.</li>
<li>Focus on relevant information for a specific task.</li>
<li>Handle long-range dependencies in sequences.</li>
</ul></li>
<li><strong>Advantages</strong>:
<ul>
<li>They significantly improve performance on complex tasks.</li>
<li>They create interpretable weightings that show what the network focuses on.</li>
<li>They enable processing of very long sequences effectively.</li>
</ul></li>
<li><strong>Challenges</strong>:
<ul>
<li>They can be computationally expensive, especially for long sequences.</li>
<li>Self-attention specifically scales quadratically with sequence length.</li>
<li>Designing the right attention mechanism requires careful consideration.</li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-28-contents" aria-controls="callout-28" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Visualization of image attention mechanism (conceptual flow)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-28" class="callout-28-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Attention mechanism is originally proposed for natural language processing tasks. The following visualization shows how it works for images. You may check how it works for text here: <a href="https://www.youtube.com/watch?v=wjZofJX0v4M">How LLMs work</a> and <a href="https://www.youtube.com/watch?v=eMlx5fFNoYc">Attention in transformers</a>.</p>
<div id="attention-layer"></div>
<script type="module" src="../_resources/js/vis-attention-layer.js"></script>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="models-1" class="level3" data-number="6.3.2">
<h3 data-number="6.3.2" class="anchored" data-anchor-id="models-1"><span class="header-section-number">6.3.2</span> Models</h3>
<p>Deep learning models are architectures composed of layers. Each model architecture has unique characteristics and is suited for particular tasks. Here are some examples:</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-30-contents" aria-controls="callout-30" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Convolutional Neural Networks (CNNs)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-30" class="callout-30-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><em>Best for image-related tasks.</em></p>
<ul>
<li><strong>Convolutional Neural Networks (CNNs)</strong> are designed to process and analyze images. They are characterized by:
<ul>
<li><strong>Convolutional Layers:</strong> Detecting patterns like edges, textures, and shapes.</li>
<li><strong>Pooling Layers:</strong> Reducing spatial dimensions to prevent overfitting.</li>
<li><strong>Fully-Connected Layers:</strong> Combining features for predictions.</li>
</ul></li>
<li><strong>Applications</strong> of CNNs:
<ul>
<li>Image classification, object detection, and segmentation.</li>
<li>Medical imaging analysis.</li>
<li>Remote sensing and satellite image processing.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-31-contents" aria-controls="callout-31" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Long Short-Term Memory Networks (LSTMs)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-31" class="callout-31-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><em>Designed for sequential data like time series or text.</em></p>
<ul>
<li><strong>Long Short-Term Memory Networks (LSTMs)</strong> are recurrent neural networks that maintain a hidden state to capture temporal dependencies. They are characterized by:
<ul>
<li><strong>Memory Cells:</strong> Capturing long-term dependencies in sequential data.</li>
<li><strong>Gates:</strong> Regulating the flow of information to prevent vanishing gradients.</li>
<li><strong>Hidden State:</strong> Maintaining a memory of past inputs to inform future predictions.</li>
</ul></li>
<li><strong>Applications</strong> of LSTMs:
<ul>
<li>Time series forecasting.</li>
<li>Natural language processing tasks like language modeling and machine translation.</li>
<li>Speech recognition and synthesis.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-32-contents" aria-controls="callout-32" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Transformers
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-32" class="callout-32-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><em>The backbone of modern natural language processing and vision models.</em></p>
<ul>
<li><strong>Transformers</strong> are models that process sequences of data using self-attention mechanisms. They are characterized by:
<ul>
<li><strong>Self-Attention:</strong> Computing relationships between elements in the data.</li>
<li><strong>Multi-Head Attention:</strong> Capturing different types of relationships in the data.</li>
<li><strong>Positional Encoding:</strong> Incorporating positional information into the model.</li>
</ul></li>
<li><strong>Applications</strong> of Transformers:
<ul>
<li>Natural language processing tasks like machine translation, text generation, and sentiment analysis.</li>
<li>Image analysis and computer vision tasks like object detection and image captioning.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-33-contents" aria-controls="callout-33" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Graph Neural Networks (GNNs)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-33" class="callout-33-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><em>Designed for graph-structured data like social networks, molecular structures, and knowledge graphs.</em></p>
<ul>
<li><strong>Graph Neural Networks (GNNs)</strong> are specialized models for processing graph-structured data. They are characterized by:
<ul>
<li><strong>Graph Convolutional Layers:</strong> Propagating information between nodes in the graph.</li>
<li><strong>Node Embeddings:</strong> Learning representations for nodes in the graph.</li>
<li><strong>Graph Pooling:</strong> Aggregating information from subgraphs.</li>
</ul></li>
<li><strong>Applications</strong> of GNNs:
<ul>
<li>Social network analysis and link prediction.</li>
<li>Drug discovery and molecular property prediction.</li>
<li>Knowledge graph completion and recommendation systems.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-34-contents" aria-controls="callout-34" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Autoencoders
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-34" class="callout-34-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><em>Used for unsupervised learning and dimensionality reduction.</em></p>
<ul>
<li><strong>Autoencoders</strong> are neural networks that learn to encode and decode data, enabling tasks like:
<ul>
<li><strong>Dimensionality Reduction:</strong> Learning compact representations of data.</li>
<li><strong>Anomaly Detection:</strong> Identifying outliers or unusual patterns in the data.</li>
<li><strong>Generative Modeling:</strong> Generating new data samples similar to the input.</li>
</ul></li>
<li><strong>Variants</strong> of autoencoders include:
<ul>
<li><strong>Variational Autoencoders (VAEs):</strong> Learn probabilistic encodings for generative modeling.</li>
<li><strong>Denoising Autoencoders:</strong> Train on noisy data to learn robust representations.</li>
<li><strong>Sparse Autoencoders:</strong> Encourage sparsity in the learned representations.</li>
</ul></li>
<li><strong>Applications</strong> of autoencoders:
<ul>
<li>Image denoising and reconstruction.</li>
<li>Anomaly detection in cybersecurity and fraud detection.</li>
<li>Generative modeling for data augmentation and synthesis.</li>
</ul></li>
</ul>
</div>
</div>
</div>
</section>
<section id="pre-trained-models-and-transfer-learning" class="level3" data-number="6.3.3">
<h3 data-number="6.3.3" class="anchored" data-anchor-id="pre-trained-models-and-transfer-learning"><span class="header-section-number">6.3.3</span> Pre-trained models and transfer learning</h3>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the realm of deep learning, building models from scratch can be both time-consuming and resource-intensive. Fortunately, pre-trained models and transfer learning offer a pratical solution to these challenges. They enables scientists to leverage existing models and achieve better performance with minimal efforts.</p>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-36-contents" aria-controls="callout-36" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Pre-trained models
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-36" class="callout-36-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Pre-trained models</strong> are deep learning models that have been previously trained on extensive datasets. These models can serve as a solid foundation for solving similar tasks in different domains. By utilizing the knowledge captured in pre-trained models, you can achieve faster training times and often better performance.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-37-contents" aria-controls="callout-37" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Transfer learning
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-37" class="callout-37-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Transfer learning</strong> is a technique where a model developed for a particular task is reused as the starting point for a model on a second task. This approach is particularly beneficial when the second task has limited data. Instead of training a new model from scratch, you can adapt an existing model that has already learned useful features from a large dataset.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-38-contents" aria-controls="callout-38" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Benefits of using pre-trained models
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-38" class="callout-38-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><strong>Faster Training:</strong> Pre-trained models provide a head start by leveraging knowledge from previous tasks, reducing the time and resources needed for training.</li>
<li><strong>Improved Performance:</strong> Transfer learning allows you to benefit from the generalization capabilities of pre-trained models, often leading to better performance on new tasks.</li>
<li><strong>Domain Adaptation:</strong> Pre-trained models can be fine-tuned on domain-specific data to adapt to new environments or tasks.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-39-contents" aria-controls="callout-39" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
How to implement transfer learning
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-39" class="callout-39-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>Select a Pre-trained Model:</strong> Choose a pre-trained model that is well-suited for your task. It depends on the nature of the data and the target task.</li>
<li><strong>Customize the Model:</strong> Adapt the pre-trained model to your specific task. The customization may occur at various stages:
<ul>
<li><strong>Input adaptation:</strong> Adjust the model to handle different types of input data. This might involve changing the input layer to accommodate data with more channels, such as multispectral images, or adapting it for temporal data like time series.</li>
<li><strong>Output adaptation:</strong> Modify the output layers to match your task requirements. This could mean changing the number of output classes for classification tasks. You can also use the pre-trained model as a backbone and build additional task-specific modules on top of it, such as object detection heads for image segmentation tasks.</li>
</ul></li>
<li><strong>Fine-tune the Model:</strong> Train the adapted model on your dataset. You can choose to freeze some of the earlier layers to preserve the learned features, while tuning the later layers to adapt to your task.</li>
</ol>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-40-contents" aria-controls="callout-40" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Practical applications
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-40" class="callout-40-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><strong>Image Classification:</strong> Use pre-trained models like ResNet or Swin Transformer for classifying images into different categories.</li>
<li><strong>Object Detection:</strong> Utilize pre-trained models like Faster R-CNN, YOLO, or RetinaNet for object detection tasks.</li>
<li><strong>Natural Language Processing:</strong> Apply pre-trained models like BERT, GPT, or RoBERTa for text classification, sentiment analysis, or question answering.</li>
</ul>
</div>
</div>
</div>
</section>
<section id="model-customization" class="level3" data-number="6.3.4">
<h3 data-number="6.3.4" class="anchored" data-anchor-id="model-customization"><span class="header-section-number">6.3.4</span> Model customization</h3>
<p><img src="../images/dl-pytorch/models.png" class="img-fluid"> In deep learning, models can be thought of as consisting of three core components: input adaptation, a feature extractor, and output adaptation. Understanding and customizing these components is crucial for effectively applying pre-trained models to new tasks.</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-41-contents" aria-controls="callout-41" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Feature extractor
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-41" class="callout-41-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The <strong>feature extractor</strong> is the heart of the model, transforming data into informative representations that highlight essential patterns relevant to the task. Pre-trained models often excel in this role, as they have already learned rich feature sets from large datasets. By using a pre-trained model as a feature extractor, you can leverage existing knowledge and focus on adapting it to your specific needs.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-42-contents" aria-controls="callout-42" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Input adaptation
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-42" class="callout-42-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Input adaptation</strong> involves transforming your data into a format that the feature extractor can process. This might mean:</p>
<ul>
<li>Adjusting the input layer to accommodate different data types, such as adding channels for multispectral images or handling temporal sequences for time series data.</li>
<li>Preprocessing data to match the scale or format expected by the pre-trained model.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-43-contents" aria-controls="callout-43" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Output adaptation
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-43" class="callout-43-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Output adaptation</strong> transforms the extracted features into usable outputs for your specific task. This often involves:</p>
<ul>
<li>Modifying the output layer to match the number of classes in your classification task.</li>
<li>Adding specialized layers, such as segmentation heads for image segmentation tasks, or regression layers for predicting continuous values.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-44-contents" aria-controls="callout-44" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Considerations for model customization
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-44" class="callout-44-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><strong>Task Similarity</strong>: The extent of adaptation needed depends on how closely the pre-trained model’s original task aligns with your target task. More divergent tasks may require extensive customization and additional data for fine-tuning. Therefore, selecting a pre-trained model that closely resembles your task can simplify the adaptation process.</li>
</ul>
</div>
</div>
</div>
</section>
</section>
<section id="loss-functions" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="loss-functions"><span class="header-section-number">6.4</span> Loss functions</h2>
<p><em>A loss function quantifies the difference between the predicted outputs and the actual target values, providing essential feedback for optimization.</em></p>
<p>For example, consider a classification task using a softmax output layer:</p>
<ul>
<li><strong>Predicted Output</strong>: <code>[0.6, 0.2, 0.2]</code></li>
<li><strong>Target Output</strong>: <code>[1, 0, 0]</code></li>
</ul>
<p>Using the <strong>Cross-Entropy loss function</strong>, the loss value is calculated as:</p>
<p><span class="math display">\[
\text{Cross-Entropy Loss} = -\sum_{i} y_i \log(p_i) = -\log(0.6) = 0.51
\]</span></p>
<p>where <span class="math inline">\(y_i\)</span> is the target output and <span class="math inline">\(p_i\)</span> is the predicted output.</p>
<p><strong>Mean Absolute Error (MAE)</strong> can also be used to evaluate the prediction:</p>
<p><span class="math display">\[
\text{MAE} = \frac{1}{n} \sum_{i} |y_i - p_i| = \frac{|1 - 0.6| + |0 - 0.2| + |0 - 0.2|}{3} = \frac{0.4 + 0.2 + 0.2}{3} = 0.27
\]</span></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick Thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the example above, both Cross-Entropy and MAE can evaluate the prediction’s accuracy. Consider these questions:</p>
<ul>
<li>How do the values of the two loss functions change when predictions are closer to or further from the target?</li>
<li>What is the impact of each loss function on the model training process?</li>
</ul>
</div>
</div>
<section id="types-of-loss-functions" class="level3" data-number="6.4.1">
<h3 data-number="6.4.1" class="anchored" data-anchor-id="types-of-loss-functions"><span class="header-section-number">6.4.1</span> Types of Loss Functions</h3>
<p>Selecting the right loss function is essential for optimizing model performance across various tasks. Here are some common types of loss functions:</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-46-contents" aria-controls="callout-46" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Task-Specific Loss Functions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-46" class="callout-46-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><strong>Regression</strong>: Measure error for continuous outputs.
<ul>
<li><strong>Mean Squared Error (MSE)</strong>: Computes the average squared difference between predictions and targets.</li>
<li><strong>Mean Absolute Error (MAE)</strong>: Calculates the average absolute difference between predictions and targets.</li>
<li><strong>Huber Loss</strong>: Combines MSE and MAE, less sensitive to outliers than MSE.</li>
</ul></li>
<li><strong>Classification</strong>: Evaluate probability distributions.
<ul>
<li><strong>Cross-Entropy Loss</strong>: Measures the difference between predicted and target distributions, used with softmax outputs.</li>
<li><strong>Binary Cross-Entropy</strong>: Specifically for binary classification tasks.</li>
<li><strong>Hinge Loss</strong>: Used for “maximum-margin” classification, mainly with support vector machines.</li>
</ul></li>
<li><strong>Sequence Prediction</strong>: Handle variable-length outputs.
<ul>
<li><strong>Connectionist Temporal Classification (CTC)</strong>: Aligns input and output sequences, used in tasks like speech recognition.</li>
<li><strong>Sequence-to-Sequence Loss</strong>: Often combines cross-entropy with attention mechanisms.</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-47-contents" aria-controls="callout-47" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Purpose-Specific Loss Functions
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-47" class="callout-47-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><strong>Imbalanced Data</strong>:
<ul>
<li><strong>Focal Loss</strong>: Mitigates class imbalance by focusing on hard-to-classify examples.</li>
<li><strong>Weighted Cross-Entropy</strong>: Assigns different weights to classes to balance their impact.</li>
</ul></li>
<li><strong>Multi-Objective Tasks</strong>:
<ul>
<li><strong>Multi-Task Loss</strong>: Combines multiple loss functions with weighting factors to optimize for several objectives simultaneously.</li>
</ul></li>
<li><strong>Robustness to Outliers</strong>:
<ul>
<li><strong>Log-Cosh Loss</strong>: Similar to MSE but less sensitive to outliers, using the hyperbolic cosine of prediction errors.</li>
</ul></li>
<li><strong>Image Processing</strong>:
<ul>
<li><strong>Dice Loss</strong>: Used for image segmentation tasks to measure overlap between predicted and target areas.</li>
<li><strong>IoU Loss (Intersection over Union)</strong>: Measures the overlap between predicted and actual bounding boxes, often used in object detection.</li>
</ul></li>
</ul>
</div>
</div>
</div>
</section>
<section id="training-and-validation-loss" class="level3" data-number="6.4.2">
<h3 data-number="6.4.2" class="anchored" data-anchor-id="training-and-validation-loss"><span class="header-section-number">6.4.2</span> Training and validation loss</h3>
<p>Training and validation loss are metrics used to evaluate and fine-tune the performance of machine learning models. They provide insights into how well a model is learning and can indicate potential issues like overfitting or underfitting.</p>
<ul>
<li><p><strong>Training Loss</strong>: This is the error calculated on the training dataset after each iteration. It reflects how well the model is learning the training data.</p></li>
<li><p><strong>Validation Loss</strong>: This is the error calculated on a separate validation dataset that the model has not seen during training. It provides an indication of how well the model generalizes to unseen data.</p></li>
</ul>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-48-contents" aria-controls="callout-48" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpreting training and validation loss
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-48" class="callout-48-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The relationship between training and validation loss can reveal important information about the model’s performance:</p>
<ul>
<li><strong>Both losses decrease:</strong> If both training and validation losses decrease and stabilize at a low value, it suggests that the model is learning well and generalizing effectively to the validation set.</li>
<li><strong>Training loss decreases, validation loss increases</strong>: This pattern indicates overfitting. The model is learning the training data too well, including its noise, and is not generalizing effectively to new data. Regularization techniques or a simpler model might be needed.</li>
<li><strong>Both losses are high</strong>: If both losses remain high, it may indicate underfitting. The model is not complex enough to capture the underlying patterns in the data. Consider increasing model capacity or improving feature engineering.</li>
<li><strong>Training loss stable, validation loss fluctuates</strong>: Fluctuating validation loss with stable training loss may suggest that the model is sensitive to the specific validation data. This could be due to a small validation set size or data noise.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-49-contents" aria-controls="callout-49" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Strategies to manage training and validation loss
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-49" class="callout-49-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>To address common issues related to training and validation loss, consider the following strategies:</p>
<ul>
<li><strong>Regularization</strong>: Techniques like L1/L2 regularization, dropout, and early stopping can help mitigate overfitting.</li>
<li><strong>Data Augmentation</strong>: Increasing the diversity of the training data can improve model generalization.</li>
<li><strong>Cross-Validation</strong>: Using k-fold cross-validation provides a more reliable estimate of model performance on unseen data.</li>
</ul>
</div>
</div>
</div>
</section>
</section>
<section id="optimization-algorithms" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="optimization-algorithms"><span class="header-section-number">6.5</span> Optimization Algorithms</h2>
<p><em>Optimization algorithms adjust model parameters to minimize the loss function, guiding the model towards better performance.</em></p>
<section id="introduction-to-gradient-descent" class="level3" data-number="6.5.1">
<h3 data-number="6.5.1" class="anchored" data-anchor-id="introduction-to-gradient-descent"><span class="header-section-number">6.5.1</span> Introduction to gradient descent</h3>
<p><strong>Gradient Descent</strong> is the foundational algorithm used in deep learning for optimization:</p>
<ul>
<li><strong>Objective</strong>: The aim is to find the minimum of a function by iteratively adjusting parameters.</li>
<li><strong>Gradient</strong>: Represents the direction of the steepest ascent. In optimization, we move in the opposite direction to find the minimum.</li>
<li><strong>Learning rate</strong>: A crucial hyperparameter that controls the size of the steps taken towards the minimum.</li>
</ul>
</section>
<section id="variants-of-gradient-descent" class="level3" data-number="6.5.2">
<h3 data-number="6.5.2" class="anchored" data-anchor-id="variants-of-gradient-descent"><span class="header-section-number">6.5.2</span> Variants of gradient descent</h3>
<p>To enhance the efficiency and performance of gradient descent, several variants have been developed:</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-50-contents" aria-controls="callout-50" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Stochastic gradient descent (SGD)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-50" class="callout-50-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Update parameters using a single training example per iteration, leading to faster but noisier convergence.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-51-contents" aria-controls="callout-51" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Mini-batch gradient descent
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-51" class="callout-51-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>It strikes a balance between batch and stochastic gradient descent by updating parameters using a small subset (mini-batch) of the training data, improving convergence stability and speed.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-52-contents" aria-controls="callout-52" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Momentum
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-52" class="callout-52-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>This method accelerates convergence by considering past gradients, helping the algorithm navigate through ravines and avoid oscillations.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-53-contents" aria-controls="callout-53" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Adam (Adaptive moment estimation)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-53" class="callout-53-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Adam combines the benefits of momentum and RMSprop, adjusting learning rates for each parameter based on historical gradients, making it one of the most popular optimization methods.</p>
</div>
</div>
</div>
</section>
<section id="key-hyperparameters" class="level3" data-number="6.5.3">
<h3 data-number="6.5.3" class="anchored" data-anchor-id="key-hyperparameters"><span class="header-section-number">6.5.3</span> Key Hyperparameters</h3>
<p>Optimization algorithms rely on hyperparameters that need to be carefully tuned for optimal performance:</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-54-contents" aria-controls="callout-54" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning rate
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-54" class="callout-54-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The learning rate determines how quickly or slowly the model learns. It needs to be carefully selected to balance convergence speed and stability.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-55-contents" aria-controls="callout-55" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Batch size
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-55" class="callout-55-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The batch size refers to the number of training samples used in one iteration. Smaller batch sizes can lead to faster convergence but noisier updates, while larger batch sizes provide smoother updates but require more computational resources.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-56-contents" aria-controls="callout-56" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Momentum rate
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-56" class="callout-56-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The momentum rate determines the influence of past gradients on the current update, helping to smooth the optimization path.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-57-contents" aria-controls="callout-57" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Regularization strength
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-57" class="callout-57-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>A factor used to prevent overfitting by penalizing complex models, ensuring simpler and more generalizable solutions.</p>
</div>
</div>
</div>
</section>
<section id="learning-rate-scheduling" class="level3" data-number="6.5.4">
<h3 data-number="6.5.4" class="anchored" data-anchor-id="learning-rate-scheduling"><span class="header-section-number">6.5.4</span> Learning rate scheduling</h3>
<p>Adjusting the learning rate over time can impact model performance:</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-58-contents" aria-controls="callout-58" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Fixed scheduling
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-58" class="callout-58-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Maintains a constant learning rate throughout training, simplifying the optimization process.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-59-contents" aria-controls="callout-59" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Step decay
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-59" class="callout-59-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Reduces the learning rate at regular intervals, allowing the model to refine its parameters as it approaches convergence.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-60-contents" aria-controls="callout-60" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exponential decay
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-60" class="callout-60-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Gradually decreases the learning rate exponentially, enabling fine-tuning of the model as training progresses.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-61-contents" aria-controls="callout-61" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Cyclical learning rates
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-61" class="callout-61-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Vary the learning rate cyclically, encouraging exploration of different regions of the loss landscape for potentially better minima.</p>
</div>
</div>
</div>
</section>
<section id="adaptive-learning-rates" class="level3" data-number="6.5.5">
<h3 data-number="6.5.5" class="anchored" data-anchor-id="adaptive-learning-rates"><span class="header-section-number">6.5.5</span> Adaptive learning rates</h3>
<p>These methods automatically adjust the learning rate during training:</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-62-contents" aria-controls="callout-62" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Adam
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-62" class="callout-62-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Adaptive moment estimation that combines momentum and RMSprop, providing an efficient and effective optimization approach.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-63-contents" aria-controls="callout-63" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
RMSprop (Root Mean Square Propagation)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-63" class="callout-63-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Divides the learning rate by a moving average of the squared gradients, adapting the learning rate for each parameter dynamically.</p>
</div>
</div>
</div>
</section>
</section>
<section id="training-and-inference" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="training-and-inference"><span class="header-section-number">6.6</span> Training and Inference</h2>
<p><em>Training and inference are the key processes that integrate the essential components for deep learning applications: data, models, loss functions, and optimization algorithms.</em></p>
<section id="training" class="level3" data-number="6.6.1">
<h3 data-number="6.6.1" class="anchored" data-anchor-id="training"><span class="header-section-number">6.6.1</span> Training</h3>
<p>Training is the phase where the model learns from the data by optimizing its parameters to minimize the loss function.</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-64-contents" aria-controls="callout-64" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Steps
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-64" class="callout-64-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>Data preparation</strong>: Gather and preprocess data into a suitable format for the model.</li>
<li><strong>Forward pass</strong>: The model processes the input data to generate predictions.</li>
<li><strong>Loss calculation</strong>: The predictions are compared against the target outputs using a loss function to quantify the error.</li>
<li><strong>Backward pass</strong>: Compute gradients of the loss with respect to the model parameters using backpropagation.</li>
<li><strong>Parameter ppdate</strong>: Utilize optimization algorithms (e.g., Gradient Descent, Adam) to update the model’s weights based on the computed gradients, iteratively improving the model’s performance.</li>
</ol>
</div>
</div>
</div>
</section>
<section id="inference" class="level3" data-number="6.6.2">
<h3 data-number="6.6.2" class="anchored" data-anchor-id="inference"><span class="header-section-number">6.6.2</span> Inference</h3>
<p>Inference is the phase where the trained model is used to make predictions on new, unseen data.</p>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-65-contents" aria-controls="callout-65" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Steps
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-65" class="callout-65-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>Data preparation</strong>: Prepare new data in the same way as the training data for consistency.</li>
<li><strong>Forward pass</strong>: The model processes the input data to generate predictions, leveraging the learned parameters.</li>
<li><strong>Output generation</strong>: Convert raw model outputs into interpretable results, such as class labels or continuous values.</li>
<li><strong>Post-processing</strong>: Apply additional processing steps like thresholding for binary classification or filtering to refine results.</li>
<li><strong>Result interpretation</strong>: Analyze the model’s outputs to make informed decisions, often integrating domain-specific knowledge or business logic.</li>
</ol>
</div>
</div>
</div>


</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p><a href="https://speech.ee.ntu.edu.tw/~hylee/ml/ml2023-course-data/ML%20basic%20(v8).pdf"><em>https://speech.ee.ntu.edu.tw/~hylee/ml/ml2023-course-data/ML%20basic%20(v8).pdf</em></a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a href="https://openai.com/chatgpt/overview/" class="uri">https://openai.com/chatgpt/overview/</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><a href="https://openai.com/index/dall-e/" class="uri">https://openai.com/index/dall-e/</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><a href="https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/" class="uri">https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p><a href="https://arcticdata.io/" class="uri">https://arcticdata.io/</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p><a href="https://arctic.noaa.gov/data/" class="uri">https://arctic.noaa.gov/data/</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p><a href="https://www.snowflake.com/en/blog/five-steps-data-diversity-for-smarter-ai-models/" class="uri">https://www.snowflake.com/en/blog/five-steps-data-diversity-for-smarter-ai-models/</a><a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p><a href="https://www.markovml.com/blog/data-quality-validation" class="uri">https://www.markovml.com/blog/data-quality-validation</a><a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p><a href="https://www.geeksforgeeks.org/ml-handling-missing-values/" class="uri">https://www.geeksforgeeks.org/ml-handling-missing-values/</a><a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p><a href="https://www.mastersindatascience.org/learning/how-to-deal-with-missing-data/" class="uri">https://www.mastersindatascience.org/learning/how-to-deal-with-missing-data/</a><a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p><a href="https://www.freecodecamp.org/news/how-to-detect-outliers-in-machine-learning/" class="uri">https://www.freecodecamp.org/news/how-to-detect-outliers-in-machine-learning/</a><a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p><a href="https://www.geeksforgeeks.org/detect-and-remove-the-outliers-using-python/" class="uri">https://www.geeksforgeeks.org/detect-and-remove-the-outliers-using-python/</a><a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p><a href="https://developers.google.com/machine-learning/crash-course/numerical-data/normalization" class="uri">https://developers.google.com/machine-learning/crash-course/numerical-data/normalization</a><a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p><a href="https://www.alooba.com/skills/concepts/deep-learning/data-splitting/" class="uri">https://www.alooba.com/skills/concepts/deep-learning/data-splitting/</a><a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p><a href="https://datascience.stanford.edu/news/splitting-data-randomly-can-ruin-your-model" class="uri">https://datascience.stanford.edu/news/splitting-data-randomly-can-ruin-your-model</a><a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p><a href="https://en.wikipedia.org/wiki/Stratified_sampling" class="uri">https://en.wikipedia.org/wiki/Stratified_sampling</a><a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p><a href="https://www.baeldung.com/cs/ml-stratified-sampling" class="uri">https://www.baeldung.com/cs/ml-stratified-sampling</a><a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p><a href="https://www.geeksforgeeks.org/spatial-data-analysis-with-python/" class="uri">https://www.geeksforgeeks.org/spatial-data-analysis-with-python/</a><a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p><a href="https://www.tandfonline.com/doi/abs/10.1080/24694452.2024.2373787">Li, W., Hsu, C. Y., Wang, S., &amp; Kedron, P. (2024). GeoAI Reproducibility and Replicability: a computational and spatial perspective. Annals of the American Association of Geographers, 114(9), 2085-2103.</a><a href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p><a href="https://anushsom.medium.com/image-augmentation-for-creating-datasets-using-pytorch-for-dummies-by-a-dummy-a7c2b08c5bcb" class="uri">https://anushsom.medium.com/image-augmentation-for-creating-datasets-using-pytorch-for-dummies-by-a-dummy-a7c2b08c5bcb</a><a href="#fnref20" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21"><p><a href="https://www.datacamp.com/tutorial/complete-guide-data-augmentation" class="uri">https://www.datacamp.com/tutorial/complete-guide-data-augmentation</a><a href="#fnref21" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn22"><p><a href="https://ubiai.tools/what-are-the-advantages-anddisadvantages-of-data-augmentation-2023-update/" class="uri">https://ubiai.tools/what-are-the-advantages-anddisadvantages-of-data-augmentation-2023-update/</a><a href="#fnref22" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn23"><p><a href="https://proceedings.neurips.cc/paper/2017/hash/f26dab9bf6a137c3b6782e562794c2f2-Abstract.html">Ratner, A. J., Ehrenberg, H., Hussain, Z., Dunnmon, J., &amp; Ré, C. (2017). Learning to compose domain-specific transformations for data augmentation. Advances in neural information processing systems, 30.</a><a href="#fnref23" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn24"><p><a href="https://arxiv.org/pdf/2006.07159">Beyer, L., Hénaff, O. J., Kolesnikov, A., Zhai, X., &amp; Oord, A. V. D. (2020). Are we done with imagenet?. arXiv preprint arXiv:2006.07159.</a><a href="#fnref24" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn25"><p><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection-in-formats.html" class="uri">https://docs.aws.amazon.com/sagemaker/latest/dg/object-detection-in-formats.html</a><a href="#fnref25" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn26"><p><a href="https://arxiv.org/abs/2203.15556">Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., … &amp; Sifre, L. (2022). Training compute-optimal large language models. arXiv preprint arXiv:2203.15556.</a><a href="#fnref26" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn27"><p><a href="https://arxiv.org/abs/2112.11446">Rae, J. W., Borgeaud, S., Cai, T., Millican, K., Hoffmann, J., Song, F., … &amp; Irving, G. (2021). Scaling language models: Methods, analysis &amp; insights from training gopher. arXiv preprint arXiv:2112.11446.</a><a href="#fnref27" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn28"><p><a href="https://arxiv.org/abs/2203.15556">Hoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., … &amp; Sifre, L. (2022). Training compute-optimal large language models. arXiv preprint arXiv:2203.15556.</a><a href="#fnref28" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn29"><p><a href="https://adamharley.com/nn_vis/mlp/3d.html" class="uri">https://adamharley.com/nn_vis/mlp/3d.html</a><a href="#fnref29" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn30"><p><a href="https://cs231n.github.io/convolutional-networks/" class="uri">https://cs231n.github.io/convolutional-networks/</a><a href="#fnref30" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn31"><p><a href="https://arxiv.org/abs/1312.4400">Lin, M., Chen, Q., &amp; Yan, S. (2013). Network in network. arXiv preprint arXiv:1312.4400.</a><a href="#fnref31" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn32"><p><a href="https://www.v7labs.com/blog/neural-networks-activation-functions" class="uri">https://www.v7labs.com/blog/neural-networks-activation-functions</a><a href="#fnref32" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn33"><p><a href="https://www.geeksforgeeks.org/tanh-vs-sigmoid-vs-relu/" class="uri">https://www.geeksforgeeks.org/tanh-vs-sigmoid-vs-relu/</a><a href="#fnref33" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn34"><p><a href="https://ieeexplore.ieee.org/abstract/document/6795963">Hochreiter, S., &amp; Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8), 1735-1780.</a><a href="#fnref34" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn35"><p><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a><a href="#fnref35" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn36"><p><a href="https://arxiv.org/abs/1406.1078">Cho, K., Van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., &amp; Bengio, Y. (2014). Learning phrase representations using RNN encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078.</a><a href="#fnref36" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn37"><p><a href="https://www.superdatascience.com/blogs/recurrent-neural-networks-rnn-the-vanishing-gradient-problem" class="uri">https://www.superdatascience.com/blogs/recurrent-neural-networks-rnn-the-vanishing-gradient-problem</a><a href="#fnref37" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../sections/hands-on-lab-data-annotation.html" class="pagination-link" aria-label="Hands-On Lab: Data Annotation">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Hands-On Lab: Data Annotation</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../sections/intro-to-pytorch.html" class="pagination-link" aria-label="Introduction to PyTorch: Core Functionalities and Advantages">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to PyTorch: Core Functionalities and Advantages</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>