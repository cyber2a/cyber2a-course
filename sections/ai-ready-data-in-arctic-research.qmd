---
execute:
  freeze: true
---
# AI-Ready Data in Arctic Research

## Goal {.unnumbered}
This session dives into the concept of 'AI-ready data' in Arctic science and geoscience, highlighting the importance of suitable data for AI applications. Participants will learn about creating and managing metadata and organizing data repositories. We'll discuss best practices for data preparation and structuring for AI processing. By the end, participants will clearly understand AI-ready data characteristics and the steps to transform raw data for AI applications.

## Are we ready for AI?

::: {.callout-tip}
## What is AI-Ready Data?

Data that are **accessible**, preferably **open**, and **well-documented**, making them easily **interpretable** for **reuse** and analysis.
:::

This is really a variant on Analysis Ready Data (ARD), or, more recently, "Analysis Ready, Cloud Optimized (ARCO)" data.

![Mahecha et al. 2020. [@mahecha_earth_2020] Visualization of the implemented Earth system data cube. The figure shows from the top left to bottom right the variables sensible heat (H), latent heat (LE), gross primary production (GPP), surface moisture (SM), land surface temperature (LST), air temperature (Tair), cloudiness (C), precipitation (P), and water vapour (V). The resolution in space is 0.25° and 8 d in time, and we are inspecting the time from May 2008 to May 2010; the spatial range is from 15° S to 60° N, and 10° E to 65° W.](../images/ai-ready/mahecha_data_cube.png)

Working with `xarray` and `zarr`, one can access many multi-petabyte earth systems datasets like CMIP6 (Coupled Model Intercomparison Project Phase 6) and ERA5 (Earth Re). For an overview of Zarr, see the Arctic Data Center Scalable Computing course [chapter on Zarr](https://learning.nceas.ucsb.edu/2024-03-arctic/sections/zarr.html).

Take, for example, the ERA5 reanalysis dataset [@noauthor_era5_nodate], which is normally downloadable in bulk from the Copernicus Data Service. [ARCO-ERA5](https://github.com/google-research/arco-era5
) is an Analysis Ready, Cloud Optimized variant of ERA5 which has been reprocessed into a consistent 0.25° global grid, and chunked and saved in Zarr format with extensive metadata such that spatial and temporal subsets are easily extracted. Hosted on the Google Cloud Storage service in a public bucket (`gcp-public-data-arco-era5`), anyone can easily access slices of this massive multi-petabyte dataset from anywhere on the Internet, and can be doing analysis in seconds. Let's take a quick peek at this massive dataset:


```python
import xarray

ds = xarray.open_zarr(
    'gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3',
    chunks=None,
    storage_options=dict(token='anon')
)
ds
```

![](../images/ai-ready/era5-zarr-arco.png)

With one line of code, we accessed 273 climate variables (e.g., `2m_temperature`, `evaporation`, `forecast_albedo`) spanning 8 decades at hourly time scales. And while this dataset is massive, we can explore it from the comfort of our laptop (not all at once, for which we would need a bigger machine!).

So, there's nothing really special about AI-Ready data, in that a lot of the core requirements for Analysis Ready Data are exactly what are needed for AI modeling as well. Labeling is probably the main difference. Neverthless, many groups have gotten motivated by the promise of AI, and particularly machine learning, across disciplines. For example, the federal government has been ramping up readiness for AI across many agencies. In 2019, the White House Office of Science Technology and Policy (OSTP) started an AI-Readiness matrix, which was followed shortly by the National AI Initiative Act in 2020 [@long_ai-ready_2023].

![](https://bipartisan-policy-center.imgix.net/wp-content/uploads/2023/02/AI-Ready-Open-Data.jpg?auto=compress,format&q=90&ixlib=imgixjs-3.4.2&w=4088)

For example, management agencies have started entire new programs to prepare data and staff for the introcution of AI and machine learning into their processes. One such program with a focus on AI-Ready data is NOAA's Center for Artificial Intelligence (NCAI).

![[NOAA NCAI](https://www.noaa.gov/ai)](../images/ai-ready/noaa-ncai.png)

In beginning to define AI-Ready data for NOAA, [Christensen et al. 2020](https://www.star.nesdis.noaa.gov/star/documents/meetings/2020AI/presentations/202010/20201022_Christensen.pdf) defined several axes for evaluation, including data quality, data acess, and data documentation. We'll be dinving into many of these today and over the course of the week.

::: {layout="[1,1,1]"}

::: {.callout-tip}
## Data Quality

- Completeness
- Consistency
- Lack of bias
- Timeliness
- Provenance and Integrity
:::

::: {.callout-tip}
## Data Access

- Formats
- Delivery options
- Usage rights
- Security / privacy
:::

::: {.callout-tip}
## Data Documentation

- Dataset Metadata
- Data dictionary
- Identifier
:::

:::

## Open Data Foundations

Preservation and open data access are the foundation of Analysis-Ready and AI-ready data. While all modeling and analysis requires access to data, the ability for AI to encompass massive swaths of information and combine disparate data streams makes open data incredibly valuable. And while the open data movement has seen massive growth and adoption, it's an unfortunate fact that most research data collected today are still not published and accessible, and challenges to the realization of open data outlined by Reichman et al. (2011) are still prominent today [@reichman_challenges_2011]. 

### Arctic Data Center

Nevertheless, progress has been made. The National Science Foundation [Office of Polar Programs Data, Code, and Sample Management Policy (DCL 22-106)](https://www.nsf.gov/pubs/2022/nsf22106/nsf22106.jsp) embraces the need to preserve, document, and share the data and results from NSF-funded research, and since 2016 has funded the Arctic Data Center to provide services supporting reseach community data needs. The center provides [data submission guidelines](https://arcticdata.io/submit/) and data curation support to create well-documented, understandable, and reusable data from the myriad projects funded by NSF and globally each year. In short, the Arctic Data Center provides a long-term home for over 7000 open, Arctic datasets that are AI-Ready. Researchers increasingly deposit large datasets from remote sensing campaigns using unmanned aerial vehicles (UAV), field expeditions, and observing networks, all of which are prime content for AI.

::: {.column-margin}
![](../images/ai-ready/arctic-data-center.png)
:::

::: {.column-page-right}
![Arctic Data Center Catalog](../images/ai-ready/adc-catalog.png)
:::

In addition to raw observational data and remote sensing imagery, the ADC also stores and distributes model output, labeled training data, and other derived data products. A recent example comes from the Permafrost Discovery Gateway project, in which Neitze et al. used machine learning on multispectral PlanetScope imagery to extract high-resolution geospatial footprints for retrogressive thaw slumps (RTS) and active layer detachment (ALD) slides across the circum-Arctic permafrost region [@nitze_darts_2024]. In addition, the dataset includes human-generated training labels, processing code, and model checkpoints -- just what is needed for further advances in this critical field of climate research.

::: {.column-margin}
![](../images/ai-ready/rts-feature.png)
:::

![DARTS retrogressive thaw slump dataset [doi:10.18739/A2RR1PP44](https://doi.org/10.18739/A2RR1PP44) ](../images/ai-ready/darts-dataset.png)

While this and other valuable data for cross-cutting analysis are available from the Arctic Data Center, there are many other repositories that hold relevant data as well. Regardless of which repository a researher has chosen to share their data, the important thing to remember is to do so -- data on your laptop or a University web server are rarely accessible and ready for reuse.

### DataONE

[DataONE](https://dataone.org) is a network designed to connect over [60 global data repositories](https://www.dataone.org/network/) (and growing) to improve the discoverability and accessiblilty of data from across the  world. DataONE provides global data search and discovery by harmonizing myriad metadata standards used across the world, and providing an interoperability API across repositories to make datasets **findable** and programatically **accessible** regardless of where they live.

![](../images/ai-ready/dataone-network.png)

For example, a query across DataONE in 2024 revealed over 4500 datasets held by 16 different repositories, most of which are not specifically tied to Greenland research, per se.

![](../images/ai-ready/dataone-greenland-datasets.png)

Looking across the whole of the Arctic, we found over 98,000 datasets from 39 data repositories. It is notable that only 6 of those repositories are focused on Arctic research (like the Arctic Data Center), while the rest are either general repositories or discipline specific repositories. For example, [Pangaea](https://www.pangaea.de/) as a generalist repository has the most datasets with over 10,000, but there are also significant and important data sets on archeology ([TDAR](https://www.tdar.org/)), hydrology ([HydroShare](https://www.hydroshare.org/)) and geochemistry ([EarthChem](https://www.earthchem.org/)).

![Graph of Arctic Data across DataONE](../images/ai-ready/dataone-arctic-datasets.png)

### Metadata harmonization

One of the main roles of DataONE is to promote interoperability and improve the quality and discoverability of global data holdings -- all of direct benefit to AI Ready data. DataONE promotes the use of detailed, discipline-specific metadata standards that enable researchers to comprehensively document the structure, contents, context, and protocols used when collecting data. For example, a good metadata record records not only the bibliographic information about the Dataset creators, but also documents the spatial and temporal extent of the data, the methods used to collect it, the types of measured properties that were observed or modeled, and other details that are fundamental to the proper interpretation and reuse of the data. Different disciplines focus on different standards: in ecology and environmental science, where biological metadata on taxonomy are important, the [Ecological Metadata Language (EML)](https://eml.ecoinformatics.org) is used extensively, whereas in geospatial science where time and space are critical, the emphasis is on the ISO 19115 family of metadata standards. Overall, DataONE supports more than a dozen metadata variants, and can be extended to support more. Across the Arctic, we find datasets that use many different metadata approaches.

![](../images/ai-ready/dataone-arctic-metadata.png)

DataONE harmonizes these standards by cross-walking them conceptually and making the data available for search through an integrated discovery portal and API. And DataONE promotes semantic labeling of the data as well, particularly for measurement types (e.g., `fork length` for fish length meeasurements) and dataset classification. These annotations are indexed against controlled, ontologically-precise term labels that are stored in queryable systems. For example, the [Ecosystem Ontology (ECSO](https://bioportal.bioontology.org/ontologies/ECSO/), the [Environment Ontology (ENVO)](https://sites.google.com/site/environmentontology/about-envo), and many others contain precisely defined terms that are useful for precise dataset labeling to differentiate subtly different terms and concepts. 

![A sub-Arctic salmon-related dataset [@game_salmon_2018], showing annotations for each of the measured variables in the dataset. Each annotation is to a precisely defined concept or term from a controlled vocabulary, allowing subtle differences in methodology to be distinguished, which helps with both data discovery and proper reuse. The underlying metadata model is machine-readable, allowing search systems, and amchine learning harvesters to make use of this structured label data.](../images/ai-ready/dataone-annotation-salmon.png)

## Data Quality

MetaDIG

![Data Quality assessment](../images/ai-ready/metadig-report.png)

## Tidy data

https://learning.nceas.ucsb.edu/2024-02-arctic/session_07.html

## ESIP AI-Readiness Checklist

[@noauthor_checklist_2022]

- Data Preparation
- Data Quality
- Data Documentation
- Data Access

## Croissant

Schema.org as *lingua franca*


Croissant specifiction [@benjelloun_croissant_2024]

Croissant Responsible AI (RAI) specification and use cases


## Exercise

Documenting data

## Key Elements {.unnumbered}
AI-ready data definition, data suitability importance, metadata management, data repository organization, data preparation practices, raw data transformation