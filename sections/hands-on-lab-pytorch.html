<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>8&nbsp; Hands-On Lab: PyTorch – Cyber2A: AI for Arctic Research</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../sections/permafrost-discovery-gateway.html" rel="next">
<link href="../sections/intro-to-pytorch.html" rel="prev">
<link href="../images/index/arcticlogo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-3584025bd2775ba93d20b6dabf7256d8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../sections/the-building-blocks-of-nn-and-dl.html"><b>Day 2: AI Fundamentals and Techniques</b></a></li><li class="breadcrumb-item"><a href="../sections/hands-on-lab-pytorch.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Hands-On Lab: PyTorch</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Cyber2A: AI for Arctic Research</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/cyber2a/cyber2a-course/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Overview</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 1: Introduction to AI and Arctic Science</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/breaking-the-ice-with-ai-in-arctic-science.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Breaking the Ice with AI in Arctic Science</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-for-everyone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI for Everyone</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-ready-data-in-arctic-research.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">AI-Ready Data in Arctic Research</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/data-annotation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Data Annotation: The Foundation of Deep Learning Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-data-annotation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Hands-On Lab: Data Annotation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 2: AI Fundamentals and Techniques</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/the-building-blocks-of-nn-and-dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The Building Blocks of Neural Networks and Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/intro-to-pytorch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to PyTorch: Core Functionalities and Advantages</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-pytorch.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Hands-On Lab: PyTorch</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/permafrost-discovery-gateway.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Permafrost Discovery Gateway</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-ethics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">AI Ethics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 3: Advanced AI Workflows and Models</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/guest-lecture-yili-arts-dataset.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Guest Lecture - Unveiling the ARTS Dataset for a Thawing Frontier</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/exploring-advanced-neural-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Exploring Advanced Neural Networks: Instance Segmentation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/intro-to-dl-libraries-for-image-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Introduction to Deep Learning Libraries for Image Analysis</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 4: Workflows and Foundation Models</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-workflows-and-mlops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">AI Workflows and MLOps: From Development to Deployment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-ai-workflows.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Hands-On Lab: AI Workflows</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/foundation-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Foundation Models: The Cornerstones of Modern AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-foundation-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Hands-On Lab: Foundation Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/reproducibility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Reproducibility</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 5: AI Frontiers</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/the-fun-and-frontiers-of-ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">The Fun and Frontiers of AI: Innovation, Imagination, Interaction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#data-handling" id="toc-data-handling" class="nav-link" data-scroll-target="#data-handling"><span class="header-section-number">8.1</span> Data Handling</a>
  <ul class="collapse">
  <li><a href="#dataset-overview" id="toc-dataset-overview" class="nav-link" data-scroll-target="#dataset-overview"><span class="header-section-number">8.1.1</span> Dataset Overview</a></li>
  <li><a href="#download-dataset" id="toc-download-dataset" class="nav-link" data-scroll-target="#download-dataset"><span class="header-section-number">8.1.2</span> Download Dataset</a></li>
  <li><a href="#visualize-the-raw-data" id="toc-visualize-the-raw-data" class="nav-link" data-scroll-target="#visualize-the-raw-data"><span class="header-section-number">8.1.3</span> Visualize the Raw Data</a></li>
  <li><a href="#build-a-custom-pytorch-dataset" id="toc-build-a-custom-pytorch-dataset" class="nav-link" data-scroll-target="#build-a-custom-pytorch-dataset"><span class="header-section-number">8.1.4</span> Build a Custom PyTorch Dataset</a></li>
  <li><a href="#test-the-custom-dataset" id="toc-test-the-custom-dataset" class="nav-link" data-scroll-target="#test-the-custom-dataset"><span class="header-section-number">8.1.5</span> Test the Custom Dataset</a></li>
  <li><a href="#define-data-transforms-and-dataloaders" id="toc-define-data-transforms-and-dataloaders" class="nav-link" data-scroll-target="#define-data-transforms-and-dataloaders"><span class="header-section-number">8.1.6</span> Define Data Transforms and DataLoaders</a></li>
  </ul></li>
  <li><a href="#model-definition" id="toc-model-definition" class="nav-link" data-scroll-target="#model-definition"><span class="header-section-number">8.2</span> Model Definition</a></li>
  <li><a href="#loss-function" id="toc-loss-function" class="nav-link" data-scroll-target="#loss-function"><span class="header-section-number">8.3</span> Loss Function</a></li>
  <li><a href="#optimization-algorithm" id="toc-optimization-algorithm" class="nav-link" data-scroll-target="#optimization-algorithm"><span class="header-section-number">8.4</span> Optimization Algorithm</a></li>
  <li><a href="#training-and-evaluation-loop" id="toc-training-and-evaluation-loop" class="nav-link" data-scroll-target="#training-and-evaluation-loop"><span class="header-section-number">8.5</span> Training and Evaluation Loop</a>
  <ul class="collapse">
  <li><a href="#train-the-model" id="toc-train-the-model" class="nav-link" data-scroll-target="#train-the-model"><span class="header-section-number">8.5.1</span> Train the Model</a></li>
  </ul></li>
  <li><a href="#inference-making-predictions" id="toc-inference-making-predictions" class="nav-link" data-scroll-target="#inference-making-predictions"><span class="header-section-number">8.6</span> Inference (Making Predictions)</a></li>
  <li><a href="#visualization" id="toc-visualization" class="nav-link" data-scroll-target="#visualization"><span class="header-section-number">8.7</span> Visualization</a></li>
  <li><a href="#conclusion-next-steps" id="toc-conclusion-next-steps" class="nav-link" data-scroll-target="#conclusion-next-steps"><span class="header-section-number">8.8</span> Conclusion &amp; Next Steps</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../sections/the-building-blocks-of-nn-and-dl.html"><b>Day 2: AI Fundamentals and Techniques</b></a></li><li class="breadcrumb-item"><a href="../sections/hands-on-lab-pytorch.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Hands-On Lab: PyTorch</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Hands-On Lab: PyTorch</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>Welcome! This hands-on lab session offers practical experience with PyTorch for building, training, and evaluating neural network models.</p>
<p>Following the concepts covered in the lecture (<strong>Tensors</strong>, <strong>Autograd</strong>, <strong>Data</strong>, <strong>Models</strong>, <strong>Loss</strong>, <strong>Optimizers</strong>, <strong>Training</strong>), you’ll work with a sample dataset, load a pre-trained model, and fine-tune it for a classification task.</p>
<p>Don’t worry if things seem complex at first – the goal is to get hands-on experience. Feel free to experiment with the code! Let’s get started!</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>You can access the Jupyter notebook for this hands-on lab on <a href="https://colab.research.google.com/drive/1HfWEZFr4tAFc5ZV4FoGhZvWINmuzFIlF?usp=sharing">Google Colab</a>.</p>
<p>Feel free to experiment with the code, but if you want to save your work, you need to make a copy to your Google Drive (<code>"File" -&gt; "Save a copy in Drive"</code>) in order to save it.</p>
</div>
</div>
</section>
<section id="data-handling" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="data-handling"><span class="header-section-number">8.1</span> Data Handling</h2>
<p>As discussed in the lecture, handling data efficiently is crucial. We’ll use PyTorch’s <code>Dataset</code> and <code>DataLoader</code> classes, along with <code>transforms</code>, to manage our dataset.</p>
<section id="dataset-overview" class="level3" data-number="8.1.1">
<h3 data-number="8.1.1" class="anchored" data-anchor-id="dataset-overview"><span class="header-section-number">8.1.1</span> Dataset Overview</h3>
<p>In this lab, we’ll use a sample RTS (Retrogressive Thaw Slumps) dataset from Dr.&nbsp;Yili Yang’s <a href="https://www.sciencedirect.com/science/article/pii/S0034425723000469">research work</a>.</p>
<p>While originally for semantic segmentation, we’ll adapt it for classification.</p>
<p><strong>Goal:</strong> Classify the number of RTS (1 to 10) present in each image.</p>
<p><strong>Dataset Structure:</strong></p>
<pre><code>cyber2a/
│--- rts/
│    │--- images/  # Folder containing RGB images
│    │    │--- train_nitze_000.jpg
│    │    │--- ...
│--- data_split.json  # Specifies train/valtest splits
│--- rts_cls.json     # Maps image filenames to RTS counts (labels)
│--- rts_coco.json    # (Optional) Contains segmentation annotations</code></pre>
<ul>
<li><code>data_split.json</code>: A dictionary with two keys: <code>train</code> and <code>valtest</code>:
<ul>
<li><code>train</code>: A list of image filenames for training.</li>
<li><code>valtest</code>: A list of image filenames for validation and testing.</li>
</ul></li>
<li><code>rts_cls.json</code>: A dictionary with image filenames as keys and the number of RTS in each image as values.</li>
</ul>
</section>
<section id="download-dataset" class="level3" data-number="8.1.2">
<h3 data-number="8.1.2" class="anchored" data-anchor-id="download-dataset"><span class="header-section-number">8.1.2</span> Download Dataset</h3>
<p>First, let’s download and unzip the dataset.</p>
<p>These commands use <code>wget</code> and <code>unzip</code>, common utilities in Colab/Linux environments.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the dataset (using wget for compatibility)</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Downloading and extracting dataset..."</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>wget <span class="op">-</span>O <span class="st">"cyber2a.zip"</span> https:<span class="op">//</span>www.dropbox.com<span class="op">/</span>scl<span class="op">/</span>fi<span class="op">/</span><span class="dv">1</span><span class="er">pz52tq3puomi0185ccyq</span><span class="op">/</span>cyber2a.<span class="bu">zip</span>?rlkey<span class="op">=</span><span class="dv">3</span><span class="er">dgf4gfrj9yk1k4p2znn9grso</span><span class="op">&amp;</span>st<span class="op">=</span>bapbt1bq<span class="op">&amp;</span>dl<span class="op">=</span><span class="dv">0</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Unzipping dataset..."</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>unzip <span class="op">-</span>o cyber2a.<span class="bu">zip</span> <span class="op">-</span>d . <span class="op">&gt;</span> <span class="op">/</span>dev<span class="op">/</span>null <span class="co"># Redirect verbose output</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Dataset downloaded and extracted."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Output
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/cyber2a-course/cyber2a-course/sections/hands-on-lab-pytorch.ipynb" data-notebook-title="Introduction: Welcome to the Hands-On Lab!" data-notebook-cellid="cell-Download-Dataset">
<div id="download-dataset" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="6726da55-3a3c-4e3f-ef26-d5d7ee9ab29d" data-execution_count="1">
<div class="cell-output cell-output-stdout">
<pre><code>Downloading and extracting dataset...
--2025-05-06 14:19:21--  https://www.dropbox.com/scl/fi/1pz52tq3puomi0185ccyq/cyber2a.zip?rlkey=3dgf4gfrj9yk1k4p2znn9grso
Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.18, 2620:100:6016:18::a27d:112
Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.18|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://uc5729ed030391453abdb4ec7943.dl.dropboxusercontent.com/cd/0/inline/CpIwMysGXSmUYnJ3yA9cnJexOMujzvbpYd4t08AlxfLTAPP7ArE73CDD6mFz63uiTIUx4S0tC9MaQlc738uD9PA_avJytNAk10f6H9YdYkDWLy9IZryD9VnkbdAP1HN2-1_1W2QwBRVa454svSIWDyKD/file# [following]
--2025-05-06 14:19:21--  https://uc5729ed030391453abdb4ec7943.dl.dropboxusercontent.com/cd/0/inline/CpIwMysGXSmUYnJ3yA9cnJexOMujzvbpYd4t08AlxfLTAPP7ArE73CDD6mFz63uiTIUx4S0tC9MaQlc738uD9PA_avJytNAk10f6H9YdYkDWLy9IZryD9VnkbdAP1HN2-1_1W2QwBRVa454svSIWDyKD/file
Resolving uc5729ed030391453abdb4ec7943.dl.dropboxusercontent.com (uc5729ed030391453abdb4ec7943.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f
Connecting to uc5729ed030391453abdb4ec7943.dl.dropboxusercontent.com (uc5729ed030391453abdb4ec7943.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: /cd/0/inline2/CpJyJsdmpiCC2vMm97SMNW-sDvEYgsFy0MlO1AFcXxeg_mZF8FVcLF4LYs5Z37c1Epljm5eO1bN4dm5Z0KcUZJg3eEdDTIXhRIo1UxgB4tt3oRJP4FkOwjQL4ScBANxBm-jZWwQFgPYFFbLzpFLOuINRt4rxF_BPThVzWHtkZtiVkcNuupCFnS2FN8Lrv0TAlJXYXvxFWH1cwZjsm-jx_30ctPK2uGCvsl2NxVpg2HD7ArJ_jPef73z94JsoSygEkoJxMhH_LpnLiJIxxtvzQYj903HJtChhd8c_4SPwJ2mUDZLINJA-2FyRofzLUB9db6iEadGtbF4ofadhPqYmvuoY2zmtDAG-g9eW9QeoJ2J_BQ56Sa91NOKIuT4J8aUbpkQ/file [following]
--2025-05-06 14:19:22--  https://uc5729ed030391453abdb4ec7943.dl.dropboxusercontent.com/cd/0/inline2/CpJyJsdmpiCC2vMm97SMNW-sDvEYgsFy0MlO1AFcXxeg_mZF8FVcLF4LYs5Z37c1Epljm5eO1bN4dm5Z0KcUZJg3eEdDTIXhRIo1UxgB4tt3oRJP4FkOwjQL4ScBANxBm-jZWwQFgPYFFbLzpFLOuINRt4rxF_BPThVzWHtkZtiVkcNuupCFnS2FN8Lrv0TAlJXYXvxFWH1cwZjsm-jx_30ctPK2uGCvsl2NxVpg2HD7ArJ_jPef73z94JsoSygEkoJxMhH_LpnLiJIxxtvzQYj903HJtChhd8c_4SPwJ2mUDZLINJA-2FyRofzLUB9db6iEadGtbF4ofadhPqYmvuoY2zmtDAG-g9eW9QeoJ2J_BQ56Sa91NOKIuT4J8aUbpkQ/file
Reusing existing connection to uc5729ed030391453abdb4ec7943.dl.dropboxusercontent.com:443.
HTTP request sent, awaiting response... 200 OK
Length: 15860057 (15M) [application/zip]
Saving to: ‘cyber2a.zip’

cyber2a.zip         100%[===================&gt;]  15.12M  --.-KB/s    in 0.1s    

2025-05-06 14:19:22 (142 MB/s) - ‘cyber2a.zip’ saved [15860057/15860057]

Unzipping dataset...
Dataset downloaded and extracted.</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="visualize-the-raw-data" class="level3" data-number="8.1.3">
<h3 data-number="8.1.3" class="anchored" data-anchor-id="visualize-the-raw-data"><span class="header-section-number">8.1.3</span> Visualize the Raw Data</h3>
<p>Let’s take a look at a sample image and its label directly from the files before we create our PyTorch Dataset. This helps understand the raw data format.</p>
<p>We will display the original image and the image with segmentation overlays (if aavilable) side-by-side for context, although our model will only perform classification.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2  <span class="co"># OpenCV for drawing polygons</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np  <span class="co"># NumPy for image array manipulation</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Visualizing a raw data sample: original and with segmentation overlay..."</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the directory where images are stored and path to COCO annotations</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>img_dir <span class="op">=</span> <span class="st">"cyber2a/rts/images/"</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>coco_file_path <span class="op">=</span> <span class="st">"cyber2a/rts_coco.json"</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data split file to get lists of training and validation/test images</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(<span class="st">"cyber2a/data_split.json"</span>, <span class="st">'r'</span>) <span class="im">as</span> f:</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        data_split <span class="op">=</span> json.load(f)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">FileNotFoundError</span>:</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Error: data_split.json not found. Make sure the dataset extracted correctly."</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    data_split <span class="op">=</span> {} <span class="co"># Ensure data_split exists</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Retrieve the list of training images</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>img_list <span class="op">=</span> data_split.get(<span class="st">"train"</span>, []) <span class="co"># Use .get for safer dictionary access</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> img_list:</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Warning: No training images found in data_split.json."</span>)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the image labels (RTS counts)</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>img_labels <span class="op">=</span> {} <span class="co"># Initialize</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(<span class="st">"cyber2a/rts_cls.json"</span>, <span class="st">'r'</span>) <span class="im">as</span> f:</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>        img_labels <span class="op">=</span> json.load(f)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">FileNotFoundError</span>:</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Error: rts_cls.json not found."</span>)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Load COCO annotations for drawing segmentation ---</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>coco_data <span class="op">=</span> {} <span class="co"># To store loaded coco image_id_map and annotation_map</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(coco_file_path, <span class="st">"r"</span>) <span class="im">as</span> f:</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>        rts_coco_json <span class="op">=</span> json.load(f)</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>    image_id_map <span class="op">=</span> {img_info[<span class="st">'file_name'</span>]: img_info[<span class="st">'id'</span>] <span class="cf">for</span> img_info <span class="kw">in</span> rts_coco_json.get(<span class="st">'images'</span>, [])}</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>    coco_data[<span class="st">'image_id_map'</span>] <span class="op">=</span> image_id_map</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>    annotation_map <span class="op">=</span> {}</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> ann <span class="kw">in</span> rts_coco_json.get(<span class="st">'annotations'</span>, []):</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>        img_id <span class="op">=</span> ann[<span class="st">'image_id'</span>]</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> img_id <span class="kw">not</span> <span class="kw">in</span> annotation_map:</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>            annotation_map[img_id] <span class="op">=</span> []</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">'segmentation'</span> <span class="kw">in</span> ann <span class="kw">and</span> ann[<span class="st">'segmentation'</span>]:</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>            annotation_map[img_id].append(ann[<span class="st">'segmentation'</span>])</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>    coco_data[<span class="st">'annotation_map'</span>] <span class="op">=</span> annotation_map</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_id_map <span class="kw">and</span> annotation_map:</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"COCO segmentation annotations loaded successfully for visualization."</span>)</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"COCO segmentation annotations loaded, but parts might be empty (e.g. no images or no annotations)."</span>)</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">FileNotFoundError</span>:</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Warning: Segmentation annotation file '</span><span class="sc">{</span>coco_file_path<span class="sc">}</span><span class="ss">' not found. Cannot display segmentation overlays."</span>)</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> json.JSONDecodeError:</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Warning: Error decoding JSON from '</span><span class="sc">{</span>coco_file_path<span class="sc">}</span><span class="ss">'. Cannot display segmentation overlays."</span>)</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Warning: An unexpected error occurred while loading COCO annotations from '</span><span class="sc">{</span>coco_file_path<span class="sc">}</span><span class="ss">': </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a><span class="co"># --- End COCO annotation loading ---</span></span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> img_list:</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>    img_name <span class="op">=</span> img_list[<span class="dv">0</span>]</span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>    img_label_count <span class="op">=</span> img_labels.get(img_name, <span class="st">"N/A"</span>)</span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Displaying Image: </span><span class="sc">{</span>img_name<span class="sc">}</span><span class="ss">, Original RTS Count: </span><span class="sc">{</span>img_label_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a>    img_path <span class="op">=</span> os.path.join(img_dir, img_name)</span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a>        pil_image <span class="op">=</span> Image.<span class="bu">open</span>(img_path).convert(<span class="st">"RGB"</span>)</span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a>        label_index <span class="op">=</span> <span class="st">"N/A"</span></span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> img_label_count <span class="op">!=</span> <span class="st">"N/A"</span>:</span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a>                label_index <span class="op">=</span> <span class="bu">int</span>(img_label_count) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a>            <span class="cf">except</span> <span class="pp">ValueError</span>:</span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Warning: Could not convert label_count '</span><span class="sc">{</span>img_label_count<span class="sc">}</span><span class="ss">' to int for </span><span class="sc">{</span>img_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a>                label_index <span class="op">=</span> <span class="st">"Error"</span></span>
<span id="cb4-82"><a href="#cb4-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-83"><a href="#cb4-83" aria-hidden="true" tabindex="-1"></a>        fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">7</span>)) <span class="co"># 1 row, 2 columns</span></span>
<span id="cb4-84"><a href="#cb4-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-85"><a href="#cb4-85" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- Display original image (left subplot) ---</span></span>
<span id="cb4-86"><a href="#cb4-86" aria-hidden="true" tabindex="-1"></a>        axs[<span class="dv">0</span>].imshow(pil_image)</span>
<span id="cb4-87"><a href="#cb4-87" aria-hidden="true" tabindex="-1"></a>        axs[<span class="dv">0</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb4-88"><a href="#cb4-88" aria-hidden="true" tabindex="-1"></a>        axs[<span class="dv">0</span>].set_title(<span class="st">"Original Image"</span>)</span>
<span id="cb4-89"><a href="#cb4-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-90"><a href="#cb4-90" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- Prepare image for annotations (right subplot) ---</span></span>
<span id="cb4-91"><a href="#cb4-91" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert PIL image to NumPy array. np.array() typically creates a copy.</span></span>
<span id="cb4-92"><a href="#cb4-92" aria-hidden="true" tabindex="-1"></a>        image_for_overlay <span class="op">=</span> np.array(pil_image)</span>
<span id="cb4-93"><a href="#cb4-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-94"><a href="#cb4-94" aria-hidden="true" tabindex="-1"></a>        annotations_drawn_successfully <span class="op">=</span> <span class="va">False</span></span>
<span id="cb4-95"><a href="#cb4-95" aria-hidden="true" tabindex="-1"></a>        annotation_status_message <span class="op">=</span> <span class="st">"(Segmentation Annotations Not Loaded)"</span></span>
<span id="cb4-96"><a href="#cb4-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-97"><a href="#cb4-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> coco_data.get(<span class="st">'image_id_map'</span>) <span class="kw">and</span> coco_data.get(<span class="st">'annotation_map'</span>):</span>
<span id="cb4-98"><a href="#cb4-98" aria-hidden="true" tabindex="-1"></a>            annotation_status_message <span class="op">=</span> <span class="st">"(No Segmentation Overlay for this Image)"</span> <span class="co"># Default if COCO loaded but no annot.</span></span>
<span id="cb4-99"><a href="#cb4-99" aria-hidden="true" tabindex="-1"></a>            image_id_map <span class="op">=</span> coco_data[<span class="st">'image_id_map'</span>]</span>
<span id="cb4-100"><a href="#cb4-100" aria-hidden="true" tabindex="-1"></a>            annotation_map <span class="op">=</span> coco_data[<span class="st">'annotation_map'</span>]</span>
<span id="cb4-101"><a href="#cb4-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-102"><a href="#cb4-102" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> img_name <span class="kw">in</span> image_id_map:</span>
<span id="cb4-103"><a href="#cb4-103" aria-hidden="true" tabindex="-1"></a>                current_image_id <span class="op">=</span> image_id_map[img_name]</span>
<span id="cb4-104"><a href="#cb4-104" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> current_image_id <span class="kw">in</span> annotation_map:</span>
<span id="cb4-105"><a href="#cb4-105" aria-hidden="true" tabindex="-1"></a>                    segmentations_for_image <span class="op">=</span> annotation_map[current_image_id]</span>
<span id="cb4-106"><a href="#cb4-106" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> segmentations_for_image:</span>
<span id="cb4-107"><a href="#cb4-107" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">for</span> ann_segmentation_list <span class="kw">in</span> segmentations_for_image:</span>
<span id="cb4-108"><a href="#cb4-108" aria-hidden="true" tabindex="-1"></a>                            <span class="cf">for</span> polygon_coords <span class="kw">in</span> ann_segmentation_list:</span>
<span id="cb4-109"><a href="#cb4-109" aria-hidden="true" tabindex="-1"></a>                                <span class="cf">try</span>:</span>
<span id="cb4-110"><a href="#cb4-110" aria-hidden="true" tabindex="-1"></a>                                    polygon <span class="op">=</span> np.array(polygon_coords, dtype<span class="op">=</span>np.int32).reshape((<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb4-111"><a href="#cb4-111" aria-hidden="true" tabindex="-1"></a>                                    <span class="co"># Draw on the NumPy array copy</span></span>
<span id="cb4-112"><a href="#cb4-112" aria-hidden="true" tabindex="-1"></a>                                    cv2.polylines(image_for_overlay, [polygon], isClosed<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), thickness<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb4-113"><a href="#cb4-113" aria-hidden="true" tabindex="-1"></a>                                    annotations_drawn_successfully <span class="op">=</span> <span class="va">True</span></span>
<span id="cb4-114"><a href="#cb4-114" aria-hidden="true" tabindex="-1"></a>                                <span class="cf">except</span> <span class="pp">ValueError</span> <span class="im">as</span> ve:</span>
<span id="cb4-115"><a href="#cb4-115" aria-hidden="true" tabindex="-1"></a>                                    <span class="bu">print</span>(<span class="ss">f"Warning: Malformed polygon coordinates for </span><span class="sc">{</span>img_name<span class="sc">}</span><span class="ss">. Details: </span><span class="sc">{</span>ve<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-116"><a href="#cb4-116" aria-hidden="true" tabindex="-1"></a>                                <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb4-117"><a href="#cb4-117" aria-hidden="true" tabindex="-1"></a>                                    <span class="bu">print</span>(<span class="ss">f"Warning: Could not draw a polygon for </span><span class="sc">{</span>img_name<span class="sc">}</span><span class="ss">. Details: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-118"><a href="#cb4-118" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">if</span> annotations_drawn_successfully:</span>
<span id="cb4-119"><a href="#cb4-119" aria-hidden="true" tabindex="-1"></a>                             annotation_status_message <span class="op">=</span> <span class="st">"(Segmentation Overlay Shown)"</span></span>
<span id="cb4-120"><a href="#cb4-120" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">else</span>: <span class="co"># Annotations existed but none could be drawn</span></span>
<span id="cb4-121"><a href="#cb4-121" aria-hidden="true" tabindex="-1"></a>                            annotation_status_message <span class="op">=</span> <span class="st">"(Error Drawing Segmentation Overlay)"</span></span>
<span id="cb4-122"><a href="#cb4-122" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">else</span>: <span class="co"># No segmentations listed for this image_id</span></span>
<span id="cb4-123"><a href="#cb4-123" aria-hidden="true" tabindex="-1"></a>                        <span class="co"># print(f"No segmentation data found for image ID {current_image_id} ({img_name}) in annotation_map.")</span></span>
<span id="cb4-124"><a href="#cb4-124" aria-hidden="true" tabindex="-1"></a>                        annotation_status_message <span class="op">=</span> <span class="st">"(No Segmentation Data for this Image)"</span></span>
<span id="cb4-125"><a href="#cb4-125" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>: <span class="co"># image_id not in annotation_map</span></span>
<span id="cb4-126"><a href="#cb4-126" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># print(f"Image ID {current_image_id} ({img_name}) not found in COCO annotation_map.")</span></span>
<span id="cb4-127"><a href="#cb4-127" aria-hidden="true" tabindex="-1"></a>                    annotation_status_message <span class="op">=</span> <span class="st">"(Image ID Not in Annotation Map)"</span></span>
<span id="cb4-128"><a href="#cb4-128" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>: <span class="co"># img_name not in image_id_map</span></span>
<span id="cb4-129"><a href="#cb4-129" aria-hidden="true" tabindex="-1"></a>                 <span class="co"># print(f"Image name '{img_name}' not found in COCO image_id_map.")</span></span>
<span id="cb4-130"><a href="#cb4-130" aria-hidden="true" tabindex="-1"></a>                 annotation_status_message <span class="op">=</span> <span class="st">"(Image Not in COCO Map)"</span></span>
<span id="cb4-131"><a href="#cb4-131" aria-hidden="true" tabindex="-1"></a>        <span class="co"># else: coco_data is empty (file not found or error during load), initial status_message applies.</span></span>
<span id="cb4-132"><a href="#cb4-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-133"><a href="#cb4-133" aria-hidden="true" tabindex="-1"></a>        axs[<span class="dv">1</span>].imshow(image_for_overlay) <span class="co"># Display the image with annotations</span></span>
<span id="cb4-134"><a href="#cb4-134" aria-hidden="true" tabindex="-1"></a>        axs[<span class="dv">1</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb4-135"><a href="#cb4-135" aria-hidden="true" tabindex="-1"></a>        axs[<span class="dv">1</span>].set_title(<span class="ss">f"Image with Overlay</span><span class="ch">\n</span><span class="sc">{</span>annotation_status_message<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-136"><a href="#cb4-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-137"><a href="#cb4-137" aria-hidden="true" tabindex="-1"></a>        fig.suptitle(<span class="ss">f"Image: </span><span class="sc">{</span>img_name<span class="sc">}</span><span class="ss"> | RTS Count (Original Label): </span><span class="sc">{</span>img_label_count<span class="sc">}</span><span class="ss"> | Model Label (0-Indexed): </span><span class="sc">{</span>label_index<span class="sc">}</span><span class="ss">"</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb4-138"><a href="#cb4-138" aria-hidden="true" tabindex="-1"></a>        plt.tight_layout(rect<span class="op">=</span>[<span class="dv">0</span>, <span class="fl">0.03</span>, <span class="dv">1</span>, <span class="fl">0.92</span>]) <span class="co"># Adjust rect for suptitle</span></span>
<span id="cb4-139"><a href="#cb4-139" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb4-140"><a href="#cb4-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-141"><a href="#cb4-141" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">FileNotFoundError</span>:</span>
<span id="cb4-142"><a href="#cb4-142" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Error: Image file </span><span class="sc">{</span>img_path<span class="sc">}</span><span class="ss"> not found."</span>)</span>
<span id="cb4-143"><a href="#cb4-143" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If image not found, try to show empty plots or a message</span></span>
<span id="cb4-144"><a href="#cb4-144" aria-hidden="true" tabindex="-1"></a>        fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">7</span>))</span>
<span id="cb4-145"><a href="#cb4-145" aria-hidden="true" tabindex="-1"></a>        axs[<span class="dv">0</span>].text(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="st">'Image not found'</span>, horizontalalignment<span class="op">=</span><span class="st">'center'</span>, verticalalignment<span class="op">=</span><span class="st">'center'</span>, transform<span class="op">=</span>axs[<span class="dv">0</span>].transAxes)</span>
<span id="cb4-146"><a href="#cb4-146" aria-hidden="true" tabindex="-1"></a>        axs[<span class="dv">1</span>].text(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="st">'Image not found'</span>, horizontalalignment<span class="op">=</span><span class="st">'center'</span>, verticalalignment<span class="op">=</span><span class="st">'center'</span>, transform<span class="op">=</span>axs[<span class="dv">1</span>].transAxes)</span>
<span id="cb4-147"><a href="#cb4-147" aria-hidden="true" tabindex="-1"></a>        axs[<span class="dv">0</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb4-148"><a href="#cb4-148" aria-hidden="true" tabindex="-1"></a>        axs[<span class="dv">1</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb4-149"><a href="#cb4-149" aria-hidden="true" tabindex="-1"></a>        fig.suptitle(<span class="ss">f"Image: </span><span class="sc">{</span>img_name<span class="sc">}</span><span class="ss"> - FILE NOT FOUND"</span>, fontsize<span class="op">=</span><span class="dv">14</span>, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb4-150"><a href="#cb4-150" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb4-151"><a href="#cb4-151" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb4-152"><a href="#cb4-152" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"An error occurred displaying the image </span><span class="sc">{</span>img_name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-153"><a href="#cb4-153" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb4-154"><a href="#cb4-154" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Cannot display sample: Training image list is empty or could not be loaded."</span>)</span>
<span id="cb4-155"><a href="#cb4-155" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Optionally, display a placeholder if no image can be shown</span></span>
<span id="cb4-156"><a href="#cb4-156" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">7</span>))</span>
<span id="cb4-157"><a href="#cb4-157" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].text(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="st">'No image selected'</span>, horizontalalignment<span class="op">=</span><span class="st">'center'</span>, verticalalignment<span class="op">=</span><span class="st">'center'</span>, transform<span class="op">=</span>axs[<span class="dv">0</span>].transAxes)</span>
<span id="cb4-158"><a href="#cb4-158" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].text(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="st">'No image selected'</span>, horizontalalignment<span class="op">=</span><span class="st">'center'</span>, verticalalignment<span class="op">=</span><span class="st">'center'</span>, transform<span class="op">=</span>axs[<span class="dv">1</span>].transAxes)</span>
<span id="cb4-159"><a href="#cb4-159" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb4-160"><a href="#cb4-160" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb4-161"><a href="#cb4-161" aria-hidden="true" tabindex="-1"></a>    fig.suptitle(<span class="st">"No image available from training list"</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb4-162"><a href="#cb4-162" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Output
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/cyber2a-course/cyber2a-course/sections/hands-on-lab-pytorch.ipynb" data-notebook-title="Introduction: Welcome to the Hands-On Lab!" data-notebook-cellid="cell-Visualize-Raw-Data">
<div id="cell-Visualize-Raw-Data" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:422}}" data-outputid="11944c31-7812-4105-cd2d-915f63bcb960" data-execution_count="2">
<div class="cell-output cell-output-stdout">
<pre><code>
Visualizing a raw data sample: original and with segmentation overlay...
COCO segmentation annotations loaded successfully for visualization.
Displaying Image: train_nitze_183.jpg, Original RTS Count: 2</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="hands-on-lab-pytorch_files/figure-html/hands-on-lab-pytorch-visualize-raw-data-output-2.png" id="visualize-raw-data" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="build-a-custom-pytorch-dataset" class="level3" data-number="8.1.4">
<h3 data-number="8.1.4" class="anchored" data-anchor-id="build-a-custom-pytorch-dataset"><span class="header-section-number">8.1.4</span> Build a Custom PyTorch Dataset</h3>
<p>As covered in the lecture, <code>torch.utils.data.Dataset</code> is the base class for representing datasets in PyTorch. We need to implement <code>__init__</code>, <code>__len__</code>, and <code>__getitem__</code>.</p>
<ul>
<li><code>__init__</code>: Initialize the dataset.</li>
<li><code>__len__</code>: Return the total number of data samples in the dataset.</li>
<li><code>__getitem__</code>: Load a data sample and its corresponding label based on the index.</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch <span class="co"># Import torch here if not already imported</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RTSDataset(Dataset):</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Custom Dataset for RTS classification."""</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, split, transform<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">            split (str): One of 'train' or 'valtest' to specify the dataset split.</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co">            transform (callable, optional): Optional transform to be applied on a sample.</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co">                                           As discussed in the lecture, transforms</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co">                                           preprocess or augment the data.</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.img_dir <span class="op">=</span> <span class="st">"cyber2a/rts/images/"</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Load image filenames based on the split</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> <span class="bu">open</span>(<span class="st">"cyber2a/data_split.json"</span>) <span class="im">as</span> f:</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>                data_split <span class="op">=</span> json.load(f)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> split <span class="op">==</span> <span class="st">'train'</span>:</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.img_list <span class="op">=</span> data_split[<span class="st">'train'</span>]</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> split <span class="op">==</span> <span class="st">'valtest'</span>:</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.img_list <span class="op">=</span> data_split[<span class="st">'valtest'</span>]</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>                <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Invalid split: choose either 'train' or 'valtest'"</span>)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">FileNotFoundError</span>:</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Error: data_split.json not found."</span>)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.img_list <span class="op">=</span> [] <span class="co"># Initialize as empty list on error</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">KeyError</span>:</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Error: Split '</span><span class="sc">{</span>split<span class="sc">}</span><span class="ss">' not found in data_split.json."</span>)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.img_list <span class="op">=</span> []</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Load image labels (RTS counts)</span></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> <span class="bu">open</span>(<span class="st">"cyber2a/rts_cls.json"</span>) <span class="im">as</span> f:</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.img_labels <span class="op">=</span> json.load(f)</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">FileNotFoundError</span>:</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Error: rts_cls.json not found."</span>)</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.img_labels <span class="op">=</span> {} <span class="co"># Initialize as empty dict on error</span></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Initialized RTSDataset for '</span><span class="sc">{</span>split<span class="sc">}</span><span class="ss">' split with </span><span class="sc">{</span><span class="bu">len</span>(<span class="va">self</span>.img_list)<span class="sc">}</span><span class="ss"> images."</span>)</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Returns the total number of samples in the dataset."""</span></span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.img_list)</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a><span class="co">        Retrieves the image and its label at the given index `idx`.</span></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a><span class="co">        This is where data loading and transformation happen for a single sample.</span></span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a><span class="co">            idx (int): Index of the sample to retrieve.</span></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a><span class="co">            tuple: (image, label) where image is the transformed image tensor</span></span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a><span class="co">                   and label is the 0-indexed integer label.</span></span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="op">&gt;=</span> <span class="bu">len</span>(<span class="va">self</span>.img_list):</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">IndexError</span>(<span class="st">"Index out of bounds"</span>)</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>        img_name <span class="op">=</span> <span class="va">self</span>.img_list[idx]</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>        img_path <span class="op">=</span> os.path.join(<span class="va">self</span>.img_dir, img_name)</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Load image using PIL</span></span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>            image <span class="op">=</span> Image.<span class="bu">open</span>(img_path).convert(<span class="st">'RGB'</span>)</span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">FileNotFoundError</span>:</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Warning: Image file not found at </span><span class="sc">{</span>img_path<span class="sc">}</span><span class="ss">. Returning None."</span>)</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Or handle differently, e.g., return a placeholder or skip</span></span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">None</span>, <span class="va">None</span></span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Warning: Error loading image </span><span class="sc">{</span>img_path<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">. Returning None."</span>)</span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">None</span>, <span class="va">None</span></span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the label (RTS count) and convert to 0-indexed integer</span></span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a>        label_count <span class="op">=</span> <span class="va">self</span>.img_labels.get(img_name)</span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> label_count <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Warning: Label not found for image </span><span class="sc">{</span>img_name<span class="sc">}</span><span class="ss">. Assigning label -1."</span>)</span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a>            label <span class="op">=</span> <span class="op">-</span><span class="dv">1</span> <span class="co"># Or handle differently</span></span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a>            label <span class="op">=</span> <span class="bu">int</span>(label_count) <span class="op">-</span> <span class="dv">1</span> <span class="co"># 0-indexing</span></span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply transformations if they exist</span></span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.transform:</span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a>            image <span class="op">=</span> <span class="va">self</span>.transform(image)</span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert label to a tensor (optional but good practice)</span></span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Using LongTensor as CrossEntropyLoss expects integer labels</span></span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> torch.tensor(label, dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> image, label</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="test-the-custom-dataset" class="level3" data-number="8.1.5">
<h3 data-number="8.1.5" class="anchored" data-anchor-id="test-the-custom-dataset"><span class="header-section-number">8.1.5</span> Test the Custom Dataset</h3>
<p>Let’s create an instance of our <code>RTSDataset</code> and check if <code>__getitem__</code> works correctly by fetching and displaying a sample.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper function to display sample images (can handle tensors or PIL Images)</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> display_sample_images(dataset, num_images<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Displays sample images from a PyTorch Dataset."""</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, num_images, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> num_images <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        axs <span class="op">=</span> [axs] <span class="co"># Make it iterable if only one image</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_images):</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">&gt;=</span> <span class="bu">len</span>(dataset):</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Requested image index </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> out of bounds for dataset size </span><span class="sc">{</span><span class="bu">len</span>(dataset)<span class="sc">}</span><span class="ss">."</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        img, label <span class="op">=</span> dataset[i]</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> img <span class="kw">is</span> <span class="va">None</span>: <span class="co"># Handle cases where __getitem__ returned None</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>             <span class="bu">print</span>(<span class="ss">f"Skipping display for index </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">, image data is None."</span>)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>             <span class="cf">if</span> num_images <span class="op">==</span> <span class="dv">1</span>: axs[i].set_title(<span class="st">"Image Load Error"</span>)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>             <span class="cf">continue</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If the dataset applies transforms (including ToTensor),</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># the image will be a Tensor. We need to convert it back for display.</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(img, torch.Tensor):</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Undo normalization and convert C x H x W to H x W x C</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>            mean <span class="op">=</span> torch.tensor([<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>]).view(<span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>            std <span class="op">=</span> torch.tensor([<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>]).view(<span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> img <span class="op">*</span> std <span class="op">+</span> mean <span class="co"># Unnormalize</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> img.permute(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>) <span class="co"># C x H x W -&gt; H x W x C</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> img.clamp(<span class="dv">0</span>, <span class="dv">1</span>) <span class="co"># Ensure values are in [0, 1] range</span></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>            img <span class="op">=</span> img.numpy() <span class="co"># Convert to NumPy array</span></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>        axs[i].imshow(img)</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        axs[i].set_title(<span class="ss">f"Sample </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> - Label: </span><span class="sc">{</span>label<span class="sc">.</span>item() <span class="cf">if</span> <span class="bu">isinstance</span>(label, torch.Tensor) <span class="cf">else</span> label<span class="sc">}</span><span class="ss">"</span>) <span class="co"># Use .item() to get scalar from tensor</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>        axs[i].axis(<span class="st">"off"</span>)</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the training dataset *without* transforms first to see raw images</span></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>    raw_train_dataset <span class="op">=</span> RTSDataset(<span class="st">"train"</span>, transform<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(raw_train_dataset) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>         <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Displaying raw samples from dataset:"</span>)</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>         display_sample_images(raw_train_dataset, num_images<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Raw train dataset is empty, cannot display samples."</span>)</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Error creating/displaying raw dataset: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Output
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/cyber2a-course/cyber2a-course/sections/hands-on-lab-pytorch.ipynb" data-notebook-title="Introduction: Welcome to the Hands-On Lab!" data-notebook-cellid="cell-Test-Custom-Dataset">
<div id="cell-Test-Custom-Dataset" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:271}}" data-outputid="86174bcc-f494-4ded-ad22-d730c243fc4f" data-execution_count="4">
<div class="cell-output cell-output-stdout">
<pre><code>Initialized RTSDataset for 'train' split with 756 images.

Displaying raw samples from dataset:</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="hands-on-lab-pytorch_files/figure-html/hands-on-lab-pytorch-test-custom-dataset-output-2.png" id="test-custom-dataset" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="define-data-transforms-and-dataloaders" class="level3" data-number="8.1.6">
<h3 data-number="8.1.6" class="anchored" data-anchor-id="define-data-transforms-and-dataloaders"><span class="header-section-number">8.1.6</span> Define Data Transforms and DataLoaders</h3>
<p>Now, let’s define the transformations we want to apply to our images.</p>
<p>As discussed in the lecture, these are crucial for preparing data for the model.</p>
<p>We’ll then create <code>DataLoaders</code> to handle batching and shuffling.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> T</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Defining transforms and dataloaders..."</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the transformations:</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Resize: Ensure all images have the same size, required by many models.</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co">#            ResNet-18 (and many ImageNet models) often expect 224x224 or 256x256.</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. ToTensor: Converts PIL Image (H x W x C) [0, 255] to PyTorch Tensor (C x H x W) [0.0, 1.0].</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co">#              This also automatically moves channel dimension first. Crucial step!</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Normalize: Standardizes pixel values using mean and standard deviation.</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co">#               Using ImageNet stats is common practice when using pre-trained models,</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co">#               as it matches the data the model was originally trained on.</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co">#               Helps with model convergence.</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> T.Compose([</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    T.Resize((<span class="dv">256</span>, <span class="dv">256</span>)),</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    T.ToTensor(),</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    T.Normalize(mean<span class="op">=</span>[<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>], std<span class="op">=</span>[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>]),</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Practice Idea ---</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Try adding data augmentation transforms for the training set!</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Uncomment and modify the transform_train below. Remember to only use</span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="co"># augmentation for the training set, not validation/testing.</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a><span class="co"># transform_train = T.Compose([</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a><span class="co">#     T.Resize((256, 256)),</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a><span class="co">#     T.RandomHorizontalFlip(p=0.5), # Example augmentation</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a><span class="co">#     T.RandomRotation(10),         # Example augmentation</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a><span class="co">#     T.ToTensor(),</span></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a><span class="co">#     T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),</span></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a><span class="co"># ])</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a><span class="co"># train_dataset = RTSDataset("train", transform=transform_train) # Use augmented transform</span></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------</span></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the training and validation datasets *with* transforms</span></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>    train_dataset <span class="op">=</span> RTSDataset(<span class="st">"train"</span>, transform<span class="op">=</span>transform)</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>    val_dataset <span class="op">=</span> RTSDataset(<span class="st">"valtest"</span>, transform<span class="op">=</span>transform)</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display transformed samples to check</span></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(train_dataset) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Displaying transformed samples from training dataset:"</span>)</span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>        display_sample_images(train_dataset, num_images<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Train dataset is empty, cannot display transformed samples."</span>)</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create DataLoaders (Lecture Topic: DataLoader)</span></span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># - `dataset`: The Dataset object to load from.</span></span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># - `batch_size`: How many samples per batch. Affects memory and training dynamics.</span></span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># - `shuffle`: Whether to shuffle data every epoch (True for training is crucial!).</span></span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># - `num_workers`: Number of subprocesses for data loading. Increases speed but uses more memory. Start with 0 or 2.</span></span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>    train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span><span class="dv">4</span>, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>    val_loader <span class="op">=</span> DataLoader(val_dataset, batch_size<span class="op">=</span><span class="dv">4</span>, shuffle<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">2</span>) <span class="co"># No shuffle for validation</span></span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">DataLoaders created."</span>)</span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Optional: Iterate over one batch to see the output shape</span></span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a>        dataiter <span class="op">=</span> <span class="bu">iter</span>(train_loader)</span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a>        images, labels <span class="op">=</span> <span class="bu">next</span>(dataiter)</span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Sample batch - Images shape: </span><span class="sc">{</span>images<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, Labels shape: </span><span class="sc">{</span>labels<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">StopIteration</span>:</span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Could not fetch a batch from train_loader (it might be empty)."</span>)</span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>         <span class="bu">print</span>(<span class="ss">f"Error iterating over DataLoader: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"An error occurred during Dataset/DataLoader creation: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Output
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/cyber2a-course/cyber2a-course/sections/hands-on-lab-pytorch.ipynb" data-notebook-title="Introduction: Welcome to the Hands-On Lab!" data-notebook-cellid="cell-Define-Data-Transforms-and-DataLoaders">
<div id="cell-Define-Data-Transforms-and-DataLoaders" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:521}}" data-outputid="c12dfb62-251f-4574-b6f1-9da76653a9ce" data-execution_count="5">
<div class="cell-output cell-output-stdout">
<pre><code>
Defining transforms and dataloaders...
Initialized RTSDataset for 'train' split with 756 images.
Initialized RTSDataset for 'valtest' split with 138 images.

Displaying transformed samples from training dataset:</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="hands-on-lab-pytorch_files/figure-html/hands-on-lab-pytorch-define-data-transforms-and-dataloaders-output-2.png" id="define-data-transforms-and-dataloaders" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
DataLoaders created.
Sample batch - Images shape: torch.Size([4, 3, 256, 256]), Labels shape: torch.Size([4])</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="model-definition" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="model-definition"><span class="header-section-number">8.2</span> Model Definition</h2>
<p>As covered in the lecture, we often don’t need to train models from scratch.</p>
<p>We can use <strong>Transfer Learning</strong> by loading a <strong>Pre-trained Model</strong> (like ResNet-18 trained on ImageNet) and adapting its final layer for our specific task.</p>
<p>We’ll use <code>torchvision.models</code> for this. Remember that the core building block for models in PyTorch is <code>nn.Module</code>.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> models</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn <span class="co"># Import the neural network module</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Loading pre-trained ResNet-18 model..."</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the pre-trained ResNet-18 model.</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co"># `weights=ResNet18_Weights.DEFAULT` automatically fetches weights pre-trained on ImageNet.</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co"># This leverages features learned on a large dataset.</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> models.resnet18(weights<span class="op">=</span>models.resnet.ResNet18_Weights.DEFAULT)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co"># **Adapting the Model Head (Transfer Learning)**</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co"># The pre-trained ResNet-18 has a final fully connected layer (`fc`) designed</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co"># for ImageNet's 1000 classes. We need to replace it with a new layer that</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="co"># outputs scores for our 10 classes (RTS counts 1-10, which are labels 0-9).</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Get the number of input features to the original fully connected layer.</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>num_ftrs <span class="op">=</span> model.fc.in_features</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Original ResNet-18 fc layer input features: </span><span class="sc">{</span>num_ftrs<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Create a new fully connected layer (`nn.Linear`) with the correct number</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="co">#    of input features (`num_ftrs`) and the desired number of output classes (10).</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a><span class="co">#    The parameters of this new layer will be randomly initialized and trained.</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>model.fc <span class="op">=</span> nn.Linear(num_ftrs, <span class="dv">10</span>)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Replaced final fc layer for 10 output classes."</span>)</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the model architecture to observe the change in the final `fc` layer.</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a><span class="co"># print("\nModified Model Architecture:")</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a><span class="co"># print(model)</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Practice Idea ---</span></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Try loading a different pre-trained model, like ResNet-34 or MobileNetV2.</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a><span class="co"># You'll need to find the name of its final classification layer (it might not be 'fc')</span></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a><span class="co"># and replace it similarly.</span></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Example:</span></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a><span class="co"># model_mobilenet = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)</span></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a><span class="co"># print(model_mobilenet) # Inspect the layers to find the classifier name</span></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a><span class="co"># num_ftrs_mobilenet = model_mobilenet.classifier[1].in_features # Example for MobileNetV2</span></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a><span class="co"># model_mobilenet.classifier[1] = nn.Linear(num_ftrs_mobilenet, 10)</span></span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a><span class="co"># model = model_mobilenet # Use this model instead</span></span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Output
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/cyber2a-course/cyber2a-course/sections/hands-on-lab-pytorch.ipynb" data-notebook-title="Introduction: Welcome to the Hands-On Lab!" data-notebook-cellid="cell-Model-Definition">
<div id="model-definition" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="663d7fa0-60e6-4b63-cb66-9466fa6756ea" data-execution_count="6">
<div class="cell-output cell-output-stdout">
<pre><code>
Loading pre-trained ResNet-18 model...
Original ResNet-18 fc layer input features: 512
Replaced final fc layer for 10 output classes.</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="loss-function" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="loss-function"><span class="header-section-number">8.3</span> Loss Function</h2>
<p>The Loss Function measures how far the model’s predictions are from the true labels. For multi-class classification (like our 10 RTS classes), <code>CrossEntropyLoss</code> is the standard choice (as mentioned in the lecture).</p>
<p><strong>Important:</strong> <code>CrossEntropyLoss</code> expects raw scores (logits) from the model (it applies Softmax internally) and 0-indexed integer labels.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Defining Loss Function..."</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the loss function</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Using CrossEntropyLoss."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Output
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/cyber2a-course/cyber2a-course/sections/hands-on-lab-pytorch.ipynb" data-notebook-title="Introduction: Welcome to the Hands-On Lab!" data-notebook-cellid="cell-Loss-Function">
<div id="loss-function" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e1c2e2c6-f89e-4986-a74e-cf4570578b72" data-execution_count="7">
<div class="cell-output cell-output-stdout">
<pre><code>
Defining Loss Function...
Using CrossEntropyLoss.</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="optimization-algorithm" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="optimization-algorithm"><span class="header-section-number">8.4</span> Optimization Algorithm</h2>
<p>The Optimizer updates the model’s weights based on the gradients calculated during backpropagation to minimize the loss. We’ll use Stochastic Gradient Descent (SGD) with momentum, a common and effective optimizer (see lecture).</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Defining Optimizer..."</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the optimizer</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># - `model.parameters()`: Tells the optimizer which parameters to update.</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co"># - `lr`: Learning Rate - controls the step size of updates. Needs tuning.</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co"># - `momentum`: Helps accelerate SGD in the relevant direction.</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>, momentum<span class="op">=</span><span class="fl">0.9</span>)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Using SGD optimizer with lr=0.001 and momentum=0.9."</span>)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Practice Idea ---</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Try using the Adam optimizer instead. It often requires less learning rate tuning.</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="co"># optimizer = optim.Adam(model.parameters(), lr=0.001)</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co"># print("Using Adam optimizer with lr=0.001.")</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Output
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/cyber2a-course/cyber2a-course/sections/hands-on-lab-pytorch.ipynb" data-notebook-title="Introduction: Welcome to the Hands-On Lab!" data-notebook-cellid="cell-Optimization-Algorithm">
<div id="optimization-algorithm" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="c8ac17e9-9adb-44da-9bea-46a60592c73b" data-execution_count="8">
<div class="cell-output cell-output-stdout">
<pre><code>
Defining Optimizer...
Using SGD optimizer with lr=0.001 and momentum=0.9.</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="training-and-evaluation-loop" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="training-and-evaluation-loop"><span class="header-section-number">8.5</span> Training and Evaluation Loop</h2>
<p>This is where we put everything together: iterating through the data, feeding it to the model, calculating loss, backpropagating, and updating weights.</p>
<p>We’ll also evaluate on the validation set after each epoch.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm <span class="co"># tqdm provides progress bars for loops</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Defining Training and Evaluation Functions..."</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_eval_model(model, criterion, optimizer, train_loader, val_loader, num_epochs<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Trains and evaluates the model.</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co">        model (nn.Module): The model to train.</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">        criterion (nn.Module): The loss function.</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co">        optimizer (optim.Optimizer): The optimizer.</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co">        train_loader (DataLoader): DataLoader for the training data.</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co">        val_loader (DataLoader): DataLoader for the validation data.</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="co">        num_epochs (int): Number of epochs to train.</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="co">        nn.Module: The trained model.</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check for GPU availability and set device (Lecture Topic: GPU Usage)</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">"cuda:0"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Using device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>    model.to(device) <span class="co"># Move model to the chosen device</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>    best_val_acc <span class="op">=</span> <span class="fl">0.0</span> <span class="co"># Keep track of best validation accuracy</span></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>        epoch_start_time <span class="op">=</span> time.time()</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">--- Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>num_epochs<span class="sc">}</span><span class="ss"> ---"</span>)</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------------------</span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Training Phase</span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------------------</span></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>        model.train() <span class="co"># **Crucial:** Set model to training mode (enables dropout, batchnorm updates etc.)</span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>        running_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>        train_pbar <span class="op">=</span> tqdm(train_loader, desc<span class="op">=</span><span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Training"</span>)</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> inputs, labels <span class="kw">in</span> train_pbar:</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Move data to the correct device</span></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>            inputs, labels <span class="op">=</span> inputs.to(device), labels.to(device)</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>            <span class="co"># **Crucial:** Zero the parameter gradients (Lecture Topic: Optimizers)</span></span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Otherwise gradients accumulate from previous batches.</span></span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Forward pass: Get model outputs (logits)</span></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(inputs)</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute the loss</span></span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(outputs, labels)</span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Backward pass: Compute gradients of the loss w.r.t. parameters</span></span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update model parameters based on gradients</span></span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Statistics</span></span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a>            running_loss <span class="op">+=</span> loss.item() <span class="op">*</span> inputs.size(<span class="dv">0</span>) <span class="co"># Weighted by batch size</span></span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a>            train_pbar.set_postfix({<span class="st">'loss'</span>: loss.item()}) <span class="co"># Show current batch loss in progress bar</span></span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>        epoch_loss <span class="op">=</span> running_loss <span class="op">/</span> <span class="bu">len</span>(train_loader.dataset) <span class="co"># Average loss over dataset</span></span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Training Loss: </span><span class="sc">{</span>epoch_loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------------------</span></span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Validation Phase</span></span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------------------</span></span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()  <span class="co"># **Crucial:** Set model to evaluation mode (disables dropout, uses running BN stats)</span></span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a>        correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a>        total <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a>        val_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a>        val_pbar <span class="op">=</span> tqdm(val_loader, desc<span class="op">=</span><span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Validation"</span>)</span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a>        <span class="co"># **Crucial:** Disable gradient calculations for efficiency (Lecture Topic: Autograd / Evaluation)</span></span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> inputs, labels <span class="kw">in</span> val_pbar:</span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a>                inputs, labels <span class="op">=</span> inputs.to(device), labels.to(device)</span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Forward pass</span></span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a>                outputs <span class="op">=</span> model(inputs)</span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Calculate validation loss</span></span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> criterion(outputs, labels)</span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a>                val_loss <span class="op">+=</span> loss.item() <span class="op">*</span> inputs.size(<span class="dv">0</span>)</span>
<span id="cb18-86"><a href="#cb18-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-87"><a href="#cb18-87" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Calculate accuracy</span></span>
<span id="cb18-88"><a href="#cb18-88" aria-hidden="true" tabindex="-1"></a>                _, predicted <span class="op">=</span> torch.<span class="bu">max</span>(outputs.data, <span class="dv">1</span>) <span class="co"># Get the index of the max logit</span></span>
<span id="cb18-89"><a href="#cb18-89" aria-hidden="true" tabindex="-1"></a>                total <span class="op">+=</span> labels.size(<span class="dv">0</span>)</span>
<span id="cb18-90"><a href="#cb18-90" aria-hidden="true" tabindex="-1"></a>                correct <span class="op">+=</span> (predicted <span class="op">==</span> labels).<span class="bu">sum</span>().item()</span>
<span id="cb18-91"><a href="#cb18-91" aria-hidden="true" tabindex="-1"></a>                val_pbar.set_postfix({<span class="st">'acc'</span>: (<span class="dv">100</span> <span class="op">*</span> correct <span class="op">/</span> total)})</span>
<span id="cb18-92"><a href="#cb18-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-93"><a href="#cb18-93" aria-hidden="true" tabindex="-1"></a>        epoch_val_loss <span class="op">=</span> val_loss <span class="op">/</span> <span class="bu">len</span>(val_loader.dataset)</span>
<span id="cb18-94"><a href="#cb18-94" aria-hidden="true" tabindex="-1"></a>        epoch_val_acc <span class="op">=</span> <span class="dv">100</span> <span class="op">*</span> correct <span class="op">/</span> total</span>
<span id="cb18-95"><a href="#cb18-95" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Validation Loss: </span><span class="sc">{</span>epoch_val_loss<span class="sc">:.4f}</span><span class="ss">, Validation Accuracy: </span><span class="sc">{</span>epoch_val_acc<span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb18-96"><a href="#cb18-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-97"><a href="#cb18-97" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Simple check for saving the best model (optional)</span></span>
<span id="cb18-98"><a href="#cb18-98" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> epoch_val_acc <span class="op">&gt;</span> best_val_acc:</span>
<span id="cb18-99"><a href="#cb18-99" aria-hidden="true" tabindex="-1"></a>            best_val_acc <span class="op">=</span> epoch_val_acc</span>
<span id="cb18-100"><a href="#cb18-100" aria-hidden="true" tabindex="-1"></a>            <span class="co"># torch.save(model.state_dict(), 'best_model.pth') # Example saving</span></span>
<span id="cb18-101"><a href="#cb18-101" aria-hidden="true" tabindex="-1"></a>            <span class="co"># print("Saved new best model.")</span></span>
<span id="cb18-102"><a href="#cb18-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-103"><a href="#cb18-103" aria-hidden="true" tabindex="-1"></a>        epoch_duration <span class="op">=</span> time.time() <span class="op">-</span> epoch_start_time</span>
<span id="cb18-104"><a href="#cb18-104" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch Duration: </span><span class="sc">{</span>epoch_duration<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb18-105"><a href="#cb18-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-106"><a href="#cb18-106" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- Practice Idea ---</span></span>
<span id="cb18-107"><a href="#cb18-107" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add code here to implement early stopping. For example, if the validation</span></span>
<span id="cb18-108"><a href="#cb18-108" aria-hidden="true" tabindex="-1"></a>        <span class="co"># accuracy doesn't improve for, say, 2 epochs, stop the training loop.</span></span>
<span id="cb18-109"><a href="#cb18-109" aria-hidden="true" tabindex="-1"></a>        <span class="co"># You'll need to store the validation accuracy from the previous epoch.</span></span>
<span id="cb18-110"><a href="#cb18-110" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------------------</span></span>
<span id="cb18-111"><a href="#cb18-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-112"><a href="#cb18-112" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Finished Training."</span>)</span>
<span id="cb18-113"><a href="#cb18-113" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Output
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/cyber2a-course/cyber2a-course/sections/hands-on-lab-pytorch.ipynb" data-notebook-title="Introduction: Welcome to the Hands-On Lab!" data-notebook-cellid="cell-Training-and-Evaluation-Loop">
<div id="training-and-evaluation-loop" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="bd6dcd78-9c82-434e-bdcb-aa008de0f1f5" data-execution_count="9">
<div class="cell-output cell-output-stdout">
<pre><code>
Defining Training and Evaluation Functions...</code></pre>
</div>
</div>
</div>
</div>
</div>
<section id="train-the-model" class="level3" data-number="8.5.1">
<h3 data-number="8.5.1" class="anchored" data-anchor-id="train-the-model"><span class="header-section-number">8.5.1</span> Train the Model</h3>
<p>Let’s start the training process for a few epochs.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Starting model training..."</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure the model is on the correct device before passing to train function</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co"># (train_eval_model also moves it, but good practice to do it here too)</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># model.to(device)</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> train_eval_model(model, criterion, optimizer, train_loader, val_loader, num_epochs<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>     <span class="bu">print</span>(<span class="ss">f"An error occurred during training: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Output
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/cyber2a-course/cyber2a-course/sections/hands-on-lab-pytorch.ipynb" data-notebook-title="Introduction: Welcome to the Hands-On Lab!" data-notebook-cellid="cell-Train-the-Model">
<div id="train-the-model" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="b1417621-9442-4e4b-e0b4-234578eb9dba" data-execution_count="10">
<div class="cell-output cell-output-stdout">
<pre><code>
Starting model training...
Using device: cuda:0

--- Epoch 1/5 ---</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Training Loss: 1.7698</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Validation Loss: 1.7400, Validation Accuracy: 37.68%
Epoch Duration: 6.34 seconds

--- Epoch 2/5 ---</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Training Loss: 1.4983</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Validation Loss: 1.7676, Validation Accuracy: 38.41%
Epoch Duration: 6.26 seconds

--- Epoch 3/5 ---</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Training Loss: 1.1677</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Validation Loss: 2.4771, Validation Accuracy: 39.86%
Epoch Duration: 5.63 seconds

--- Epoch 4/5 ---</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Training Loss: 0.9606</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Validation Loss: 2.8200, Validation Accuracy: 33.33%
Epoch Duration: 6.52 seconds

--- Epoch 5/5 ---</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Training Loss: 0.8626</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Validation Loss: 2.3195, Validation Accuracy: 36.23%
Epoch Duration: 5.75 seconds

Finished Training.</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="inference-making-predictions" class="level2" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="inference-making-predictions"><span class="header-section-number">8.6</span> Inference (Making Predictions)</h2>
<p>After training, we want to use the model to predict the class (RTS count) for new, unseen images. This is the inference step. Remember to use <code>model.eval()</code> and <code>torch.no_grad()</code>.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Defining prediction function..."</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict_image(model, image_path, transform):</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Predicts the class label for a single image.</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="co">        model (nn.Module): The trained model.</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="co">        image_path (str): Path to the image file.</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="co">        transform (callable): The transformations to apply to the image.</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a><span class="co">        int: The predicted 0-indexed class label. Returns -1 on error.</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> Image.<span class="bu">open</span>(image_path).convert(<span class="st">"RGB"</span>)</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply the same transformations used during training/validation</span></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>        image_tensor <span class="op">=</span> transform(image).unsqueeze(<span class="dv">0</span>) <span class="co"># Add batch dimension</span></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ensure model and data are on the same device</span></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> <span class="bu">next</span>(model.parameters()).device</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>        image_tensor <span class="op">=</span> image_tensor.to(device)</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>() <span class="co"># Set model to evaluation mode</span></span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad(): <span class="co"># Disable gradients</span></span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(image_tensor)</span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>            _, predicted <span class="op">=</span> torch.<span class="bu">max</span>(outputs, <span class="dv">1</span>)</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>            predicted_label <span class="op">=</span> predicted.item() <span class="co"># Get the scalar value</span></span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> predicted_label</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">FileNotFoundError</span>:</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Error: Image not found at </span><span class="sc">{</span>image_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Error during prediction for </span><span class="sc">{</span>image_path<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="op">-</span><span class="dv">1</span></span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Predict a specific image from the validation set</span></span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a>img_name_to_predict <span class="op">=</span> <span class="st">"valtest_yg_070.jpg"</span> <span class="co"># Example image</span></span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a>img_dir <span class="op">=</span> <span class="st">"./cyber2a/rts/images"</span></span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a>img_path_to_predict <span class="op">=</span> os.path.join(img_dir, img_name_to_predict)</span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Predicting class for image: </span><span class="sc">{</span>img_name_to_predict<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true" tabindex="-1"></a>predicted_class <span class="op">=</span> predict_image(model, img_path_to_predict, transform)</span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> predicted_class <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb32-47"><a href="#cb32-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add 1 back to get the RTS count (since labels are 0-indexed)</span></span>
<span id="cb32-48"><a href="#cb32-48" aria-hidden="true" tabindex="-1"></a>    predicted_rts_count <span class="op">=</span> predicted_class <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb32-49"><a href="#cb32-49" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Predicted Class Index: </span><span class="sc">{</span>predicted_class<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-50"><a href="#cb32-50" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Predicted RTS Count: </span><span class="sc">{</span>predicted_rts_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-51"><a href="#cb32-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-52"><a href="#cb32-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Practice Idea ---</span></span>
<span id="cb32-53"><a href="#cb32-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Choose a *different* image name from the `val_dataset.img_list`</span></span>
<span id="cb32-54"><a href="#cb32-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># and predict its class using the `predict_image` function.</span></span>
<span id="cb32-55"><a href="#cb32-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Example:</span></span>
<span id="cb32-56"><a href="#cb32-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># if len(val_dataset) &gt; 1:</span></span>
<span id="cb32-57"><a href="#cb32-57" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     img_name_practice = val_dataset.img_list[1] # Get the second image name</span></span>
<span id="cb32-58"><a href="#cb32-58" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     img_path_practice = os.path.join(img_dir, img_name_practice)</span></span>
<span id="cb32-59"><a href="#cb32-59" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     predicted_class_practice = predict_image(model, img_path_practice, transform)</span></span>
<span id="cb32-60"><a href="#cb32-60" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     print(f"\nPractice Prediction for {img_name_practice}: {predicted_class_practice}")</span></span>
<span id="cb32-61"><a href="#cb32-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ---------------------</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Output
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/cyber2a-course/cyber2a-course/sections/hands-on-lab-pytorch.ipynb" data-notebook-title="Introduction: Welcome to the Hands-On Lab!" data-notebook-cellid="cell-Inference">
<div id="inference" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="f06d6bb7-0b6f-459d-cae1-5d8c8b94d355" data-execution_count="11">
<div class="cell-output cell-output-stdout">
<pre><code>
Defining prediction function...

Predicting class for image: valtest_yg_070.jpg
Predicted Class Index: 1
Predicted RTS Count: 2</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="visualization" class="level2" data-number="8.7">
<h2 data-number="8.7" class="anchored" data-anchor-id="visualization"><span class="header-section-number">8.7</span> Visualization</h2>
<p>Let’s visualize the image we just predicted on, showing the predicted RTS count.</p>
<p>We’ll also overlay the original segmentation annotations (if available) for context, although our model only performed classification.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2 <span class="co"># OpenCV for image handling</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Visualizing prediction..."</span>)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> display_image_with_annotations(image_name, image_folder, predicted_class):</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Displays an image with its original annotations (if available) and the</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="co">    predicted class label from our model.</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a><span class="co">        image_name (str): The name of the image file.</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a><span class="co">        image_folder (str): The folder where the image is stored.</span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a><span class="co">        predicted_class (int): The 0-indexed predicted class label.</span></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the COCO annotations (optional, for context only)</span></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>    coco_annotations <span class="op">=</span> {}</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="bu">open</span>(<span class="st">"cyber2a/rts_coco.json"</span>, <span class="st">"r"</span>) <span class="im">as</span> f:</span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>            rts_coco <span class="op">=</span> json.load(f)</span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create a mapping from image filename to image ID and annotations</span></span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>        image_id_map <span class="op">=</span> {img[<span class="st">'file_name'</span>]: img[<span class="st">'id'</span>] <span class="cf">for</span> img <span class="kw">in</span> rts_coco.get(<span class="st">'images'</span>, [])}</span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>        annotation_map <span class="op">=</span> {}</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> ann <span class="kw">in</span> rts_coco.get(<span class="st">'annotations'</span>, []):</span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a>            img_id <span class="op">=</span> ann[<span class="st">'image_id'</span>]</span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> img_id <span class="kw">not</span> <span class="kw">in</span> annotation_map:</span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a>                annotation_map[img_id] <span class="op">=</span> []</span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a>            annotation_map[img_id].append(ann[<span class="st">'segmentation'</span>])</span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a>        image_id <span class="op">=</span> image_id_map.get(image_name)</span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a>        annotations <span class="op">=</span> annotation_map.get(image_id, []) <span class="cf">if</span> image_id <span class="cf">else</span> []</span>
<span id="cb34-34"><a href="#cb34-34" aria-hidden="true" tabindex="-1"></a>        coco_annotations[<span class="st">'annotations'</span>] <span class="op">=</span> annotations <span class="co"># Store for drawing</span></span>
<span id="cb34-35"><a href="#cb34-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-36"><a href="#cb34-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">FileNotFoundError</span>:</span>
<span id="cb34-37"><a href="#cb34-37" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Warning: rts_coco.json not found. Cannot display annotations."</span>)</span>
<span id="cb34-38"><a href="#cb34-38" aria-hidden="true" tabindex="-1"></a>        coco_annotations[<span class="st">'annotations'</span>] <span class="op">=</span> []</span>
<span id="cb34-39"><a href="#cb34-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb34-40"><a href="#cb34-40" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Warning: Error loading COCO annotations: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb34-41"><a href="#cb34-41" aria-hidden="true" tabindex="-1"></a>        coco_annotations[<span class="st">'annotations'</span>] <span class="op">=</span> []</span>
<span id="cb34-42"><a href="#cb34-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-43"><a href="#cb34-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-44"><a href="#cb34-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Read the image using OpenCV</span></span>
<span id="cb34-45"><a href="#cb34-45" aria-hidden="true" tabindex="-1"></a>    img_path <span class="op">=</span> os.path.join(image_folder, image_name)</span>
<span id="cb34-46"><a href="#cb34-46" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb34-47"><a href="#cb34-47" aria-hidden="true" tabindex="-1"></a>        cv2_image <span class="op">=</span> cv2.imread(img_path)</span>
<span id="cb34-48"><a href="#cb34-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> cv2_image <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb34-49"><a href="#cb34-49" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">FileNotFoundError</span></span>
<span id="cb34-50"><a href="#cb34-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert from BGR (OpenCV default) to RGB (matplotlib default)</span></span>
<span id="cb34-51"><a href="#cb34-51" aria-hidden="true" tabindex="-1"></a>        cv2_image <span class="op">=</span> cv2.cvtColor(cv2_image, cv2.COLOR_BGR2RGB)</span>
<span id="cb34-52"><a href="#cb34-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">FileNotFoundError</span>:</span>
<span id="cb34-53"><a href="#cb34-53" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Error: Image file not found at </span><span class="sc">{</span>img_path<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb34-54"><a href="#cb34-54" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span></span>
<span id="cb34-55"><a href="#cb34-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb34-56"><a href="#cb34-56" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Error reading image </span><span class="sc">{</span>img_path<span class="sc">}</span><span class="ss"> with OpenCV: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb34-57"><a href="#cb34-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span></span>
<span id="cb34-58"><a href="#cb34-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-59"><a href="#cb34-59" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Overlay the polygons (optional visualization)</span></span>
<span id="cb34-60"><a href="#cb34-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> annotation_list <span class="kw">in</span> coco_annotations.get(<span class="st">'annotations'</span>, []):</span>
<span id="cb34-61"><a href="#cb34-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> polygon_coords <span class="kw">in</span> annotation_list:</span>
<span id="cb34-62"><a href="#cb34-62" aria-hidden="true" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb34-63"><a href="#cb34-63" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Reshape polygon coordinates for cv2.polylines</span></span>
<span id="cb34-64"><a href="#cb34-64" aria-hidden="true" tabindex="-1"></a>                polygon <span class="op">=</span> np.array(polygon_coords, dtype<span class="op">=</span>np.int32).reshape((<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb34-65"><a href="#cb34-65" aria-hidden="true" tabindex="-1"></a>                cv2.polylines(cv2_image, [polygon], isClosed<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">255</span>, <span class="dv">0</span>), thickness<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb34-66"><a href="#cb34-66" aria-hidden="true" tabindex="-1"></a>            <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb34-67"><a href="#cb34-67" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f"Warning: Could not draw polygon </span><span class="sc">{</span>polygon_coords<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb34-68"><a href="#cb34-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-69"><a href="#cb34-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-70"><a href="#cb34-70" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display the image with the predicted label</span></span>
<span id="cb34-71"><a href="#cb34-71" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb34-72"><a href="#cb34-72" aria-hidden="true" tabindex="-1"></a>    ax.imshow(cv2_image)</span>
<span id="cb34-73"><a href="#cb34-73" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add 1 back to predicted_class to show the RTS count</span></span>
<span id="cb34-74"><a href="#cb34-74" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="ss">f'Image: </span><span class="sc">{</span>image_name<span class="sc">}</span><span class="ch">\n</span><span class="ss">Predicted RTS Count: </span><span class="sc">{</span>predicted_class <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb34-75"><a href="#cb34-75" aria-hidden="true" tabindex="-1"></a>    ax.axis(<span class="st">'off'</span>)</span>
<span id="cb34-76"><a href="#cb34-76" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb34-77"><a href="#cb34-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-78"><a href="#cb34-78" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the prediction for the example image</span></span>
<span id="cb34-79"><a href="#cb34-79" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> predicted_class <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb34-80"><a href="#cb34-80" aria-hidden="true" tabindex="-1"></a>    display_image_with_annotations(img_name_to_predict, img_dir, predicted_class)</span>
<span id="cb34-81"><a href="#cb34-81" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb34-82"><a href="#cb34-82" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Cannot visualize prediction due to previous error."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="callout callout-style-default callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Output
</div>
</div>
<div class="callout-body-container callout-body">
<div class="quarto-embed-nb-cell" data-notebook="/home/runner/work/cyber2a-course/cyber2a-course/sections/hands-on-lab-pytorch.ipynb" data-notebook-title="Introduction: Welcome to the Hands-On Lab!" data-notebook-cellid="cell-Visualization">
<div id="cell-Visualization" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:483}}" data-outputid="ecc05691-0266-40b6-d91f-ae7d08e169db" data-execution_count="12">
<div class="cell-output cell-output-stdout">
<pre><code>
Visualizing prediction...</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="hands-on-lab-pytorch_files/figure-html/hands-on-lab-pytorch-visualization-output-2.png" id="visualization" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="conclusion-next-steps" class="level2" data-number="8.8">
<h2 data-number="8.8" class="anchored" data-anchor-id="conclusion-next-steps"><span class="header-section-number">8.8</span> Conclusion &amp; Next Steps</h2>
<p>Congratulations! You’ve successfully:</p>
<ol type="1">
<li>Loaded and prepared data using <code>Dataset</code>, <code>Transforms</code>, and <code>DataLoader</code>.</li>
<li>Loaded a pre-trained <code>nn.Module</code> (ResNet-18) and adapted it using transfer learning.</li>
<li>Defined a loss function (<code>CrossEntropyLoss</code>) and optimizer (<code>SGD</code>).</li>
<li>Implemented and run a basic training and validation loop.</li>
<li>Performed inference on a single image.</li>
<li>Visualized the prediction.</li>
</ol>
<p>This covers the fundamental workflow of a PyTorch application!</p>
<p><strong>Where to go from here?</strong></p>
<ul>
<li><strong>Experiment:</strong> Try the “Practice Ideas” suggested in the comments above.</li>
<li><strong>Tune Hyperparameters:</strong> Adjust the learning rate, batch size, or number of epochs.</li>
<li><strong>Data Augmentation:</strong> Implement more complex transforms for the training data.</li>
<li><strong>Different Models:</strong> Try other pre-trained architectures from <code>torchvision.models</code>.</li>
<li><strong>Metrics:</strong> Use libraries like <code>torchmetrics</code> or <code>scikit-learn</code> for more detailed evaluation (precision, recall, F1-score).</li>
<li><strong>Learning Rate Scheduling:</strong> Implement a learning rate scheduler (<code>torch.optim.lr_scheduler</code>).</li>
<li><strong>Saving/Loading:</strong> Add code to save your trained model’s <code>state_dict</code> and load it later (as shown in the lecture).</li>
</ul>
<p>Keep practicing and exploring!</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../sections/intro-to-pytorch.html" class="pagination-link" aria-label="Introduction to PyTorch: Core Functionalities and Advantages">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to PyTorch: Core Functionalities and Advantages</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../sections/permafrost-discovery-gateway.html" class="pagination-link" aria-label="Permafrost Discovery Gateway">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Permafrost Discovery Gateway</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<!-- Default Statcounter code for cyber2a online course
http://cyber2a.github.io/cyber2a-course/ -->
<script type="text/javascript">
    var sc_project=13129980; 
    var sc_invisible=1; 
    var sc_security="fa33fcfd"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async=""></script>
    <noscript><div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img class="statcounter" src="https://c.statcounter.com/13129980/0/fa33fcfd/1/" alt="Web Analytics" referrerpolicy="no-referrer-when-downgrade"></a></div></noscript>
    <!-- End of Statcounter Code -->




</body></html>