<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>7&nbsp; Introduction to PyTorch: Core Functionalities and Advantages – Cyber2A: AI for Arctic Research</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../sections/hands-on-lab-pytorch.html" rel="next">
<link href="../sections/the-building-blocks-of-nn-and-dl.html" rel="prev">
<link href="../images/index/arcticlogo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-5fd9db47a040b21ac2cac9a0b3b722ba.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../sections/the-building-blocks-of-nn-and-dl.html"><b>Day 2: AI Fundamentals and Techniques</b></a></li><li class="breadcrumb-item"><a href="../sections/intro-to-pytorch.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to PyTorch: Core Functionalities and Advantages</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Cyber2A: AI for Arctic Research</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/cyber2a/cyber2a-course/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Overview</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 1: Introduction to AI and Arctic Science</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/breaking-the-ice-with-ai-in-arctic-science.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Breaking the Ice with AI in Arctic Science</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-for-everyone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI for Everyone</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-ready-data-in-arctic-research.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">AI-Ready Data in Arctic Research</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/data-annotation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Data Annotation: The Foundation of Deep Learning Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-data-annotation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Hands-On Lab: Data Annotation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 2: AI Fundamentals and Techniques</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/the-building-blocks-of-nn-and-dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The Building Blocks of Neural Networks and Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/intro-to-pytorch.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to PyTorch: Core Functionalities and Advantages</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-pytorch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Hands-On Lab: PyTorch</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/permafrost-discovery-gateway.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Permafrost Discovery Gateway</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-ethics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">AI Ethics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 3: Advanced AI Workflows and Models</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/guest-lecture-yili-arts-dataset.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Guest Lecture - Unveiling the ARTS Dataset for a Thawing Frontier</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/exploring-advanced-neural-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Exploring Advanced Neural Networks: Instance Segmentation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/intro-to-dl-libraries-for-image-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Introduction to Deep Learning Libraries for Image Analysis</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 4: Workflows and Foundation Models</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-workflows-and-mlops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">AI Workflows and MLOps: From Development to Deployment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-ai-workflows.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Hands-On Lab: AI Workflows</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/foundation-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Foundation Models: The Cornerstones of Modern AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-foundation-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Hands-On Lab: Foundation Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/reproducibility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Reproducibility</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 5: AI Frontiers</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/the-fun-and-frontiers-of-ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">The Fun and Frontiers of AI: Innovation, Imagination, Interaction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#what-is-pytorch" id="toc-what-is-pytorch" class="nav-link" data-scroll-target="#what-is-pytorch"><span class="header-section-number">7.1</span> What is PyTorch?</a>
  <ul class="collapse">
  <li><a href="#why-use-a-framework-like-pytorch" id="toc-why-use-a-framework-like-pytorch" class="nav-link" data-scroll-target="#why-use-a-framework-like-pytorch"><span class="header-section-number">7.1.1</span> Why Use a Framework Like PyTorch?</a></li>
  </ul></li>
  <li><a href="#pytorch-tensors-the-building-blocks-of-data" id="toc-pytorch-tensors-the-building-blocks-of-data" class="nav-link" data-scroll-target="#pytorch-tensors-the-building-blocks-of-data"><span class="header-section-number">7.2</span> PyTorch Tensors: The Building Blocks of Data</a>
  <ul class="collapse">
  <li><a href="#creating-tensors" id="toc-creating-tensors" class="nav-link" data-scroll-target="#creating-tensors"><span class="header-section-number">7.2.1</span> Creating Tensors</a></li>
  <li><a href="#tensor-attributes" id="toc-tensor-attributes" class="nav-link" data-scroll-target="#tensor-attributes"><span class="header-section-number">7.2.2</span> Tensor Attributes</a></li>
  <li><a href="#common-tensor-operations" id="toc-common-tensor-operations" class="nav-link" data-scroll-target="#common-tensor-operations"><span class="header-section-number">7.2.3</span> Common Tensor Operations</a></li>
  <li><a href="#the-numpy-bridge" id="toc-the-numpy-bridge" class="nav-link" data-scroll-target="#the-numpy-bridge"><span class="header-section-number">7.2.4</span> The NumPy Bridge</a></li>
  </ul></li>
  <li><a href="#autograd-automatic-differentiation" id="toc-autograd-automatic-differentiation" class="nav-link" data-scroll-target="#autograd-automatic-differentiation"><span class="header-section-number">7.3</span> Autograd: Automatic Differentiation</a>
  <ul class="collapse">
  <li><a href="#how-does-autograd-work-the-concepts" id="toc-how-does-autograd-work-the-concepts" class="nav-link" data-scroll-target="#how-does-autograd-work-the-concepts"><span class="header-section-number">7.3.1</span> How Does Autograd Work? (The Concepts)</a></li>
  <li><a href="#important-points-about-autograd" id="toc-important-points-about-autograd" class="nav-link" data-scroll-target="#important-points-about-autograd"><span class="header-section-number">7.3.2</span> Important Points about Autograd</a></li>
  </ul></li>
  <li><a href="#moving-computations-to-the-gpu" id="toc-moving-computations-to-the-gpu" class="nav-link" data-scroll-target="#moving-computations-to-the-gpu"><span class="header-section-number">7.4</span> Moving Computations to the GPU</a></li>
  <li><a href="#data-handling-dataset-transforms-and-dataloader" id="toc-data-handling-dataset-transforms-and-dataloader" class="nav-link" data-scroll-target="#data-handling-dataset-transforms-and-dataloader"><span class="header-section-number">7.5</span> Data Handling: <code>Dataset</code>, Transforms, and <code>DataLoader</code></a>
  <ul class="collapse">
  <li><a href="#torch.utils.data.dataset" id="toc-torch.utils.data.dataset" class="nav-link" data-scroll-target="#torch.utils.data.dataset"><span class="header-section-number">7.5.1</span> <code>torch.utils.data.Dataset</code></a></li>
  <li><a href="#preprocessing-and-augmentation-with-transforms" id="toc-preprocessing-and-augmentation-with-transforms" class="nav-link" data-scroll-target="#preprocessing-and-augmentation-with-transforms"><span class="header-section-number">7.5.2</span> Preprocessing and Augmentation with Transforms</a></li>
  <li><a href="#torch.utils.data.dataloader" id="toc-torch.utils.data.dataloader" class="nav-link" data-scroll-target="#torch.utils.data.dataloader"><span class="header-section-number">7.5.3</span> <code>torch.utils.data.DataLoader</code></a></li>
  <li><a href="#summary-dataset-transforms-and-dataloader" id="toc-summary-dataset-transforms-and-dataloader" class="nav-link" data-scroll-target="#summary-dataset-transforms-and-dataloader"><span class="header-section-number">7.5.4</span> Summary: <code>Dataset</code>, Transforms, and <code>DataLoader</code></a></li>
  </ul></li>
  <li><a href="#model-building-nn.module-layers-and-containers" id="toc-model-building-nn.module-layers-and-containers" class="nav-link" data-scroll-target="#model-building-nn.module-layers-and-containers"><span class="header-section-number">7.6</span> Model Building: <code>nn.Module</code>, Layers, and Containers</a>
  <ul class="collapse">
  <li><a href="#the-torch.nn-namespace" id="toc-the-torch.nn-namespace" class="nav-link" data-scroll-target="#the-torch.nn-namespace"><span class="header-section-number">7.6.1</span> The <code>torch.nn</code> Namespace</a></li>
  <li><a href="#nn.module-the-base-for-all-models" id="toc-nn.module-the-base-for-all-models" class="nav-link" data-scroll-target="#nn.module-the-base-for-all-models"><span class="header-section-number">7.6.2</span> <code>nn.Module</code>: The Base for All Models</a></li>
  <li><a href="#common-layers-in-torch.nn-torch-nn-layers" id="toc-common-layers-in-torch.nn-torch-nn-layers" class="nav-link" data-scroll-target="#common-layers-in-torch.nn-torch-nn-layers"><span class="header-section-number">7.6.3</span> Common Layers in <code>torch.nn</code> </a></li>
  <li><a href="#organizing-models-containers" id="toc-organizing-models-containers" class="nav-link" data-scroll-target="#organizing-models-containers"><span class="header-section-number">7.6.4</span> Organizing Models: Containers</a></li>
  <li><a href="#accessing-model-parameters" id="toc-accessing-model-parameters" class="nav-link" data-scroll-target="#accessing-model-parameters"><span class="header-section-number">7.6.5</span> Accessing Model Parameters</a></li>
  </ul></li>
  <li><a href="#leveraging-pre-trained-models-transfer-learning" id="toc-leveraging-pre-trained-models-transfer-learning" class="nav-link" data-scroll-target="#leveraging-pre-trained-models-transfer-learning"><span class="header-section-number">7.7</span> Leveraging Pre-trained Models &amp; Transfer Learning</a>
  <ul class="collapse">
  <li><a href="#loading-pre-trained-models-with-torchvision.models" id="toc-loading-pre-trained-models-with-torchvision.models" class="nav-link" data-scroll-target="#loading-pre-trained-models-with-torchvision.models"><span class="header-section-number">7.7.1</span> Loading Pre-trained Models with <code>torchvision.models</code></a></li>
  <li><a href="#adapting-the-model-for-your-task" id="toc-adapting-the-model-for-your-task" class="nav-link" data-scroll-target="#adapting-the-model-for-your-task"><span class="header-section-number">7.7.2</span> Adapting the Model for Your Task</a></li>
  </ul></li>
  <li><a href="#loss-functions-in-pytorch-torch.nn" id="toc-loss-functions-in-pytorch-torch.nn" class="nav-link" data-scroll-target="#loss-functions-in-pytorch-torch.nn"><span class="header-section-number">7.8</span> Loss Functions in PyTorch (<code>torch.nn</code>)</a>
  <ul class="collapse">
  <li><a href="#common-loss-functions" id="toc-common-loss-functions" class="nav-link" data-scroll-target="#common-loss-functions"><span class="header-section-number">7.8.1</span> Common Loss Functions</a></li>
  <li><a href="#using-the-loss-function-in-training" id="toc-using-the-loss-function-in-training" class="nav-link" data-scroll-target="#using-the-loss-function-in-training"><span class="header-section-number">7.8.2</span> Using the Loss Function in Training</a></li>
  </ul></li>
  <li><a href="#optimizers-in-pytorch-torch.optim" id="toc-optimizers-in-pytorch-torch.optim" class="nav-link" data-scroll-target="#optimizers-in-pytorch-torch.optim"><span class="header-section-number">7.9</span> Optimizers in PyTorch (<code>torch.optim</code>)</a>
  <ul class="collapse">
  <li><a href="#instantiating-an-optimizer" id="toc-instantiating-an-optimizer" class="nav-link" data-scroll-target="#instantiating-an-optimizer"><span class="header-section-number">7.9.1</span> Instantiating an Optimizer</a></li>
  <li><a href="#common-optimizers" id="toc-common-optimizers" class="nav-link" data-scroll-target="#common-optimizers"><span class="header-section-number">7.9.2</span> Common Optimizers</a></li>
  <li><a href="#using-the-optimizer-in-the-training-loop" id="toc-using-the-optimizer-in-the-training-loop" class="nav-link" data-scroll-target="#using-the-optimizer-in-the-training-loop"><span class="header-section-number">7.9.3</span> Using the Optimizer in the Training Loop</a></li>
  <li><a href="#learning-rate-scheduling" id="toc-learning-rate-scheduling" class="nav-link" data-scroll-target="#learning-rate-scheduling"><span class="header-section-number">7.9.4</span> Learning Rate Scheduling</a></li>
  </ul></li>
  <li><a href="#training-a-model-in-pytorch-the-training-loop" id="toc-training-a-model-in-pytorch-the-training-loop" class="nav-link" data-scroll-target="#training-a-model-in-pytorch-the-training-loop"><span class="header-section-number">7.10</span> Training a Model in PyTorch (The Training Loop)</a>
  <ul class="collapse">
  <li><a href="#the-training-loop-structure" id="toc-the-training-loop-structure" class="nav-link" data-scroll-target="#the-training-loop-structure"><span class="header-section-number">7.10.1</span> The Training Loop Structure</a></li>
  </ul></li>
  <li><a href="#evaluating-a-model-in-pytorch-metrics-test-loop" id="toc-evaluating-a-model-in-pytorch-metrics-test-loop" class="nav-link" data-scroll-target="#evaluating-a-model-in-pytorch-metrics-test-loop"><span class="header-section-number">7.11</span> Evaluating a Model in PyTorch (Metrics &amp; Test Loop)</a>
  <ul class="collapse">
  <li><a href="#the-evaluation-loop-structure" id="toc-the-evaluation-loop-structure" class="nav-link" data-scroll-target="#the-evaluation-loop-structure"><span class="header-section-number">7.11.1</span> The Evaluation Loop Structure</a></li>
  <li><a href="#calculating-evaluation-metrics" id="toc-calculating-evaluation-metrics" class="nav-link" data-scroll-target="#calculating-evaluation-metrics"><span class="header-section-number">7.11.2</span> Calculating Evaluation Metrics</a></li>
  </ul></li>
  <li><a href="#saving-and-loading-models" id="toc-saving-and-loading-models" class="nav-link" data-scroll-target="#saving-and-loading-models"><span class="header-section-number">7.12</span> Saving and Loading Models</a>
  <ul class="collapse">
  <li><a href="#saving-the-state_dict" id="toc-saving-the-state_dict" class="nav-link" data-scroll-target="#saving-the-state_dict"><span class="header-section-number">7.12.1</span> Saving the <code>state_dict</code></a></li>
  <li><a href="#loading-the-state_dict" id="toc-loading-the-state_dict" class="nav-link" data-scroll-target="#loading-the-state_dict"><span class="header-section-number">7.12.2</span> Loading the <code>state_dict</code></a></li>
  <li><a href="#saving-checkpoints-for-resuming-training" id="toc-saving-checkpoints-for-resuming-training" class="nav-link" data-scroll-target="#saving-checkpoints-for-resuming-training"><span class="header-section-number">7.12.3</span> Saving Checkpoints for Resuming Training</a></li>
  <li><a href="#handling-devices-cpugpu" id="toc-handling-devices-cpugpu" class="nav-link" data-scroll-target="#handling-devices-cpugpu"><span class="header-section-number">7.12.4</span> Handling Devices (CPU/GPU)</a></li>
  </ul></li>
  <li><a href="#common-pitfalls-and-best-practices" id="toc-common-pitfalls-and-best-practices" class="nav-link" data-scroll-target="#common-pitfalls-and-best-practices"><span class="header-section-number">7.13</span> Common Pitfalls and Best Practices</a></li>
  <li><a href="#conclusion-bringing-concepts-to-code" id="toc-conclusion-bringing-concepts-to-code" class="nav-link" data-scroll-target="#conclusion-bringing-concepts-to-code"><span class="header-section-number">7.14</span> Conclusion: Bringing Concepts to Code</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../sections/the-building-blocks-of-nn-and-dl.html"><b>Day 2: AI Fundamentals and Techniques</b></a></li><li class="breadcrumb-item"><a href="../sections/intro-to-pytorch.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to PyTorch: Core Functionalities and Advantages</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to PyTorch: Core Functionalities and Advantages</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>Welcome to the next exciting step on your deep learning journey! Having explored the fundamental building blocks – <strong>Data</strong>, <strong>Models</strong>, <strong>Loss Functions</strong>, and <strong>Optimization Algorithms</strong> – you now have a solid conceptual understanding of how deep learning works.</p>
<p>Now, it’s time to bring those concepts to life! Think of the last lesson as learning the rules of the road and understanding how a car works in principle. This lesson is where we get behind the wheel and learn to drive using a specific, powerful vehicle: <strong>PyTorch</strong> <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<p>PyTorch is a popular and flexible framework that makes building and training neural networks much more manageable. This session will guide you through its essential components in a simple and friendly way, showing you how the concepts we discussed map directly onto practical code.</p>
<p>In this session, we’ll explore:</p>
<ul>
<li><strong>PyTorch Fundamentals</strong>: Understand what PyTorch is and why it’s widely used. We’ll start with <strong>Tensors</strong>, PyTorch’s core data structure, and <strong>Autograd</strong>, its magic for automatically calculating gradients.</li>
<li><strong>Handling Data</strong>: Learn how PyTorch uses <code>Dataset</code> and <code>DataLoader</code> to efficiently manage and feed data into your models.</li>
<li><strong>Building and Training</strong>: Discover how to define <strong>Models</strong> using <code>nn.Module</code>, select <strong>Loss Functions</strong>, choose <strong>Optimizers</strong>, and combine everything into a working <strong>Training Loop</strong>.</li>
</ul>
<p>By the end of this lesson, you’ll grasp these key PyTorch components and understand how they implement the deep learning concepts you’ve already learned. This will equip you to start building and experimenting with your own neural networks in the hands-on sections to come!</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>It could be overwhelming to take in all the information at once. Don’t worry if you don’t understand everything right away. The key is to get started and practice. Open a Jupyter Notebook on <a href="https://colab.research.google.com">Google Colab</a> and start playing with the code snippets. As you gain more experience, the concepts will become clearer.</p>
</div>
</div>
<div class="callout callout-style-default callout-important no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Let’s start coding!
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div style="display: flex; justify-content: center; align-items: center; width: 100%;">
    <div class="tenor-gif-embed" data-postid="5368357" data-share-method="host" data-aspect-ratio="1" data-width="80%">
        <a href="https://tenor.com/view/cat-computer-typing-fast-gif-5368357">Cat Computer GIF</a>
        from <a href="https://tenor.com/search/cat-gifs">Cat GIFs</a>
    </div>
</div>
<script type="text/javascript" async="" src="https://tenor.com/embed.js"></script>
</div>
</div>
</div>
</section>
<section id="what-is-pytorch" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="what-is-pytorch"><span class="header-section-number">7.1</span> What is PyTorch?</h2>
<p>Now that we understand the conceptual building blocks of deep learning, let’s meet the tool we’ll use to put them into practice: <strong>PyTorch</strong>.</p>
<p><em>PyTorch is an open-source deep learning framework developed by Meta AI (formerly Facebook’s AI Research lab) <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. It is designed to provide flexibility and efficiency in building and deploying machine learning models.</em></p>
<p>Think back to our analogy: if deep learning concepts are the principles of how a car works, PyTorch is like a specific, well-designed car model – powerful, relatively easy to learn, and equipped with features that make driving (or in our case, building neural networks) smoother.</p>
<section id="why-use-a-framework-like-pytorch" class="level3" data-number="7.1.1">
<h3 data-number="7.1.1" class="anchored" data-anchor-id="why-use-a-framework-like-pytorch"><span class="header-section-number">7.1.1</span> Why Use a Framework Like PyTorch?</h3>
<p>You could implement neural network operations using standard numerical libraries like NumPy, but it quickly becomes complex, especially for deep networks and when calculating gradients for training. PyTorch abstracts away much of this complexity.</p>
<p>Consider implementing a basic convolutional layer:</p>
<ul>
<li><p><strong>Using NumPy (Conceptual Example):</strong> Requires manual implementation of sliding windows, dot products, and bias addition. You don’t need to follow every detail, but notice the amount of manual work required compared to the PyTorch equivalent.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Conceptual NumPy implementation - verbose and complex</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Input data (Batch, Channels, Height, Width)</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.random.randn(<span class="dv">10</span>, <span class="dv">3</span>, <span class="dv">32</span>, <span class="dv">32</span>) </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Weights (Out_channels, In_channels, Kernel_H, Kernel_W)</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>W <span class="op">=</span> np.random.randn(<span class="dv">20</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">5</span>) </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Biases (Out_channels)</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> np.random.randn(<span class="dv">20</span>) </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Output placeholder (careful calculation of output size needed)</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>output_h, output_w <span class="op">=</span> <span class="dv">28</span>, <span class="dv">28</span> <span class="co"># Assuming stride=1, padding=0</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> np.zeros((<span class="dv">10</span>, <span class="dv">20</span>, output_h, output_w)) </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Manual nested loops for convolution</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>): <span class="co"># Batch</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> c_out <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>): <span class="co"># Output channels</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> h <span class="kw">in</span> <span class="bu">range</span>(output_h): <span class="co"># Output height</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> w <span class="kw">in</span> <span class="bu">range</span>(output_w): <span class="co"># Output width</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Extract region, perform dot product across input channels, add bias</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>                h_start, w_start <span class="op">=</span> h, w</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>                h_end, w_end <span class="op">=</span> h_start <span class="op">+</span> <span class="dv">5</span>, w_start <span class="op">+</span> <span class="dv">5</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>                region <span class="op">=</span> X[n, :, h_start:h_end, w_start:w_end]</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>                convolution_sum <span class="op">=</span> np.<span class="bu">sum</span>(region <span class="op">*</span> W[c_out]) <span class="op">+</span> b[c_out]</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>                out[n, c_out, h, w] <span class="op">=</span> convolution_sum </span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">NOTE</span><span class="co">: This is simplified; correct gradient calculation would add much more complexity!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><strong>Using PyTorch:</strong> Leverages optimized, pre-built layers</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Input data (Batch, Channels, Height, Width)</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.randn(<span class="dv">10</span>, <span class="dv">3</span>, <span class="dv">32</span>, <span class="dv">32</span>) </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a convolutional layer (weights/biases handled internally)</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>conv_layer <span class="op">=</span> nn.Conv2d(in_channels<span class="op">=</span><span class="dv">3</span>, out_channels<span class="op">=</span><span class="dv">20</span>, kernel_size<span class="op">=</span><span class="dv">5</span>) </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the layer - PyTorch handles the complex operation</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> conv_layer(X) </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Print output shape (PyTorch calculates it automatically)</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(out.shape) <span class="co"># Output: torch.Size([10, 20, 28, 28]) </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul>
<p>This example highlights how PyTorch drastically simplifies deep learning development by providing high-level building blocks. How does PyTorch achieve this? <strong>Through several key features</strong>:</p>
<ul>
<li><p><strong>It Feels Like Python (Pythonic Integration)</strong></p>
<ul>
<li><p>If you’re comfortable with Python, PyTorch feels remarkably natural. Its API is designed to be intuitive, closely resembling standard Python code.</p></li>
<li><p>It integrates seamlessly with the Python ecosystem (NumPy, SciPy, etc.). You can use standard Python control flow (<code>if</code>, <code>for</code>) and debugging tools (<code>pdb</code>, <code>print</code>) effectively. This makes learning, prototyping, and debugging faster.</p></li>
</ul></li>
<li><p><strong>Dynamic Computation Graphs (Define-by-Run)</strong></p>
<ul>
<li><p>PyTorch builds the graph representing your network’s computations <em>on-the-fly</em> as your Python code runs.</p></li>
<li><p>Think Lego: You add blocks (operations) dynamically, rather than needing a fixed blueprint upfront.</p></li>
<li><p>Benefits: This provides great flexibility for models with variable structures (like RNNs processing different length sentences without requiring complex padding upfront) and makes debugging more straightforward using standard Python tools.</p></li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick Thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>Imagine you want a part of your neural network to behave differently depending on the length of the input sequence. Why might a dynamic graph framework (like PyTorch) make implementing this easier than a framework requiring a fixed graph defined upfront?</p>
<p><em>Hint: You can use standard Python <code>if</code> statements within your model’s forward pass.</em></p>
</div>
</div>
<ul>
<li><p><strong>Automatic Differentiation (Autograd)</strong></p>
<ul>
<li><p>This is tightly linked to dynamic graphs and is essential for training. PyTorch’s autograd engine automatically calculates the gradients (slopes) of your loss function with respect to all your model’s parameters (weights and biases).</p></li>
<li><p>You simply define the forward pass (how inputs become outputs), and PyTorch figures out the backward pass (gradient calculation) needed for optimization, saving you from complex manual calculus. We’ll explore this magic in detail soon!</p></li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick Thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>Remember the “Backward Pass / Backpropagation” step in our conceptual training loop? Which PyTorch feature directly handles the complex calculations needed for this step?</p>
<p><em>Hint: It automatically figures out the gradients.</em></p>
</div>
</div>
<ul>
<li><p><strong>Strong GPU Acceleration</strong></p>
<ul>
<li><p>Deep learning requires immense computational power (mostly matrix math). GPUs excel at this due to their parallel processing capabilities.</p></li>
<li><p>PyTorch seamlessly integrates with NVIDIA GPUs (via CUDA). Moving computations from the CPU to the GPU often requires minimal code changes (<code>.to('cuda')</code>) but can result in massive speedups (orders of magnitude) for training and inference.</p></li>
</ul></li>
<li><p><strong>Rich Ecosystem</strong></p>
<ul>
<li><p>PyTorch isn’t just the core library. It has a vibrant ecosystem with official libraries tailored for specific domains:</p>
<ul>
<li><strong>TorchVision</strong> <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>: For computer vision tasks, offering common datasets, pre-built model architectures, and image tranformation functions.</li>
<li><strong>TorchText</strong> <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>: For natural language processing, providing tools for text processing, standard datasets, and common NLP model components.</li>
<li><strong>TorchAudio</strong> <a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>: For audio processing, including datasets, models, and functions for audio data manipulation.</li>
</ul></li>
</ul></li>
</ul>
<ul>
<li><p><strong>Pre-trained Models and Community <a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> <a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></strong></p>
<ul>
<li><p>Leveraging the concept of Transfer Learning is easy in PyTorch. A large community contributes state-of-the-art pre-trained models (especially via TorchVision and platforms like Hugging Face <a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>).</p></li>
<li><p>You can easily load these models and adapt them for your own tasks, often achieving great results with less data and training time.</p></li>
</ul></li>
</ul>
<p>In the next sections, we’ll dive into the specifics, starting with PyTorch’s fundamental data structure: the <strong>Tensor</strong>.</p>
</section>
</section>
<section id="pytorch-tensors-the-building-blocks-of-data" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="pytorch-tensors-the-building-blocks-of-data"><span class="header-section-number">7.2</span> PyTorch Tensors: The Building Blocks of Data</h2>
<p>In the previous section, we saw how PyTorch provides high-level tools to simplify deep learning. Now, let’s look under the hood at the most fundamental object you’ll work with: the <strong>Tensor</strong>.</p>
<section id="what-is-a-tensor" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="what-is-a-tensor"><strong>What is a Tensor?</strong></h4>
<p>If you’ve used NumPy before, you’re already familiar with the concept of a multi-dimensional array (<code>ndarray</code>). A PyTorch Tensor is very similar: it’s a <strong>multi-dimensional grid of numerical values</strong>. Tensors can represent various forms of data:</p>
<ul>
<li>A single number (a <strong>scalar</strong> or 0-dimensional tensor).</li>
<li>A list of numbers (a <strong>vector</strong> or 1-dimensional tensor).</li>
<li>A table of numbers (a <strong>matrix</strong> or 2-dimensional tensor).</li>
<li>Or higher-dimensional data, like a color image (which can be represented as a 3D tensor: <code>height x width x color channels</code>) or a batch of images (a 4D tensor: <code>batch size x height x width x channels</code> – although PyTorch often uses <code>batch size x channels x height x width</code>).</li>
</ul>
</section>
<section id="why-tensors" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="why-tensors"><strong>Why Tensors?</strong></h4>
<p>Tensors are the primary way we represent and manipulate data in PyTorch. They are optimized for:</p>
<ol type="1">
<li><strong>Numerical Computation:</strong> Performing mathematical operations efficiently.</li>
<li><strong>GPU Acceleration:</strong> Unlike NumPy arrays, Tensors can be easily moved to and processed on GPUs for massive speedups.</li>
<li><strong>Automatic Differentiation:</strong> PyTorch’s <code>autograd</code> system (which we’ll cover next) operates directly on Tensors to calculate gradients automatically.</li>
</ol>
</section>
<section id="creating-tensors" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="creating-tensors"><span class="header-section-number">7.2.1</span> Creating Tensors</h3>
<p>There are several ways to create tensors in PyTorch:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>You don’t need to memorize all these operations. You can always refer to the <a href="https://pytorch.org/docs/stable/tensors.html">PyTorch documentation</a> for a comprehensive list of tensor operations and functions.</p>
</div>
</div>
<ol type="1">
<li><p><strong>Directly from data (Python lists or NumPy arrays)</strong></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># From a Python list</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>list_data <span class="op">=</span> [[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>]]</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> torch.tensor(list_data) </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(t1)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[1, 2],</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co">#         [3, 4]])</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># From a NumPy array (shares memory!)</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>numpy_array <span class="op">=</span> np.array([<span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>])</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> torch.from_numpy(numpy_array) </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(t2)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([5, 6, 7], dtype=torch.int64) # dtype often inferred</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><strong>Creating tensors with specific values</strong></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Tensor of zeros</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>shape <span class="op">=</span> (<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>zeros_tensor <span class="op">=</span> torch.zeros(shape)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(zeros_tensor)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[0., 0., 0.],</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">#         [0., 0., 0.]])</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Tensor of ones</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>ones_tensor <span class="op">=</span> torch.ones(shape)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ones_tensor)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[1., 1., 1.],</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co">#         [1., 1., 1.]])</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Tensor with random values (uniform distribution 0 to 1)</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>rand_tensor <span class="op">=</span> torch.rand(shape)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(rand_tensor) </span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[0.1234, 0.5678, 0.9012], # Example random values</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co">#         [0.3456, 0.7890, 0.2345]])</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Tensor with random values (standard normal distribution)</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>randn_tensor <span class="op">=</span> torch.randn(shape) </span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(randn_tensor)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[-0.5432,  1.2345, -0.9876], # Example random values</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="co">#         [ 0.6543, -1.5432,  0.1234]])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><strong>Creating tensors similar to other tensors:</strong> You can create new tensors that have the same shape and <code>dtype</code> (data type) as an existing tensor</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>x_data <span class="op">=</span> torch.tensor([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>]], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create zeros with the same shape and type as x_data</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>x_zeros <span class="op">=</span> torch.zeros_like(x_data) </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x_zeros)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[0., 0.],</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">#         [0., 0.]])</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create random numbers with the same shape and type as x_data</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>x_rand <span class="op">=</span> torch.rand_like(x_data) </span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x_rand)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[0.1111, 0.2222], # Example random values</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">#         [0.3333, 0.4444]])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
</section>
<section id="tensor-attributes" class="level3" data-number="7.2.2">
<h3 data-number="7.2.2" class="anchored" data-anchor-id="tensor-attributes"><span class="header-section-number">7.2.2</span> Tensor Attributes</h3>
<p>Every tensor has important attributes that describe it:</p>
<ul>
<li><strong><code>shape</code></strong> (or <code>.size()</code>): A tuple representing the dimensions of the tensor.</li>
<li><strong><code>dtype</code></strong>: The data type of the elements within the tensor (e.g., <code>torch.float32</code>, <code>torch.int64</code>, <code>torch.bool</code>) <a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>. <code>float32</code> is the most common for neural network parameters.</li>
<li><strong><code>device</code></strong>: The device where the tensor’s data is stored (e.g., <code>cpu</code> or <code>cuda:0</code> for the first GPU).</li>
</ul>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">4</span>) <span class="co"># Shape (3, 4)</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Shape of tensor: </span><span class="sc">{</span>tensor<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>) </span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Output: Shape of tensor: torch.Size([3, 4])</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Datatype of tensor: </span><span class="sc">{</span>tensor<span class="sc">.</span>dtype<span class="sc">}</span><span class="ss">"</span>) </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Output: Datatype of tensor: torch.float32 (default float)</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Device tensor is stored on: </span><span class="sc">{</span>tensor<span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>) </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Output: Device tensor is stored on: cpu (default)</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating a tensor with specific dtype and on GPU (if available)</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    gpu_tensor <span class="op">=</span> torch.ones(<span class="dv">2</span>, <span class="dv">2</span>, dtype<span class="op">=</span>torch.float64, device<span class="op">=</span><span class="st">'cuda'</span>)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">GPU Tensor Device: </span><span class="sc">{</span>gpu_tensor<span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"GPU Tensor Dtype: </span><span class="sc">{</span>gpu_tensor<span class="sc">.</span>dtype<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">CUDA not available, GPU tensor not created."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="common-tensor-operations" class="level3" data-number="7.2.3">
<h3 data-number="7.2.3" class="anchored" data-anchor-id="common-tensor-operations"><span class="header-section-number">7.2.3</span> Common Tensor Operations</h3>
<p>PyTorch supports hundreds of operations on tensors. Here are some basics:</p>
<ul>
<li><p><strong>Element-wise Operations:</strong> Standard math operations apply element by element.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> torch.tensor([[<span class="fl">1.</span>, <span class="fl">2.</span>], [<span class="fl">3.</span>, <span class="fl">4.</span>]])</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> torch.ones(<span class="dv">2</span>, <span class="dv">2</span>) <span class="op">*</span> <span class="dv">5</span> <span class="co"># Creates a tensor [[5., 5.], [5., 5.]]</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Addition</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Addition:</span><span class="ch">\n</span><span class="st">"</span>, t1 <span class="op">+</span> t2) </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[ 6.,  7.],</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co">#         [ 8.,  9.]])</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiplication (element-wise)</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Multiplication:</span><span class="ch">\n</span><span class="st">"</span>, t1 <span class="op">*</span> t2)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[ 5., 10.],</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co">#         [15., 20.]])</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="co"># In-place operations (modify the tensor directly, often denoted by trailing _)</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>t1.add_(t2) <span class="co"># t1 is now modified</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"t1 after in-place add:</span><span class="ch">\n</span><span class="st">"</span>, t1)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[ 6.,  7.],</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="co">#         [ 8.,  9.]])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Operations often support <strong>broadcasting</strong> (similar to NumPy) where PyTorch automatically expands tensors of smaller dimensions to match larger ones under certain rules, simplifying code.</p>
</div>
</div>
<ul>
<li><p><strong>Indexing and Slicing:</strong> Works just like NumPy indexing.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>], [<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>]])</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"First row:"</span>, tensor[<span class="dv">0</span>]) <span class="co"># tensor([1, 2, 3])</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Second column:"</span>, tensor[:, <span class="dv">1</span>]) <span class="co"># tensor([2, 5, 8])</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Element at row 1, col 2:"</span>, tensor[<span class="dv">1</span>, <span class="dv">2</span>]) <span class="co"># tensor(6)</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sub-matrix (rows 0-1, cols 1-2):</span><span class="ch">\n</span><span class="st">"</span>, tensor[<span class="dv">0</span>:<span class="dv">2</span>, <span class="dv">1</span>:<span class="dv">3</span>]) </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[2, 3],</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co">#         [5, 6]])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><strong>Reshaping Tensors:</strong> Changing the shape without changing the data.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.arange(<span class="dv">6</span>) <span class="co"># tensor([0, 1, 2, 3, 4, 5])</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Reshape to 2 rows, 3 columns</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>reshaped <span class="op">=</span> tensor.reshape(<span class="dv">2</span>, <span class="dv">3</span>) </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Reshaped:</span><span class="ch">\n</span><span class="st">"</span>, reshaped)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[0, 1, 2],</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co">#         [3, 4, 5]])</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># .view() is similar but requires the new shape to be compatible </span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co"># with the original's memory layout (often faster, shares memory)</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>viewed <span class="op">=</span> tensor.view(<span class="dv">3</span>, <span class="dv">2</span>) </span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Viewed:</span><span class="ch">\n</span><span class="st">"</span>, viewed)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[0, 1],</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co">#         [2, 3],</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="co">#         [4, 5]])</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a dimension (unsqueeze)</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>unsqueezed <span class="op">=</span> tensor.unsqueeze(dim<span class="op">=</span><span class="dv">0</span>) <span class="co"># Add dimension at the beginning</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Unsqueezed shape:"</span>, unsqueezed.shape) <span class="co"># torch.Size([1, 6])</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove dimensions of size 1 (squeeze)</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>squeezed <span class="op">=</span> unsqueezed.squeeze(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Squeezed shape:"</span>, squeezed.shape) <span class="co"># torch.Size([6])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><strong>Matrix Multiplication</strong>: Use the <code>@</code> operator or <code>torch.matmul()</code>.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>mat1 <span class="op">=</span> torch.randn(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>mat2 <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>product <span class="op">=</span> mat1 <span class="op">@</span> mat2 <span class="co"># or torch.matmul(mat1, mat2)</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Matrix product shape:"</span>, product.shape) <span class="co"># torch.Size([2, 4])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul>
</section>
<section id="the-numpy-bridge" class="level3" data-number="7.2.4">
<h3 data-number="7.2.4" class="anchored" data-anchor-id="the-numpy-bridge"><span class="header-section-number">7.2.4</span> The NumPy Bridge</h3>
<p>PyTorch tensors on the CPU can be converted to NumPy arrays and vice-versa very efficiently.</p>
<ul>
<li><strong>Tensor to NumPy</strong>: <code>.numpy()</code></li>
<li><strong>NumPy to Tensor</strong>: <code>torch.from_numpy()</code></li>
</ul>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>If the Tensor is on the CPU, the Tensor and the NumPy array share the same underlying memory location. This means changing one will change the other!</p></li>
<li><p>If the tensor is on the GPU, you must first move it to the CPU (<code>.cpu()</code>) before converting it to NumPy using <code>.numpy()</code>.</p></li>
</ul>
</div>
</div>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Tensor to NumPy</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>tensor_cpu <span class="op">=</span> torch.ones(<span class="dv">5</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>numpy_arr <span class="op">=</span> tensor_cpu.numpy() </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"NumPy array:"</span>, numpy_arr) <span class="co"># [1. 1. 1. 1. 1.]</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>tensor_cpu.add_(<span class="dv">1</span>) <span class="co"># Modify the tensor</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"NumPy array after tensor modified:"</span>, numpy_arr) <span class="co"># [2. 2. 2. 2. 2.] &lt;- It changed!</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co"># NumPy to Tensor</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>numpy_arr <span class="op">=</span> np.zeros(<span class="dv">3</span>)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>tensor_from_numpy <span class="op">=</span> torch.from_numpy(numpy_arr)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Tensor:"</span>, tensor_from_numpy) <span class="co"># tensor([0., 0., 0.], ...)</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>np.add(numpy_arr, <span class="dv">5</span>, out<span class="op">=</span>numpy_arr) <span class="co"># Modify the NumPy array</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Tensor after NumPy array modified:"</span>, tensor_from_numpy) <span class="co"># tensor([5., 5., 5.], ...) &lt;- It changed!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick Thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why is the shared memory feature of the NumPy bridge both powerful and potentially dangerous if you’re not careful?</p>
<p><em>Hint: Think about efficiency vs.&nbsp;unintended side effects.</em></p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick Thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>Based on the <a href="https://pytorch.org/docs/stable/index.html">PyTorch documentation</a>, can you find the differences between the following functions or attributes?</p>
<ul>
<li><code>torch.view()</code> vs.&nbsp;<code>torch.reshape()</code></li>
<li><code>torch.cat()</code> vs.&nbsp;<code>torch.stack()</code></li>
<li><code>torch.unsqueeze()</code> vs.&nbsp;<code>torch.squeeze()</code></li>
<li><code>torch.cuda.FloatTensor</code> vs.&nbsp;<code>torch.FloatTensor</code></li>
<li><code>"cpu"</code> vs.&nbsp;<code>"cuda"</code> vs.&nbsp;<code>"cuda:0"</code></li>
</ul>
<p><em>Hint: Try creating a tensor in Google Colab and playing around with these functions to see what they do.</em></p>
</div>
</div>
<p>Tensors are the starting point for everything else in PyTorch. Understanding how to create and manipulate them is essential before we move on to how PyTorch automatically computes gradients with them using <code>Autograd</code>.</p>
</section>
</section>
<section id="autograd-automatic-differentiation" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="autograd-automatic-differentiation"><span class="header-section-number">7.3</span> Autograd: Automatic Differentiation</h2>
<p>Remember back in our Deep Learning overview, we discussed <strong>Optimization Algorithms</strong> like Gradient Descent? These algorithms need to know the <strong>gradient</strong> (the slope or derivative) of the loss function with respect to each model parameter (weights and biases) to update them correctly and minimize the loss. Calculating these gradients manually for complex models would be incredibly tedious and error-prone.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Check out <a href="https://www.youtube.com/watch?v=IHZwWFHWa-w">3Blue1Brown’s video</a> to recap the idea of gradients, backpropagation, and the chain rule.</p>
</div>
</div>
<p>This is where PyTorch’s magic comes in: <strong><code>torch.autograd</code></strong>, its automatic differentiation engine.</p>
<section id="what-does-autograd-do" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="what-does-autograd-do"><strong>What Does Autograd Do?</strong></h4>
<p>Autograd automates the computation of gradients. You define the <em>forward pass</em> of your computation (how inputs produce outputs), and Autograd automatically figures out how to compute the gradients for the <em>backward pass</em>.</p>
</section>
<section id="how-does-autograd-work-the-concepts" class="level3" data-number="7.3.1">
<h3 data-number="7.3.1" class="anchored" data-anchor-id="how-does-autograd-work-the-concepts"><span class="header-section-number">7.3.1</span> How Does Autograd Work? (The Concepts)</h3>
<ol type="1">
<li><p><strong>Tracking Operations:</strong> PyTorch keeps track of all the operations performed on tensors for which gradient tracking is enabled. It does this by building a <strong>dynamic computational graph</strong> behind the scenes. This graph represents the relationships between tensors and the operations that created them. Think of it as a recipe recording every step taken.</p></li>
<li><p><strong>The <code>requires_grad</code> Flag:</strong> For Autograd to track operations on a tensor and compute gradients for it later, the tensor’s <code>requires_grad</code> attribute must be set to <code>True</code>.</p>
<ul>
<li>Tensors representing learnable parameters (like the weights and biases in <code>nn.Linear</code> or <code>nn.Conv2d</code> layers) automatically have <code>requires_grad=True</code>.</li>
<li>Input data tensors typically don’t need gradients, so they usually have <code>requires_grad=False</code> (the default for newly created tensors).</li>
<li>You can set it explicitly when creating a tensor: <code>torch.randn(3, 3, requires_grad=True)</code> or change it in-place later: <code>my_tensor.requires_grad_(True)</code>.</li>
</ul></li>
<li><p><strong>Starting the Backward Pass: <code>.backward()</code>:</strong> Once you have performed your forward pass and computed your final loss value (which <em>must</em> be a <strong>scalar</strong> – a single number), you call the <code>.backward()</code> method on that scalar loss tensor (e.g., <code>loss.backward()</code>).</p></li>
<li><p><strong>Gradient Calculation &amp; Storage:</strong> Calling <code>.backward()</code> triggers Autograd to traverse the computational graph backward from the loss scalar. Using the chain rule of calculus, it computes the gradient of the loss with respect to every tensor in the graph that has <code>requires_grad=True</code>.</p></li>
<li><p><strong>The <code>.grad</code> Attribute:</strong> The computed gradients are then <strong>accumulated</strong> (added) into the <code>.grad</code> attribute of the corresponding <em>leaf</em> tensors (the initial tensors in the graph that had <code>requires_grad=True</code>, typically your model’s parameters).</p></li>
</ol>
<section id="a-simple-example" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="a-simple-example"><strong>A Simple Example</strong></h4>
<p>Let’s see it in action:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a tensor 'x' that requires gradients</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.ones(<span class="dv">2</span>, <span class="dv">2</span>, requires_grad<span class="op">=</span><span class="va">True</span>) </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x:</span><span class="ch">\n</span><span class="st">"</span>, x)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform an operation</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x <span class="op">+</span> <span class="dv">2</span> </span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y:</span><span class="ch">\n</span><span class="st">"</span>, y) </span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co"># y was created by an operation involving x, so it has a 'grad_fn'</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform more operations</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> y <span class="op">*</span> y <span class="op">*</span> <span class="dv">3</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> z.mean() <span class="co"># Calculate a scalar mean value</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"out:"</span>, out) <span class="co"># out = tensor(27., grad_fn=&lt;MeanBackward0&gt;)</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, compute gradients using backpropagation</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>out.backward() </span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="co"># The gradient dz/dx is computed and stored in x.grad</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Gradient of out w.r.t x (x.grad):</span><span class="ch">\n</span><span class="st">"</span>, x.grad) </span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor([[4.5000, 4.5000],</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a><span class="co">#         [4.5000, 4.5000]]) </span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Math check: out = (1/4) * sum(3 * (x+2)^2)</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a><span class="co"># d(out)/dx_ij = (1/4) * 3 * 2 * (x_ij+2) = 1.5 * (x_ij+2)</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Since x_ij = 1, d(out)/dx_ij = 1.5 * (1+2) = 4.5</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this example:</p>
<ul>
<li>We created <code>x</code> with <code>requires_grad=True</code>.</li>
<li>We performed operations (<code>+</code>, <code>*</code>, <code>mean</code>) to get a scalar <code>out</code>. PyTorch built a graph tracking these.</li>
<li>Calling <code>out.backward()</code> calculated the gradient <span class="math inline">\(\frac{\partial \text{out}}{\partial x}\)</span> using the chain rule.</li>
<li>The result was stored in <code>x.grad</code>.</li>
</ul>
</section>
</section>
<section id="important-points-about-autograd" class="level3" data-number="7.3.2">
<h3 data-number="7.3.2" class="anchored" data-anchor-id="important-points-about-autograd"><span class="header-section-number">7.3.2</span> Important Points about Autograd</h3>
<ul>
<li><p><strong>Gradient Accumulation</strong>: As mentioned, gradients computed by <code>.backward()</code> are accumulated into the <code>.grad</code> attribute. They don’t overwrite the previous value; they add to it. This is why, before each training iteration’s backward pass, you must explicitly zero out the gradients from the previous step using <code>optimizer.zero_grad()</code>. Otherwise, gradients from multiple steps would mix, leading to incorrect parameter updates.</p></li>
<li><p><strong>Disabling Gradient Tracking</strong>: Sometimes you <em>don’t</em> want PyTorch to track operations (e.g., during model evaluation/inference, or when modifying parameters outside the optimizer). Tracking consumes memory and computation. You can disable it in two main ways:</p>
<ul>
<li><p><code>with torch.no_grad():</code>: A context manager that disables gradient tracking for any operation within its block. This is the standard way to run inference code.</p></li>
<li><p><code>.detach()</code>: Creates a new tensor that shares the same data as the original but is detached from the computation history. It won’t require gradients, even if the original did. Useful if you need to use a tensor’s value without affecting gradient calculations later.</p></li>
</ul>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">3</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Requires grad:"</span>, x.requires_grad) <span class="co"># True</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Using no_grad context</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> x <span class="op">*</span> <span class="dv">2</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"y requires grad inside no_grad:"</span>, y.requires_grad) <span class="co"># False</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Using detach</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> x <span class="op">*</span> <span class="dv">3</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>z_detached <span class="op">=</span> z.detach()</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"z requires grad:"</span>, z.requires_grad) <span class="co"># True</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"z_detached requires grad:"</span>, z_detached.requires_grad) <span class="co"># False</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><strong>Backward on Scalars Only:</strong> You can only call <code>.backward()</code> implicitly on a tensor containing a single scalar value (like a loss). If you have a non-scalar tensor and need gradients, you typically provide a gradient argument to <code>.backward()</code> specifying how to weight the gradients for each element (this is more advanced).</p></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick Thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>During model evaluation (inference), why is it crucial to use <code>with torch.no_grad():</code> or <code>.detach()</code> before passing data through the model? (Think about efficiency and correctness)</p>
<p><em>Hint: Do we need gradients when just making predictions? What resources does tracking gradients consume?</em></p>
</div>
</div>
<p>Autograd is the engine that enables efficient gradient-based optimization in PyTorch. By understanding <code>requires_grad</code>, <code>.backward()</code>, and <code>.grad</code>, along with the concept of gradient accumulation and how to disable tracking, you have the core knowledge needed to understand how models learn during the training loop.</p>
</section>
</section>
<section id="moving-computations-to-the-gpu" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="moving-computations-to-the-gpu"><span class="header-section-number">7.4</span> Moving Computations to the GPU</h2>
<p>We’ve mentioned that one of PyTorch’s key strengths is its excellent <strong>GPU acceleration support</strong>. Deep learning often involves vast amounts of computation, especially large matrix multiplications. GPUs are designed for precisely this kind of parallel processing and can dramatically speed up model training and inference compared to using only the CPU.</p>
<p>PyTorch makes using a GPU remarkably simple using the <code>.to()</code> method (if you have a <em>compatible NVIDIA GPU</em> and have installed the <em>correct</em> PyTorch version with CUDA support).</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Check out this <a href="https://www.youtube.com/watch?v=ZrJeYFxpUyQ">video</a> to see the difference between how CPUs and GPUs compute. Deep learning involves tons of matrix multiplications, which are easy to parallelize - that’s why GPUs are so great for deep learning.</p>
</div>
</div>
<section id="how-to-move-tensors-and-models-to-the-gpu" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="how-to-move-tensors-and-models-to-the-gpu"><strong>How to Move Tensors and Models to the GPU</strong></h4>
<ol type="1">
<li><p><strong>Checking for GPU Availability and Setting the Device</strong></p>
<p>First, you should check if a GPU is available and define a <code>device</code> object that your code can use. This makes your code portable – it will run on the GPU if available, otherwise defaulting to the CPU.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Check if CUDA (GPU support) is available</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set device to the first CUDA device (GPU 0)</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">"cuda"</span>) </span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"CUDA is available. Using device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set device to CPU</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">"cpu"</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"CUDA not available. Using device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><em>Note:</em> If you have multiple GPUs, you can specify a different device like <code>cuda:1</code> or <code>cuda:0</code> to use a specific GPU.</p></li>
<li><p><strong>Moving Tensors to the Device</strong></p>
<p>You can move a tensor to the selected device using the <code>.to()</code> method:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming 'device' is defined as above</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a tensor on the CPU (default)</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>cpu_tensor <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Original tensor device: </span><span class="sc">{</span>cpu_tensor<span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Move the tensor to the determined device (GPU or CPU)</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>device_tensor <span class="op">=</span> cpu_tensor.to(device)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Moved tensor device: </span><span class="sc">{</span>device_tensor<span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><em>Note:</em> The <code>.to()</code> method returns a new tensor on the target device (if it’s not already there). It doesn’t modify the original tensor in-place unless you reassign it (<code>cpu_tensor = cpu_tensor.to(device)</code>).</p></li>
<li><p><strong>Moving Models to the Device</strong></p>
<p>Similarly, you need to move your neural network model (which is an instance of <code>nn.Module</code>) to the device (We’ll learn more about <code>nn.Module</code> later). This moves all the model’s parameters (which are themselves tensors) to the target device.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a simple model</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleModel(nn.Module):</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear <span class="op">=</span> nn.Linear(<span class="dv">10</span>, <span class="dv">2</span>) <span class="co"># Example layer</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.linear(x)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an instance of the model (initially on CPU)</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SimpleModel()</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Model parameter device (before move): </span><span class="sc">{</span><span class="bu">next</span>(model.parameters())<span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Move the entire model to the determined device</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>model.to(device)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Model parameter device (after move): </span><span class="sc">{</span><span class="bu">next</span>(model.parameters())<span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ol>
</section>
<section id="crucial-requirement-same-device" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="crucial-requirement-same-device"><strong>Crucial Requirement: Same Device!</strong></h4>
<p>For any operation involving multiple tensors (e.g., passing input data through a model layer), <strong>all tensors involved must be on the same device</strong>. If you try to perform an operation between a tensor on the CPU and a tensor on the GPU, you will get a runtime error.</p>
<p>Therefore, a standard pattern in PyTorch training scripts is:</p>
<ol type="1">
<li>Define the <code>device</code>.</li>
<li>Move the <code>model</code> to the <code>device</code>.</li>
<li>Inside the training loop, move each batch of input <code>data</code> and <code>labels</code> to the <code>device</code> before feeding them into the model.</li>
</ol>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Inside a typical training loop --- </span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming model and device are already defined and model is on device</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get a batch of data and labels from your DataLoader</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># inputs, labels = data_batch # (DataLoader typically yields CPU tensors)</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Move data to the same device as the model &lt;&lt;&lt; IMPORTANT STEP</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co"># inputs = inputs.to(device)</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># labels = labels.to(device)</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Now perform the forward pass (model and inputs are on the same device)</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co"># outputs = model(inputs) </span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co"># ... rest of the loop (loss calculation, etc.) ...</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Remember</strong>: Always ensure your model and the data being fed into it reside on the <em>same</em> device (<code>cpu</code> or <code>cuda</code>) to avoid runtime errors. Use the <code>.to(device)</code> pattern consistently.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick Thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>What happens if you consistently move your model and data to and from different devices?</p>
<p><em>Hint: Think about the performance implications. Moving stuff around costs time.</em></p>
</div>
</div>
<p>This simple <code>.to(device)</code> mechanism is fundamental for unlocking the performance potential of PyTorch for deep learning tasks. Now, let’s move on to how PyTorch helps manage the data itself.</p>
</section>
</section>
<section id="data-handling-dataset-transforms-and-dataloader" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="data-handling-dataset-transforms-and-dataloader"><span class="header-section-number">7.5</span> Data Handling: <code>Dataset</code>, Transforms, and <code>DataLoader</code></h2>
<p>In the previous lecture, we emphasized the critical role of <strong>Data</strong>. Preparing input data, formatting outputs, splitting into training/validation/testing sets, handling potentially massive datasets, and feeding data efficiently to the model are all essential steps. Doing this manually, especially with operations like shuffling, batching, and data preprocessing/augmentation, can be complex and inefficient.</p>
<p>PyTorch provides elegant tools within the <code>torch.utils.data</code> module to streamline this process: <code>Dataset</code>, <code>DataLoader</code>, and commonly used transforms (especially from <code>torchvision.transforms</code>).</p>
<section id="torch.utils.data.dataset" class="level3" data-number="7.5.1">
<h3 data-number="7.5.1" class="anchored" data-anchor-id="torch.utils.data.dataset"><span class="header-section-number">7.5.1</span> <code>torch.utils.data.Dataset</code></h3>
<p>The <code>Dataset</code> class is an abstraction that represents your dataset. Think of it as a standardized way to access individual data points. PyTorch has two main types, but the most common is the <strong>map-style dataset</strong>. To create a custom map-style dataset, you typically subclass <code>torch.utils.data.Dataset</code> and override two key methods (we’ll see an example later):</p>
<ol type="1">
<li><p><strong><code>__len__(self)</code></strong>: This method should return the total number of samples in your dataset.</p></li>
<li><p><strong><code>__getitem__(self, idx)</code></strong>: This method is responsible for retrieving the single data sample (features and corresponding label/target) at the given index <code>idx</code>. This is often where you’ll implement the logic to load data from disk (e.g., read an image file, load text) and perform initial processing.</p></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Libraries like <code>torchvision.datasets</code> provide convenient pre-built <code>Dataset</code> classes for many common public datasets (MNIST, CIFAR-10, ImageNet, etc.), handling downloading and setup automatically <a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>.</p>
</div>
</div>
</section>
<section id="preprocessing-and-augmentation-with-transforms" class="level3" data-number="7.5.2">
<h3 data-number="7.5.2" class="anchored" data-anchor-id="preprocessing-and-augmentation-with-transforms"><span class="header-section-number">7.5.2</span> Preprocessing and Augmentation with Transforms</h3>
<p>Raw data (like images on disk) is rarely in the exact format a neural network expects (e.g., specific size, numerical range, tensor structure). Furthermore, we often want to apply <strong>data augmentation</strong> during training to artificially increase the diversity of our dataset and make the model more robust. This is where <strong>transforms</strong> come in.</p>
<p>Transforms are functions/classes that perform operations on your data, usually applied within the <code>Dataset</code>’s <code>__getitem__</code> method. For images, the <code>torchvision.transforms</code> module provides a wide array of useful transforms.</p>
<section id="common-preprocessing-transforms" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="common-preprocessing-transforms"><strong>Common Preprocessing Transforms</strong></h4>
<ul>
<li><code>transforms.Resize((height, width))</code>: Resizes the input image to a specific size.</li>
<li><code>transforms.CenterCrop(size)</code>: Crops the center of the image.</li>
<li><code>transforms.ToTensor()</code>: <strong>Crucial!</strong> Converts a PIL Image or NumPy array (H x W x C, range [0, 255]) into a PyTorch FloatTensor (C x H x W, range [0.0, 1.0]). It handles the necessary dimension reordering and scaling.</li>
<li><code>transforms.Normalize(mean, std)</code>: Normalizes a tensor image with a specified mean and standard deviation for each channel. This helps stabilize training, as models often perform better with input features centered around zero with unit variance. <code>mean</code> and <code>std</code> are often pre-computed on large datasets like ImageNet as we often use models pre-trained on them for transfer learning.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><code>ToTensor()</code> is a crucial transform that it’s almost <em>always</em> required working with image data from PIL or NumPy, as it performs the necessary conversion and reshaping (HWC -&gt; CHW) that models expect.</p>
</div>
</div>
</section>
<section id="common-augmentation-transforms-usually-only-applied-to-training-data" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="common-augmentation-transforms-usually-only-applied-to-training-data"><strong>Common Augmentation Transforms (Usually only applied to training data)</strong></h4>
<ul>
<li><code>transforms.RandomHorizontalFlip(p=0.5)</code>: Randomly flips the image horizontally with a given probability <code>p</code>.</li>
<li><code>transforms.RandomRotation(degrees)</code>: Randomly rotates the image by a certain angle range.</li>
<li><code>transforms.ColorJitter(...)</code>, <code>transforms.RandomResizedCrop(...)</code>, etc.</li>
</ul>
</section>
<section id="chaining-transforms-with-compose" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="chaining-transforms-with-compose"><strong>Chaining Transforms with <code>Compose</code></strong></h4>
<p>Typically, you want to apply multiple transforms in sequence. <code>transforms.Compose</code> allows you to chain them together neatly:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example transform pipeline for training</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>train_transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    transforms.Resize((<span class="dv">256</span>, <span class="dv">256</span>)),      <span class="co"># Resize</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    transforms.RandomCrop(<span class="dv">224</span>),         <span class="co"># Randomly crop to 224x224</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    transforms.RandomHorizontalFlip(),  <span class="co"># Augmentation</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),              <span class="co"># Convert to tensor (scales to [0, 1])</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    transforms.Normalize(mean<span class="op">=</span>[<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>], <span class="co"># ImageNet stats</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>                         std<span class="op">=</span>[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>])  <span class="co"># Normalize</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Example transform pipeline for validation/testing (no augmentation)</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>val_transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    transforms.Resize((<span class="dv">224</span>, <span class="dv">224</span>)),      <span class="co"># Resize directly to final size</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),              <span class="co"># Convert to tensor</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    transforms.Normalize(mean<span class="op">=</span>[<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>],</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>                         std<span class="op">=</span>[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>])</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="conceptual-example-of-a-custom-dataset-and-transforms" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="conceptual-example-of-a-custom-dataset-and-transforms"><strong>Conceptual Example of a Custom Dataset and Transforms</strong></h4>
<p>The transform pipeline is usually passed to the <code>Dataset</code> during initialization and applied within <code>__getitem__</code>.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume necessary imports like os, pandas, PIL.Image, torch etc.</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CustomImageDataset(Dataset):</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, annotations_file, img_dir, transform<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co">            annotations_file (string): Path to the csv file with annotations.</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co">            img_dir (string): Directory with all the images.</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co">            transform (callable, optional): Optional transform to be applied on a sample.</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.img_labels <span class="op">=</span> <span class="va">self</span>._load_annotations(annotations_file) <span class="co"># e.g., load into pandas DataFrame</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.img_dir <span class="op">=</span> img_dir</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _load_annotations(<span class="va">self</span>, file_path):</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Implement logic to load image names and labels, e.g., from a CSV</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Return something like a list of tuples: [('image1.jpg', 0), ('image2.jpg', 1), ...]</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span> </span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Returns the total number of samples</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.img_labels) </span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 1. Get image path and label based on index</span></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>        img_path <span class="op">=</span> os.path.join(<span class="va">self</span>.img_dir, <span class="va">self</span>.img_labels[idx][<span class="dv">0</span>]) </span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> <span class="va">self</span>.img_labels[idx][<span class="dv">1</span>] </span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 2. Load image (e.g., using PIL)</span></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> Image.<span class="bu">open</span>(img_path).convert(<span class="st">"RGB"</span>) <span class="co"># Example loading</span></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 3. Apply transformations HERE before returning (if any) - e.g., resize, normalize, convert to tensor</span></span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.transform:</span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>            image <span class="op">=</span> <span class="va">self</span>.transform(image)</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 4. Return the sample (image tensor, label tensor)</span></span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> image, torch.tensor(label, dtype<span class="op">=</span>torch.<span class="bu">long</span>) </span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Usage (conceptual):</span></span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a><span class="co"># train_dataset = CustomImageDataset(annotations_file='labels.csv', img_dir='images/', transform=train_transform)</span></span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a><span class="co"># val_dataset = CustomImageDataset(annotations_file='labels.csv', img_dir='images/', transform=val_transform)</span></span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a><span class="co"># inputs, labels = train_dataset[0] # Get the first sample</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick Thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why do we typically apply data augmentation transforms (like RandomHorizontalFlip or RandomRotation) only to the training data and not to the validation or test data?</p>
<p><em>Hint: What is the goal of augmentation? What do we want to measure during validation/testing?</em></p>
</div>
</div>
</section>
</section>
<section id="torch.utils.data.dataloader" class="level3" data-number="7.5.3">
<h3 data-number="7.5.3" class="anchored" data-anchor-id="torch.utils.data.dataloader"><span class="header-section-number">7.5.3</span> <code>torch.utils.data.DataLoader</code></h3>
<p>Now that our <code>Dataset</code> (with transforms) can provide processed individual samples, we need an efficient way to iterate over these samples in batches for training. This is the job of the <code>DataLoader</code>.</p>
<p><code>DataLoader</code> wraps a <code>Dataset</code> and provides an <strong>iterator</strong> that yields batches of data automatically. It handles the complexities of:</p>
<ul>
<li><strong>Batching</strong>: Grouping individual samples fetched from the <code>Dataset</code> into mini-batches.</li>
<li><strong>Shuffling</strong>: Randomly shuffling the data indices at the beginning of each epoch (crucial for effective training).</li>
<li><strong>Parallel Loading</strong>: Using multiple subprocesses (<code>num_workers</code>) to load data in the background, preventing data loading from becoming a bottleneck during training.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><code>num_workers</code> &gt; 0 means that the data loading uses subprocesses for loading. It’s best to start from 0 (main process) or a small number (e.g., 2 or 4) and increase it cautiously, as too many workers can sometimes cause issues or increase overhead, depending on your system.</p>
</div>
</div>
<section id="creating-and-using-a-dataloader" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="creating-and-using-a-dataloader"><strong>Creating and Using a DataLoader</strong></h4>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume 'train_dataset' and 'val_dataset' are instances of a Dataset class</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># (potentially using train_transform and val_transform respectively)</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataLoader for the training set</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    dataset<span class="op">=</span>train_dataset, </span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">64</span>,     <span class="co"># How many samples per batch</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span>,      <span class="co"># Shuffle data every epoch (IMPORTANT for training)</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span><span class="dv">4</span>      <span class="co"># Number of subprocesses for data loading (adjust based on system)</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pin_memory=True  # Often used with GPU for faster memory transfers</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataLoader for the validation set</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>val_loader <span class="op">=</span> DataLoader(</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>    dataset<span class="op">=</span>val_dataset,</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">128</span>,    <span class="co"># Can often use larger batch size for validation</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">False</span>,     <span class="co"># No need to shuffle validation data</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span><span class="dv">4</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pin_memory=True</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a><span class="co"># How to iterate over the DataLoader in a training loop:</span></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>num_epochs<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training phase</span></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># model.train() </span></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx, (inputs, labels) <span class="kw">in</span> <span class="bu">enumerate</span>(train_loader):</span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 'inputs' is a batch of images, 'labels' is a batch of labels</span></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Move inputs and labels to the correct device (e.g., GPU)</span></span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># inputs, labels = inputs.to(device), labels.to(device)</span></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- Your training steps ---</span></span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ... (as shown previously) ...</span></span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ---------------------------</span></span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> batch_idx <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>: <span class="co"># Print progress every 100 batches</span></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  Batch </span><span class="sc">{</span>batch_idx<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(train_loader)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Validation phase (using val_loader)</span></span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># model.eval() </span></span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a>    <span class="co"># with torch.no_grad():</span></span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a>    <span class="co">#    for inputs, labels in val_loader:</span></span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a>            <span class="co"># inputs, labels = inputs.to(device), labels.to(device)</span></span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ... evaluation logic ...</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="summary-dataset-transforms-and-dataloader" class="level3" data-number="7.5.4">
<h3 data-number="7.5.4" class="anchored" data-anchor-id="summary-dataset-transforms-and-dataloader"><span class="header-section-number">7.5.4</span> Summary: <code>Dataset</code>, Transforms, and <code>DataLoader</code></h3>
<p>These three components form a powerful pipeline for feeding data to your models:</p>
<ol type="1">
<li><p><code>Dataset</code>: Defines access to individual raw data samples and applies necessary <strong>Transforms</strong>.</p></li>
<li><p>Transforms (<code>torchvision.transforms</code>): Preprocess (resize, normalize, ToTensor) and optionally augment individual samples within the <code>Dataset</code>.</p></li>
<li><p><code>DataLoader</code>: Efficiently wraps the <code>Dataset</code> to provide shuffled batches of processed data, often using parallel workers.</p></li>
</ol>
<p>Using this pipeline makes your data loading code clean, efficient, standardized, and ready for training.</p>
</section>
</section>
<section id="model-building-nn.module-layers-and-containers" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="model-building-nn.module-layers-and-containers"><span class="header-section-number">7.6</span> Model Building: <code>nn.Module</code>, Layers, and Containers</h2>
<p>In our journey through the “Building Blocks of Deep Learning,” we explored the concept of <strong>Models</strong> – the architectures composed of various layers (like Convolutional, Fully-Connected, Activation layers) that learn to map inputs to outputs. Now, we’ll see how to construct these models using PyTorch’s powerful <code>torch.nn</code> module.</p>
<section id="the-torch.nn-namespace" class="level3" data-number="7.6.1">
<h3 data-number="7.6.1" class="anchored" data-anchor-id="the-torch.nn-namespace"><span class="header-section-number">7.6.1</span> The <code>torch.nn</code> Namespace</h3>
<p><code>torch.nn</code> is PyTorch’s dedicated library for building neural networks. It provides implementations of common layers, activation functions, loss functions, and other essential building blocks. The most fundamental component within <code>torch.nn</code> for creating any neural network is the <code>nn.Module</code> base class.</p>
</section>
<section id="nn.module-the-base-for-all-models" class="level3" data-number="7.6.2">
<h3 data-number="7.6.2" class="anchored" data-anchor-id="nn.module-the-base-for-all-models"><span class="header-section-number">7.6.2</span> <code>nn.Module</code>: The Base for All Models</h3>
<p>Every neural network model and every custom layer you build in PyTorch should be a class that inherits from <code>nn.Module</code>. This base class provides a lot of essential functionality behind the scenes, such as tracking the model’s parameters (weights and biases) and offering helpful methods (like <code>.to(device)</code> to move the model to a GPU, or <code>.parameters()</code> to get all learnable weights).</p>
<p>When creating your custom model class, you typically need to implement two key methods:</p>
<ol type="1">
<li><strong><code>__init__(self)</code> (The Constructor):</strong>
<ul>
<li><p>This is where you define and instantiate the layers your network will use. You should assign these layers as attributes of your class (e.g., <code>self.conv1 = nn.Conv2d(...)</code>, <code>self.relu1 = nn.ReLU()</code>, <code>self.fc1 = nn.Linear(...)</code>).</p></li>
<li><p>Layers defined here are automatically registered as sub-modules, allowing <code>nn.Module</code> to track their parameters.</p></li>
</ul></li>
<li><strong><code>forward(self, x)</code> (The Forward Pass):</strong>
<ul>
<li><p>This method defines how the input data <code>x</code> flows through the layers you defined in <code>__init__</code>. You call the layers like functions, passing the output of one layer as the input to the next.</p></li>
<li><p>The <code>forward</code> method specifies the actual computation of your network.</p></li>
</ul></li>
</ol>
<section id="conceptual-structure" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="conceptual-structure"><strong>Conceptual Structure</strong></h4>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F <span class="co"># Often used for functional APIs like activation functions</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyCustomModel(nn.Module):</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>() <span class="co"># IMPORTANT: Call parent class constructor first!</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define layers here - these become tracked parameters</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(in_channels<span class="op">=</span><span class="dv">3</span>, out_channels<span class="op">=</span><span class="dv">16</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relu1 <span class="op">=</span> nn.ReLU()</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool1 <span class="op">=</span> nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">2</span>, stride<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(in_features<span class="op">=</span>..., out_features<span class="op">=</span><span class="dv">10</span>) <span class="co"># '...' depends on conv/pool output size</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># calculating `...` based on the output dimensions of the preceding layers is a common practical step</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define the data flow through the layers</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.conv1(x)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.relu1(x)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool1(x)</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Flatten the output for the fully-connected layer </span></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (e.g., x = torch.flatten(x, 1) # Flatten all dimensions except batch)</span></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.view(x.size(<span class="dv">0</span>), <span class="op">-</span><span class="dv">1</span>) <span class="co"># Alternative flatten using view</span></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc1(x)</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># No activation/softmax here - often applied outside or handled by the loss function</span></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate the model</span></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a><span class="co"># model = MyCustomModel() </span></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a><span class="co"># print(model) # Prints the layers</span></span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a><span class="co"># model.to(device) # Move model to GPU/CPU</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>See we didn’t need to define the <code>backward</code> pass (gradient calculation). It is automatically handled by PyTorch’s Autograd system, as discussed previously. You don’t need to implement it manually when using <code>nn.Module</code> correctly.</p>
</div>
</div>
</section>
<section id="nesting-modules" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="nesting-modules"><strong>Nesting Modules</strong></h4>
<p>You can easily include instances of other <code>nn.Module</code> classes within your model definition, promoting modularity.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define another model that uses CustomModel internally</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyCustomModel2(nn.Module):</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model1 <span class="op">=</span> MyCustomModel() <span class="co"># Use instance of the previous model</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear_out <span class="op">=</span> nn.Linear(<span class="dv">5</span>, <span class="dv">1</span>) <span class="co"># Takes output of model1 (size 5)</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.model1(x) <span class="co"># Pass data through the first model</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.linear_out(x) <span class="co"># Pass through the final layer</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an instance</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> MyCustomModel2()</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Nested Model Architecture:</span><span class="ch">\n</span><span class="st">"</span>, model2)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the nested model</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>output2 <span class="op">=</span> model2(input_data)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Output shape from MyCustomModel2: </span><span class="sc">{</span>output2<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>) <span class="co"># Output: torch.Size([32, 1])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="common-layers-in-torch.nn-torch-nn-layers" class="level3" data-number="7.6.3">
<h3 data-number="7.6.3" class="anchored" data-anchor-id="common-layers-in-torch.nn-torch-nn-layers"><span class="header-section-number">7.6.3</span> Common Layers in <code>torch.nn</code> <a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></h3>
<p><code>torch.nn</code> provides a wide variety of pre-built layers. Here are some you’ll frequently encounter, linking back to concepts from the previous lecture:</p>
<ul>
<li><p><strong>Linear Layers</strong></p>
<ul>
<li><code>nn.Linear(in_features, out_features)</code></li>
<li>Applies a linear transformation (fully-connected layer, dense layer, or dense connection).</li>
</ul></li>
<li><p><strong>Convolutional Layers</strong></p>
<ul>
<li><code>nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)</code></li>
<li>Performs 2D convolution, common for image data.</li>
<li><code>nn.Conv1d</code> and <code>nn.Conv3d</code> also exist.</li>
</ul></li>
<li><p><strong>Pooling Layers</strong></p>
<ul>
<li><code>nn.MaxPool2d(kernel_size, stride=None), nn.AvgPool2d(...)</code></li>
<li>Downsamples feature maps.</li>
<li><code>nn.AdaptiveAvgPool2d</code> is also useful.</li>
</ul></li>
<li><p><strong>Activation Functions</strong></p>
<ul>
<li><code>nn.ReLU()</code>, <code>nn.LeakyReLU()</code>, <code>nn.Sigmoid()</code>, <code>nn.Tanh()</code>, <code>nn.Softmax(dim=...)</code></li>
<li>Introduce non-linearity.</li>
<li>Can be used as modules (e.g., <code>nn.ReLU()</code>) or often via the <code>torch.nn.functional</code> API (e.g., <code>F.relu(...)</code>) within the forward method.</li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><code>F.relu(...)</code> is a function call, useful for simple stateless operations like activations within <code>forward</code>, while <code>nn.ReLU()</code> is a module, necessary if the operation has internal state or parameters, though less common for base activations.</p>
</div>
</div>
<ul>
<li><p><strong>Regularization Layers</strong></p>
<ul>
<li><code>nn.Dropout(p=0.5)</code>: Randomly zeros elements during training.</li>
<li><code>nn.BatchNorm1d(num_features)</code>, <code>nn.BatchNorm2d(...)</code>: Normalizes activations across a batch.</li>
<li>Help prevent overfitting and stabilize training.</li>
</ul></li>
<li><p><strong>Recurrent Layers</strong></p>
<ul>
<li><code>nn.LSTM(input_size, hidden_size, batch_first=False)</code>, <code>nn.GRU(...)</code></li>
<li>For sequential data.</li>
</ul></li>
<li><p><strong>Transformer Layers</strong></p>
<ul>
<li><code>nn.Transformer(...)</code>, <code>nn.TransformerEncoderLayer(...)</code>, <code>nn.TransformerDecoderLayer(...)</code>, <code>nn.MultiheadAttention(...)</code></li>
<li>Building blocks for Transformer models.</li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>For a complete list of all available layers, refer to the <a href="https://pytorch.org/docs/stable/nn.html">torch.nn documentation</a>.</p>
</div>
</div>
</section>
<section id="organizing-models-containers" class="level3" data-number="7.6.4">
<h3 data-number="7.6.4" class="anchored" data-anchor-id="organizing-models-containers"><span class="header-section-number">7.6.4</span> Organizing Models: Containers</h3>
<p>For clarity and structure, especially in complex models, PyTorch provides container modules:</p>
<section id="nn.sequential" class="level5 unnumbered">
<h5 class="unnumbered anchored" data-anchor-id="nn.sequential"><strong>1. <code>nn.Sequential</code></strong></h5>
<ul>
<li>A container that stacks layers sequentially. Data passed to it flows through each layer in the order they were added (no skipping, branching, or complex connections).</li>
<li>Convenient for simple, linear architectures.</li>
</ul>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a model using Sequential</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>sequential_model <span class="op">=</span> nn.Sequential(</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    nn.Linear(<span class="dv">10</span>, <span class="dv">20</span>),</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    nn.ReLU(),</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    nn.Linear(<span class="dv">20</span>, <span class="dv">5</span>) </span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Sequential Model:</span><span class="ch">\n</span><span class="st">"</span>, sequential_model)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>output_seq <span class="op">=</span> sequential_model(input_data)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Output shape from Sequential: </span><span class="sc">{</span>output_seq<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>) <span class="co"># Output: torch.Size([32, 5])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="nn.modulelist" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="nn.modulelist"><strong>2. <code>nn.ModuleList</code></strong></h4>
<ul>
<li><p>Holds modules in a Python list-like structure. Useful when you need to iterate over layers or access them by index, perhaps applying them within a loop or complex control flow in your <code>forward</code> method.</p></li>
<li><p>Unlike a standard Python list, modules inside <code>ModuleList</code> are correctly registered (parameters are tracked by PyTorch).</p></li>
</ul>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a model using ModuleList (layers applied manually in forward)</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ModuleListModel(nn.Module):</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> nn.ModuleList([</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">10</span>, <span class="dv">20</span>), </span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(), </span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">20</span>, <span class="dv">5</span>)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> <span class="va">self</span>.layers: <span class="co"># Manually iterate and apply layers</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> layer(x)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>module_list_model <span class="op">=</span> ModuleListModel()</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">ModuleList Model:</span><span class="ch">\n</span><span class="st">"</span>, module_list_model)</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>output_ml <span class="op">=</span> module_list_model(input_data)</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Output shape from ModuleListModel: </span><span class="sc">{</span>output_ml<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>) <span class="co"># Output: torch.Size([32, 5])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="nn.moduledict" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="nn.moduledict"><strong>3. <code>nn.ModuleDict</code></strong></h4>
<ul>
<li>Holds modules in a Python dictionary-like structure. Allows you to access layers by name (key).</li>
<li>Useful for organizing named components or selecting specific layers dynamically in the <code>forward</code> method. Modules are correctly registered.</li>
</ul>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a model using ModuleDict</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ModuleDictModel(nn.Module):</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> nn.ModuleDict({</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">'input_layer'</span>: nn.Linear(<span class="dv">10</span>, <span class="dv">20</span>),</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>            <span class="st">'activation'</span>: nn.ReLU(),</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">'output_layer'</span>: nn.Linear(<span class="dv">20</span>, <span class="dv">5</span>)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.layers[<span class="st">'input_layer'</span>](x)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.layers[<span class="st">'activation'</span>](x)</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.layers[<span class="st">'output_layer'</span>](x)</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>module_dict_model <span class="op">=</span> ModuleDictModel()</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">ModuleDict Model:</span><span class="ch">\n</span><span class="st">"</span>, module_dict_model)</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>output_md <span class="op">=</span> module_dict_model(input_data)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Output shape from ModuleDictModel: </span><span class="sc">{</span>output_md<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>) <span class="co"># Output: torch.Size([32, 5])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick Thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>When would you choose to define a model by subclassing <code>nn.Module</code> versus using <code>nn.Sequential</code>?</p>
<p><em>Hint: Think about the complexity of the data flow through the layers.</em></p>
</div>
</div>
</section>
</section>
<section id="accessing-model-parameters" class="level3" data-number="7.6.5">
<h3 data-number="7.6.5" class="anchored" data-anchor-id="accessing-model-parameters"><span class="header-section-number">7.6.5</span> Accessing Model Parameters</h3>
<p>Once you’ve defined your model (either via <code>nn.Module</code> or a container), PyTorch makes it easy to access all of its learnable parameters (weights and biases). Some methods to help you do this are:</p>
<ul>
<li><code>.parameters()</code>: Returns an iterator over all parameters.</li>
<li><code>.named_parameters()</code>: Returns an iterator over all parameters, yielding both the name and the parameter tensor.</li>
<li><code>.named_children()</code>: Returns an iterator over immediate children modules, yielding both the name and the module.</li>
<li><code>.state_dict()</code>: Returns a dictionary containing all model parameters (learnable and non-learnable). We’ll learn more about this later.</li>
</ul>
<div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of accessing parameters</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> param.requires_grad:</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Layer: </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> | Size: </span><span class="sc">{</span>param<span class="sc">.</span>size()<span class="sc">}</span><span class="ss"> | Requires Grad: </span><span class="sc">{</span>param<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of accessing named parameters</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> param.requires_grad:</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Layer: </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> | Size: </span><span class="sc">{</span>param<span class="sc">.</span>size()<span class="sc">}</span><span class="ss"> | Requires Grad: </span><span class="sc">{</span>param<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of accessing children modules</span></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, child <span class="kw">in</span> model.named_children():</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Child: </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> | Module: </span><span class="sc">{</span>child<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of accessing state_dict</span></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">State Dict:</span><span class="ch">\n</span><span class="st">"</span>, model.state_dict().keys()) <span class="co"># Returns a dictionary of all parameters</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>By understanding <code>nn.Module</code>, common layers, and containers, you now have the tools to translate the conceptual model architectures discussed earlier into concrete PyTorch code, ready to be trained.</p>
</section>
</section>
<section id="leveraging-pre-trained-models-transfer-learning" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="leveraging-pre-trained-models-transfer-learning"><span class="header-section-number">7.7</span> Leveraging Pre-trained Models &amp; Transfer Learning</h2>
<p>We’ve just seen how to build neural network models from scratch using <code>nn.Module</code> and various layers. While essential to understand, training large models (especially deep ones like ResNet or VGG) on large datasets (like ImageNet) requires significant data and computational resources (time, powerful GPUs).</p>
<p>Fortunately, we often don’t need to start from zero! Remember the concepts of <strong>Pre-trained Models</strong> and <strong>Transfer Learning</strong> from our “Building Blocks” lecture? The core idea is to take a model already trained on a large general dataset (like ImageNet for images) and adapt it for our specific, often smaller, dataset and task. This usually leads to:</p>
<ul>
<li><strong>Faster development:</strong> Less training time needed.</li>
<li><strong>Lower data requirements:</strong> Works well even with smaller datasets.</li>
<li><strong>Better performance:</strong> Often achieves higher accuracy than training from scratch on limited data.</li>
</ul>
<p>PyTorch makes using pre-trained models incredibly easy, primarily through the <code>torchvision.models</code> module for computer vision tasks (similar libraries exist for other domains, like Hugging Face’s <code>transformers</code> <a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> for NLP).</p>
<section id="loading-pre-trained-models-with-torchvision.models" class="level3" data-number="7.7.1">
<h3 data-number="7.7.1" class="anchored" data-anchor-id="loading-pre-trained-models-with-torchvision.models"><span class="header-section-number">7.7.1</span> Loading Pre-trained Models with <code>torchvision.models</code></h3>
<p>The <code>torchvision.models</code> submodule contains definitions for many popular model architectures (ResNet, VGG, AlexNet, MobileNet, Vision Transformer, etc.) and provides easy access to weights pre-trained on ImageNet.</p>
<p>There are two main ways to load a pre-trained model:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.models <span class="im">as</span> models</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Option 1: Using the newer 'weights' API (Recommended) ---</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># This provides access to different pre-trained weight sets and associated metadata</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># List available weights for resnet18</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># print(models.ResNet18_Weights.DEFAULT) # Often points to IMAGENET1K_V1</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co"># print(models.list_models(weights=models.ResNet18_Weights)) </span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Load resnet18 with the default ImageNet v1 weights</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> models.ResNet18_Weights.DEFAULT <span class="co"># Or models.ResNet18_Weights.IMAGENET1K_V1</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>model_v1 <span class="op">=</span> models.resnet18(weights<span class="op">=</span>weights)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Option 2: Using the older 'pretrained=True' argument ---</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="co"># This typically loads the original ImageNet weights the model was published with</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="co"># model_v2 = models.resnet18(pretrained=True) # Legacy way</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="co"># It's generally recommended to use the 'weights' API for clarity and future options.</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model_v1 </span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the model to evaluation mode if just doing inference/inspection</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>() </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="inspect-the-model" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="inspect-the-model"><strong>Inspect the Model</strong></h4>
<p>Once loaded, you can print the model to see its architecture, paying close attention to the final layer(s), often called the “classifier” or “fully-connected head”.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the ResNet18 architecture</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model) </span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Output will show layers like conv1, bn1, layer1, layer2, ..., avgpool, fc</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Notice the final layer: </span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="co"># (fc): Linear(in_features=512, out_features=1000, bias=True) </span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="co"># This layer outputs 1000 scores, corresponding to the 1000 ImageNet classes.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="adapting-the-model-for-your-task" class="level3" data-number="7.7.2">
<h3 data-number="7.7.2" class="anchored" data-anchor-id="adapting-the-model-for-your-task"><span class="header-section-number">7.7.2</span> Adapting the Model for Your Task</h3>
<p>The key step in transfer learning is adapting this pre-trained model for <em>your</em> specific task, which likely has a different number of output classes. We typically modify the final classification layer. There are two main strategies:</p>
<section id="feature-extraction" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="feature-extraction"><strong>1. Feature Extraction</strong></h4>
<p>Treat the pre-trained model (except the final layer) as a fixed feature extractor. We <em>freeze</em> its weights and only train the weights of the <em>new</em> final layer(s) we add. This is suitable when your dataset is small or very similar to the original dataset (e.g., ImageNet).</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Feature Extraction Example ---</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Freeze all parameters in the pre-trained model</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> param <span class="kw">in</span> model.parameters():</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    param.requires_grad <span class="op">=</span> <span class="va">False</span> <span class="co"># Freeze weights</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Replace the final layer (the 'head')</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co">#    ResNet's final layer is named 'fc'. Others might be 'classifier'.</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>num_features <span class="op">=</span> model.fc.in_features <span class="co"># Get the input feature size of the original fc layer</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>num_my_classes <span class="op">=</span> <span class="dv">10</span> <span class="co"># Example: Your dataset has 10 classes</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a new nn.Linear layer for your task</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>model.fc <span class="op">=</span> nn.Linear(num_features, num_my_classes) </span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">NOTE</span><span class="co">: Parameters of this new layer automatically have requires_grad=True</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, only the parameters of 'model.fc' will be updated during training</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimizer should be created AFTER replacing the head:</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="co"># optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The optimizer should be created <em>after</em> freezing parameters and replacing the head, and should typically <em>only</em> be passed the parameters of the new head. We’ll learn more about optimizers later.</p>
<ul>
<li>By creating the optimizer after replacing the head, we ensure the optimizer knows about the <em>final</em> set of parameters in your model.</li>
<li>By passing only the parameters of the new head, we make the code intent more clear (we only want to update the new head) and slightly more efficient by telling the optimizer exactly which parameters need updating.<br>
</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The name of the final layer (<code>fc</code> in the case of ResNet) can vary depending on the model architecture. You can inspect the model by <code>print(model)</code> to see the exact name.</p>
</div>
</div>
</section>
<section id="fine-tuning" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="fine-tuning"><strong>2. Fine-tuning</strong></h4>
<p>Start with the pre-trained weights, but allow some or all of them (usually the later layers) to be updated during training on your new dataset, typically using a <strong>low learning rate</strong>. This adapts the learned features more closely to your specific task. It generally requires more data than feature extraction.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Fine-tuning Preparation Example ---</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. (Optional) Start by freezing all layers as in feature extraction</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co"># for param in model.parameters():</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co">#    param.requires_grad = False </span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Replace the head (as before)</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>num_features <span class="op">=</span> model.fc.in_features</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>num_my_classes <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>model.fc <span class="op">=</span> nn.Linear(num_features, num_my_classes)</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. (Later, or from the start) Unfreeze some layers for fine-tuning</span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Unfreeze parameters in the last two layers (layer4 and fc)</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="co"># for name, param in model.named_parameters():</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="co">#     if "layer4" in name or "fc" in name:</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a><span class="co">#          param.requires_grad = True</span></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Create the optimizer to train ALL parameters where requires_grad=True</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a><span class="co">#    Use a much smaller learning rate for the pre-trained parts than for the new head.</span></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a><span class="co"># optimizer = torch.optim.Adam([</span></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a><span class="co">#     {'params': model.conv1.parameters(), 'lr': 1e-5}, # Example: Very low LR for early layers</span></span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a><span class="co">#     # ... potentially different LRs for different blocks ...</span></span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a><span class="co">#     {'params': model.layer4.parameters(), 'lr': 1e-4}, </span></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a><span class="co">#     {'params': model.fc.parameters(), 'lr': 1e-3} # Higher LR for the new head</span></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a><span class="co"># ], lr=1e-5) # Default LR if not specified in groups</span></span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Fine-tuning requires careful setup of the optimizer and learning rates.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Fine-tuning usually involves a <em>globally smaller</em> learning rate than training from scratch, even for the unfrozen layers, to avoid destroying the pre-trained features too quickly.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>After potential freezing/unfreezing steps, you can check which parameters require gradients by:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">: requires_grad=</span><span class="sc">{</span>param<span class="sc">.</span>requires_grad<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section>
<section id="input-preprocessing" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="input-preprocessing"><strong>Input Preprocessing</strong></h4>
<p>Pre-trained models were trained with specific input preprocessing steps (image size, normalization mean/standard deviation). <strong>Normally, you’d need to apply these same transformations to your own data when using these models.</strong></p>
<p>Luckily, the newer <code>weights</code> API often provides the necessary transforms:</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the appropriate weights object</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>weights <span class="op">=</span> models.ResNet18_Weights.DEFAULT </span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the preprocessing transforms recommended for these weights</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>preprocess <span class="op">=</span> weights.transforms() </span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Preprocessing Transforms required by model:</span><span class="ch">\n</span><span class="st">"</span>, preprocess)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply these transforms to your input images in your Dataset's __getitem__</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Example usage within Dataset:</span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="co"># image = Image.open(...)</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="co"># input_tensor = preprocess(image) # Apply the transforms</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Using these standard transforms ensures your input data matches what the model expects.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick Thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>You want to adapt a pre-trained ResNet18 model to classify 5 different types of flowers using a small dataset you collected. Which transfer learning strategy (Feature Extraction or Fine-tuning) would likely be the better starting point, and why? What’s the most critical change you need to make to the loaded model object?</p>
<p><em>Hint: Consider dataset size and the main goal of adapting the model.</em></p>
</div>
</div>
<p>Transfer learning with pre-trained models is a cornerstone of modern deep learning practice. PyTorch and <code>torchvision</code> make it accessible, allowing you to leverage powerful models without the need for massive resources, accelerating your path to building effective applications.</p>
</section>
</section>
</section>
<section id="loss-functions-in-pytorch-torch.nn" class="level2" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="loss-functions-in-pytorch-torch.nn"><span class="header-section-number">7.8</span> Loss Functions in PyTorch (<code>torch.nn</code>)</h2>
<p>Recall from the “Building Blocks” lecture that the <strong>Loss Function</strong> is crucial for training. It measures how far the model’s predictions are from the actual target values (the ground truth). This calculated “loss” (a scalar value) tells us how poorly the model is performing on a given sample or batch, and its gradient provides the signal needed by the optimizer to update the model’s parameters.</p>
<p>PyTorch provides a variety of standard loss functions within the <code>torch.nn</code> module. You typically instantiate a loss function object and then call it like a function, passing the model’s predictions and the true targets.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># General pattern:</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co"># criterion = nn.SomeLossFunction()</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ... obtain model predictions and targets ...</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co"># loss = criterion(predictions, targets)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>By default, the loss function will compute the <em>mean</em> loss across the samples in a batch (controlled by the <code>reduction='mean'</code> argument). This results in a single scalar loss value ready for <code>.backward()</code>.</p>
<p>The specific loss function you choose depends heavily on the type of task (regression or classification) and the format of your model’s output.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>For a full list of loss functions, see the <a href="https://pytorch.org/docs/stable/nn.html#loss-functions">PyTorch Loss Functions</a> documentation.</p>
</div>
</div>
<section id="common-loss-functions" class="level3" data-number="7.8.1">
<h3 data-number="7.8.1" class="anchored" data-anchor-id="common-loss-functions"><span class="header-section-number">7.8.1</span> Common Loss Functions</h3>
<section id="for-regression-tasks-predicting-continuous-values" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="for-regression-tasks-predicting-continuous-values"><strong>1. For Regression Tasks (Predicting Continuous Values)</strong></h4>
<ul>
<li><code>nn.MSELoss()</code>: Computes the Mean Squared Error between each element in the prediction and target.
<ul>
<li><strong>Prediction</strong>: Tensor of any shape containing predicted values.</li>
<li><strong>Target</strong>: Tensor of the same shape containing true values.</li>
</ul>
<div class="sourceCode" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>criterion_mse <span class="op">=</span> nn.MSELoss()</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>predicted_values <span class="op">=</span> torch.randn(<span class="dv">10</span>, <span class="dv">1</span>, requires_grad<span class="op">=</span><span class="va">True</span>) <span class="co"># e.g., 10 predictions</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>true_values <span class="op">=</span> torch.randn(<span class="dv">10</span>, <span class="dv">1</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>loss_mse <span class="op">=</span> criterion_mse(predicted_values, true_values)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"MSE Loss: </span><span class="sc">{</span>loss_mse<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><code>nn.L1Loss()</code>: Computes the Mean Absolute Error (MAE). Less sensitive to outliers than MSE.
<ul>
<li><strong>Prediction/Target</strong>: Same shape requirements as <code>MSELoss</code>.</li>
</ul>
<div class="sourceCode" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>criterion_l1 <span class="op">=</span> nn.L1Loss()</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>loss_l1 <span class="op">=</span> criterion_l1(predicted_values, true_values)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"L1 (MAE) Loss: </span><span class="sc">{</span>loss_l1<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><code>nn.SmoothL1Loss()</code>: A combination of L1 and MSE (Huber Loss), often used in object detection bounding box regression. Less sensitive to outliers than MSE but smoother near zero than L1.</li>
</ul>
</section>
<section id="for-classification-tasks-predicting-categories" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="for-classification-tasks-predicting-categories"><strong>2. For Classification Tasks (Predicting Categories)</strong></h4>
<ul>
<li><p><code>nn.CrossEntropyLoss()</code>: <strong>The standard choice for multi-class classification</strong>. This function is particularly convenient because it combines <code>nn.LogSoftmax</code> and <code>nn.NLLLoss</code> in one step.</p>
<ul>
<li><strong>Prediction</strong>: Expects <strong>raw, unnormalized scores (logits)</strong> directly from the model’s final linear layer. Shape: <code>(N, C)</code> where <code>N</code> is batch size and <code>C</code> is the number of classes.</li>
<li><strong>Target</strong>: Expects <code>class indices</code> (long integers) ranging from 0 to C-1. Shape: <code>(N)</code>. <strong>Do not use one-hot encoded targets with this loss</strong>.</li>
</ul>
<div class="sourceCode" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>criterion_ce <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: 4 samples, 3 classes</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>logits <span class="op">=</span> torch.randn(<span class="dv">4</span>, <span class="dv">3</span>, requires_grad<span class="op">=</span><span class="va">True</span>) <span class="co"># Raw output from model</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="co"># True class indices (e.g., sample 0 is class 1, sample 1 is class 0, ...)</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>true_indices <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>], dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>loss_ce <span class="op">=</span> criterion_ce(logits, true_indices)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">CrossEntropy Loss: </span><span class="sc">{</span>loss_ce<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><code>nn.BCEWithLogitsLoss()</code>: <strong>The standard choice for binary classification (two classes) or multi-label classification</strong> (where each sample can belong to multiple classes). It combines a <code>Sigmoid</code> layer with the Binary Cross Entropy loss (<code>nn.BCELoss</code>) for better numerical stability.</p>
<ul>
<li><strong>Prediction</strong>: Expects <strong>raw logits</strong> from the model. Shape typically <code>(N)</code> or <code>(N, 1)</code> for binary, or <code>(N, C)</code> for multi-label.</li>
<li><strong>Target</strong>: Expects <strong>float values</strong> representing probabilities or target labels (usually 0.0 or 1.0). Must have the <em>same shape</em> as the input predictions.</li>
</ul>
<div class="sourceCode" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>criterion_bce <span class="op">=</span> nn.BCEWithLogitsLoss()</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Binary classification, 4 samples</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>binary_logits <span class="op">=</span> torch.randn(<span class="dv">4</span>, requires_grad<span class="op">=</span><span class="va">True</span>) <span class="co"># Raw output for positive class</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="co"># True labels (0.0 or 1.0)</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>binary_targets <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="fl">0.0</span>, <span class="fl">1.0</span>, <span class="fl">0.0</span>])</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>loss_bce <span class="op">=</span> criterion_bce(binary_logits, binary_targets)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"BCEWithLogits Loss: </span><span class="sc">{</span>loss_bce<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Multi-label classification, 2 samples, 3 classes</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>multilabel_logits <span class="op">=</span> torch.randn(<span class="dv">2</span>, <span class="dv">3</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Targets: sample 0 belongs to class 0 &amp; 2; sample 1 belongs to class 1</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>multilabel_targets <span class="op">=</span> torch.tensor([[<span class="fl">1.0</span>, <span class="fl">0.0</span>, <span class="fl">1.0</span>], [<span class="fl">0.0</span>, <span class="fl">1.0</span>, <span class="fl">0.0</span>]], dtype<span class="op">=</span>torch.float32) <span class="co"># Explicit dtype</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>loss_multilabel <span class="op">=</span> criterion_bce(multilabel_logits, multilabel_targets)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Multi-label BCEWithLogits Loss: </span><span class="sc">{</span>loss_multilabel<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><code>nn.BCELoss()</code>: Computes Binary Cross Entropy. Requires the input predictions to <em>already be probabilities</em> (i.e., passed through a <code>Sigmoid</code> layer). Less numerically stable than <code>BCEWithLogitsLoss</code>, which is generally preferred.</p></li>
<li><p><code>nn.NLLLoss()</code>: Negative Log Likelihood loss. Typically used <em>after</em> applying <code>nn.LogSoftmax</code> to the model’s output. <code>nn.CrossEntropyLoss</code> combines these two steps and is usually more convenient for multi-class classification.</p></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Different loss functions have different requirements for their input shapes and targets. Ensure your model’s output and target tensors match the expected shapes and types for the chosen loss function.</p>
</div>
</div>
</section>
</section>
<section id="using-the-loss-function-in-training" class="level3" data-number="7.8.2">
<h3 data-number="7.8.2" class="anchored" data-anchor-id="using-the-loss-function-in-training"><span class="header-section-number">7.8.2</span> Using the Loss Function in Training</h3>
<p>The loss function is used within the training loop after obtaining the model’s predictions:</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Inside a typical training loop ---</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="co"># model = ... (Your nn.Module model)</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="co"># criterion = nn.CrossEntropyLoss() # Choose appropriate loss</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co"># optimizer = ... (Your optimizer)</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="co"># inputs, targets = ... # Your data batch, on the correct device</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Zero gradients</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="co"># optimizer.zero_grad()</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Forward pass: Get model predictions (logits)</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="co"># outputs = model(inputs)</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Calculate loss</span></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a><span class="co"># loss = criterion(outputs, targets) # &lt;&lt;&lt; Use the loss function</span></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Backward pass: Compute gradients</span></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a><span class="co"># loss.backward() # &lt;&lt;&lt; Autograd calculates gradients based on the loss</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Update weights</span></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a><span class="co"># optimizer.step()</span></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick Thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>You are building a model to classify images into 10 categories (cat, dog, bird, …, truck). Your model’s final layer is <code>nn.Linear(..., 10)</code>.</p>
<ol type="1">
<li>Which loss function (<code>nn.CrossEntropyLoss</code> or <code>nn.BCEWithLogitsLoss</code>) is appropriate?</li>
<li>What should the shape of the <code>targets</code> tensor be for a batch size of 32? What should its <code>dtype</code> be?</li>
</ol>
<p><em>Hint: Think about multi-class vs.&nbsp;binary/multi-label, and what <code>nn.CrossEntropyLoss</code> expects.</em></p>
</div>
</div>
<p>Choosing the correct loss function based on your task and ensuring your model’s output and target data formats match its requirements are crucial steps in building a successful PyTorch model.</p>
</section>
</section>
<section id="optimizers-in-pytorch-torch.optim" class="level2" data-number="7.9">
<h2 data-number="7.9" class="anchored" data-anchor-id="optimizers-in-pytorch-torch.optim"><span class="header-section-number">7.9</span> Optimizers in PyTorch (<code>torch.optim</code>)</h2>
<p>In the “Building Blocks” lecture, we learned about <strong>Optimization Algorithms</strong> like Gradient Descent, SGD, Adam, etc. Their purpose is to take the error signal (represented by the loss) and the calculated gradients (telling us the direction of steepest ascent) and use this information to adjust the model’s learnable parameters (weights and biases) in a way that minimizes the loss.</p>
<p>PyTorch implements various optimization algorithms in the <code>torch.optim</code> package.</p>
<section id="instantiating-an-optimizer" class="level3" data-number="7.9.1">
<h3 data-number="7.9.1" class="anchored" data-anchor-id="instantiating-an-optimizer"><span class="header-section-number">7.9.1</span> Instantiating an Optimizer</h3>
<p>To use an optimizer, you first need to create an instance of it, telling it which parameters it should manage and what learning rate to use.</p>
<p>The general pattern is:</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume 'model' is your nn.Module instance</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co"># optimizer = optim.OptimizerName(params_to_optimize, learning_rate, ...)</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Example using Adam:</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.001</span> </span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span>learning_rate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="key-arguments" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="key-arguments"><strong>Key Arguments</strong></h4>
<ul>
<li><p><code>params</code>: An iterable containing the parameters (tensors) the optimizer should update. The most common way to provide this is by passing <code>model.parameters()</code>, which conveniently returns an iterator over all learnable parameters within your <code>nn.Module</code>. For more complex scenarios, one can pass specific lists or dictionaries of parameters. See <a href="#fine-tuning">Fine-tuning in Transfer Learning</a> for an example.</p></li>
<li><p><code>lr</code> <strong>(Learning Rate)</strong>: Controls the step size for parameter updates. This is arguably the most important hyperparameter to tune. Different optimizers often work best with different learning rate ranges.</p></li>
</ul>
</section>
</section>
<section id="common-optimizers" class="level3" data-number="7.9.2">
<h3 data-number="7.9.2" class="anchored" data-anchor-id="common-optimizers"><span class="header-section-number">7.9.2</span> Common Optimizers</h3>
<p><code>torch.optim</code> provides many choices, mirroring the algorithms discussed conceptually:</p>
<ul>
<li><p><code>optim.SGD(params, lr, momentum=0, weight_decay=0, ...)</code></p>
<ul>
<li>Implements Stochastic Gradient Descent.</li>
<li>Often used with the <code>momentum</code> argument (e.g., <code>momentum=0.9</code>) which implements SGD with Momentum, typically leading to faster convergence than basic SGD.</li>
<li>Can optionally include <code>weight_decay</code> for L2 regularization.</li>
<li>Usually requires careful tuning of the learning rate and potentially a learning rate schedule.</li>
</ul></li>
<li><p><code>optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, ...)</code></p>
<ul>
<li>Implements the Adam algorithm.</li>
<li>Combines ideas from Momentum and RMSprop, adapting learning rates for each parameter.</li>
<li>Often works well with default settings (lr=0.001) across a wide range of problems, making it a popular default choice.</li>
</ul></li>
<li><p><code>optim.AdamW(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, ...)</code></p>
<ul>
<li>Adam with decoupled Weight Decay.</li>
<li>Generally preferred over standard Adam when using weight decay (L2 regularization), as it implements it in a potentially more effective way.</li>
</ul></li>
<li><p><code>optim.RMSprop(params, lr=0.01, alpha=0.99, ...)</code></p>
<ul>
<li>Implements the RMSprop algorithm.</li>
<li>Adapts learning rates based on the magnitude of recent gradients.</li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>For a full list of optimizers, see the <a href="https://pytorch.org/docs/stable/optim.html">PyTorch Optimizers</a> documentation.</p>
</div>
</div>
</section>
<section id="using-the-optimizer-in-the-training-loop" class="level3" data-number="7.9.3">
<h3 data-number="7.9.3" class="anchored" data-anchor-id="using-the-optimizer-in-the-training-loop"><span class="header-section-number">7.9.3</span> Using the Optimizer in the Training Loop</h3>
<p>The optimizer performs its main work in two steps within the training loop:</p>
<ol type="1">
<li><p><code>optimizer.zero_grad()</code>: This method <strong>must</strong> be called at the start of each training iteration (before the backward pass). It resets the <code>.grad</code> attribute of all the parameters the optimizer is managing back to zero. This is crucial because, as we learned in the Autograd section, <code>.backward()</code> <em>accumulates</em> gradients into the <code>.grad</code> attribute. Without <code>zero_grad()</code>, gradients from previous batches would add up, leading to incorrect updates.</p></li>
<li><p><code>optimizer.step()</code>: This method is called <em>after</em> the gradients have been computed <code>using loss.backward()</code>. It updates the values of the parameters based on the computed gradients stored in their <code>.grad</code> attribute and the specific update rule of the chosen optimization algorithm (e.g., applying momentum, using adaptive learning rates).</p></li>
</ol>
<section id="the-training-loop-revisited" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="the-training-loop-revisited"><strong>The Training Loop Revisited</strong></h4>
<p>Let’s look at the training loop fragment again, highlighting the optimizer’s role:</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Inside a typical training loop ---</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="co"># model = ... </span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co"># criterion = ...</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co"># optimizer = optim.Adam(model.parameters(), lr=0.001) # Instantiate the optimizer</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="co"># inputs, targets = ... # Your data batch</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="co"># &gt;&gt;&gt; Step 1: Reset gradients from previous iteration</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="co"># optimizer.zero_grad() </span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Forward pass</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="co"># outputs = model(inputs) </span></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate loss</span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a><span class="co"># loss = criterion(outputs, targets) </span></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Backward pass (compute gradients for current batch)</span></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a><span class="co"># loss.backward() </span></span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a><span class="co"># &gt;&gt;&gt; Step 2: Update model parameters using computed gradients</span></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a><span class="co"># optimizer.step() </span></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a><span class="co"># -------------------------------------</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick Thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>What would likely happen during training if you forgot to call <code>optimizer.zero_grad()</code> at the beginning of each iteration?</p>
<p><em>Hint: Remember that gradients accumulate in the <code>.grad</code> attribute.</em></p>
</div>
</div>
</section>
</section>
<section id="learning-rate-scheduling" class="level3" data-number="7.9.4">
<h3 data-number="7.9.4" class="anchored" data-anchor-id="learning-rate-scheduling"><span class="header-section-number">7.9.4</span> Learning Rate Scheduling</h3>
<p>As discussed in the previous lecture, adjusting the learning rate during training can often improve performance and convergence. PyTorch provides tools for this in the <code>torch.optim.lr_scheduler</code> module. You typically create a scheduler after creating your optimizer and call <code>scheduler.step()</code> at the appropriate point in your training loop (often after each epoch, sometimes after each batch depending on the scheduler). Common schedulers include <code>StepLR</code>, <code>MultiStepLR</code>, <code>ReduceLROnPlateau</code>, and <code>CosineAnnealingLR</code>. Exploring schedulers is often a next step after getting a basic training loop working.</p>
<section id="example" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="example"><strong>Example</strong></h4>
<div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the optimizer</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the scheduler</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>scheduler <span class="op">=</span> optim.lr_scheduler.StepLR(optimizer, step_size<span class="op">=</span><span class="dv">7</span>, gamma<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co"># In the training loop</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> inputs, targets <span class="kw">in</span> train_loader:</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ... existing training loop code ...</span></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ... forward pass, loss calculation, backward pass ...</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ... update weights ...</span></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ... call scheduler.step() ...</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The timing of <code>scheduler.step()</code> depends on the scheduler type (e.g., some step per epoch, some per batch, <code>ReduceLROnPlateau</code> steps based on a metric). The example shows it inside the epoch loop, which is common for many schedulers like <code>StepLR</code>.</p>
</div>
</div>
<p>With the optimizer managing parameter updates based on gradients derived from the loss function, we now have almost all the pieces needed to actually train a PyTorch model. The next step is to put them all together in a complete training loop.</p>
</section>
</section>
</section>
<section id="training-a-model-in-pytorch-the-training-loop" class="level2" data-number="7.10">
<h2 data-number="7.10" class="anchored" data-anchor-id="training-a-model-in-pytorch-the-training-loop"><span class="header-section-number">7.10</span> Training a Model in PyTorch (The Training Loop)</h2>
<p>We’ve reached the heart of the process! In the “Building Blocks” lecture, we discussed the <strong>Training</strong> phase – an iterative cycle where the model processes data, calculates errors, and adjusts its parameters to improve. Let’s translate that conceptual loop into PyTorch code.</p>
<section id="the-goal-revisited" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="the-goal-revisited"><strong>The Goal Revisited</strong></h4>
<p>Remember, the objective isn’t just to minimize loss on the training data, but to achieve good <strong>generalization</strong> – performance on new, unseen data. We monitor this using a separate validation dataset.</p>
</section>
<section id="assembling-the-pieces" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="assembling-the-pieces"><strong>Assembling the Pieces</strong></h4>
<p>We’ll use the PyTorch components we’ve learned about:</p>
<ul>
<li><strong>DataLoaders:</strong> <code>train_loader</code> and <code>val_loader</code> (providing batches of inputs and targets).</li>
<li><strong>Model:</strong> An <code>nn.Module</code> instance (e.g., <code>model = MyCustomModel()</code>).</li>
<li><strong>Criterion:</strong> A loss function instance (e.g., <code>criterion = nn.CrossEntropyLoss()</code>).</li>
<li><strong>Optimizer:</strong> An optimizer instance linked to the model’s parameters (e.g., <code>optimizer = optim.Adam(model.parameters(), lr=0.001)</code>).</li>
<li><strong>Device:</strong> The <code>device</code> object (<code>cuda</code> or <code>cpu</code>) for hardware placement.</li>
</ul>
</section>
<section id="the-training-loop-structure" class="level3" data-number="7.10.1">
<h3 data-number="7.10.1" class="anchored" data-anchor-id="the-training-loop-structure"><span class="header-section-number">7.10.1</span> The Training Loop Structure</h3>
<p>Training typically involves two nested loops:</p>
<ol type="1">
<li><strong>Outer Loop (Epochs):</strong> Iterates over the entire dataset multiple times. One pass over the full dataset is called an epoch.</li>
<li><strong>Inner Loop (Batches):</strong> Iterates over the mini-batches provided by the <code>DataLoader</code>. Parameter updates happen after processing each batch.</li>
</ol>
<section id="the-training-loop-steps-inside-the-inner-loop" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="the-training-loop-steps-inside-the-inner-loop"><strong>The Training Loop Steps (Inside the Inner Loop)</strong></h4>
<p>For each batch within an epoch, we perform the following crucial steps:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume DataLoader, Model, Criterion, Optimizer, device are defined</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Also assume train_loader, val_loader are defined</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co"># e.g.</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="co"># model, criterion, optimizer = ..., ..., ...</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="co"># train_loader, val_loader = ..., ...</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="co"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="co"># model.to(device) # Ensure model is on the correct device!</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="co"># scheduler = ... # Optional: define a learning rate scheduler</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">10</span> <span class="co"># Example number of epochs</span></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Training Phase ---</span></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>    model.train() <span class="co"># 1. Set model to training mode (enables dropout, batchnorm updates)</span></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>    epoch_train_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>    epoch_train_samples <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>num_epochs<span class="sc">}</span><span class="ss"> - Training..."</span>)</span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Inner loop: Iterates over batches from the DataLoader</span></span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_idx, (inputs, targets) <span class="kw">in</span> <span class="bu">enumerate</span>(train_loader):</span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 2. Move data to the correct device (must match model's device)</span></span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> inputs.to(device)</span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a>        targets <span class="op">=</span> targets.to(device)</span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 3. Clear previous gradients stored in the optimizer</span></span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 4. Forward pass: Get model outputs (logits)</span></span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(inputs)</span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 5. Calculate loss</span></span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(outputs, targets)</span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 6. Backward pass: Compute gradients of the loss w.r.t. model parameters</span></span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb42-40"><a href="#cb42-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-41"><a href="#cb42-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 7. Update weights using the optimizer and computed gradients</span></span>
<span id="cb42-42"><a href="#cb42-42" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb42-43"><a href="#cb42-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-44"><a href="#cb42-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># --- Track statistics for the epoch ---</span></span>
<span id="cb42-45"><a href="#cb42-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Accumulate loss (weighted by batch size)</span></span>
<span id="cb42-46"><a href="#cb42-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use loss.item() to get the Python scalar value of the loss tensor</span></span>
<span id="cb42-47"><a href="#cb42-47" aria-hidden="true" tabindex="-1"></a>        epoch_train_loss <span class="op">+=</span> loss.item() <span class="op">*</span> inputs.size(<span class="dv">0</span>)</span>
<span id="cb42-48"><a href="#cb42-48" aria-hidden="true" tabindex="-1"></a>        epoch_train_samples <span class="op">+=</span> inputs.size(<span class="dv">0</span>)</span>
<span id="cb42-49"><a href="#cb42-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-50"><a href="#cb42-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (Optional: Print progress within the epoch)</span></span>
<span id="cb42-51"><a href="#cb42-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># if batch_idx % 100 == 99: # Print every 100 batches</span></span>
<span id="cb42-52"><a href="#cb42-52" aria-hidden="true" tabindex="-1"></a>        <span class="co">#     print(f'  Batch {batch_idx + 1}/{len(train_loader)} Current Avg Batch Loss: {loss.item():.4f}')</span></span>
<span id="cb42-53"><a href="#cb42-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-54"><a href="#cb42-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate average training loss for the epoch</span></span>
<span id="cb42-55"><a href="#cb42-55" aria-hidden="true" tabindex="-1"></a>    avg_epoch_train_loss <span class="op">=</span> epoch_train_loss <span class="op">/</span> epoch_train_samples</span>
<span id="cb42-56"><a href="#cb42-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-57"><a href="#cb42-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Validation Phase ---</span></span>
<span id="cb42-58"><a href="#cb42-58" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()  <span class="co"># 1. Set model to evaluation mode (disables dropout, uses running batchnorm stats)</span></span>
<span id="cb42-59"><a href="#cb42-59" aria-hidden="true" tabindex="-1"></a>    epoch_val_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb42-60"><a href="#cb42-60" aria-hidden="true" tabindex="-1"></a>    epoch_val_correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb42-61"><a href="#cb42-61" aria-hidden="true" tabindex="-1"></a>    epoch_val_samples <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb42-62"><a href="#cb42-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-63"><a href="#cb42-63" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>num_epochs<span class="sc">}</span><span class="ss"> - Validation..."</span>)</span>
<span id="cb42-64"><a href="#cb42-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad(): <span class="co"># 2. Disable gradient calculations for efficiency</span></span>
<span id="cb42-65"><a href="#cb42-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> inputs, targets <span class="kw">in</span> val_loader:</span>
<span id="cb42-66"><a href="#cb42-66" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 3. Move data to device</span></span>
<span id="cb42-67"><a href="#cb42-67" aria-hidden="true" tabindex="-1"></a>            inputs <span class="op">=</span> inputs.to(device)</span>
<span id="cb42-68"><a href="#cb42-68" aria-hidden="true" tabindex="-1"></a>            targets <span class="op">=</span> targets.to(device)</span>
<span id="cb42-69"><a href="#cb42-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-70"><a href="#cb42-70" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 4. Forward pass</span></span>
<span id="cb42-71"><a href="#cb42-71" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(inputs)</span>
<span id="cb42-72"><a href="#cb42-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-73"><a href="#cb42-73" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 5. Calculate loss</span></span>
<span id="cb42-74"><a href="#cb42-74" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(outputs, targets)</span>
<span id="cb42-75"><a href="#cb42-75" aria-hidden="true" tabindex="-1"></a>            epoch_val_loss <span class="op">+=</span> loss.item() <span class="op">*</span> inputs.size(<span class="dv">0</span>) <span class="co"># Accumulate validation loss</span></span>
<span id="cb42-76"><a href="#cb42-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-77"><a href="#cb42-77" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 6. Calculate accuracy (example metric)</span></span>
<span id="cb42-78"><a href="#cb42-78" aria-hidden="true" tabindex="-1"></a>            _, predicted_indices <span class="op">=</span> torch.<span class="bu">max</span>(outputs.data, <span class="dv">1</span>) <span class="co"># Get class index with highest score</span></span>
<span id="cb42-79"><a href="#cb42-79" aria-hidden="true" tabindex="-1"></a>            epoch_val_samples <span class="op">+=</span> targets.size(<span class="dv">0</span>)</span>
<span id="cb42-80"><a href="#cb42-80" aria-hidden="true" tabindex="-1"></a>            epoch_val_correct <span class="op">+=</span> (predicted_indices <span class="op">==</span> targets).<span class="bu">sum</span>().item()</span>
<span id="cb42-81"><a href="#cb42-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-82"><a href="#cb42-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate average validation loss and metrics for the epoch</span></span>
<span id="cb42-83"><a href="#cb42-83" aria-hidden="true" tabindex="-1"></a>    avg_epoch_val_loss <span class="op">=</span> epoch_val_loss <span class="op">/</span> epoch_val_samples</span>
<span id="cb42-84"><a href="#cb42-84" aria-hidden="true" tabindex="-1"></a>    avg_epoch_val_accuracy <span class="op">=</span> <span class="fl">100.0</span> <span class="op">*</span> epoch_val_correct <span class="op">/</span> epoch_val_samples</span>
<span id="cb42-85"><a href="#cb42-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-86"><a href="#cb42-86" aria-hidden="true" tabindex="-1"></a>    <span class="co"># (Optional: Step the learning rate scheduler, if defined)</span></span>
<span id="cb42-87"><a href="#cb42-87" aria-hidden="true" tabindex="-1"></a>    <span class="co"># if scheduler:</span></span>
<span id="cb42-88"><a href="#cb42-88" aria-hidden="true" tabindex="-1"></a>    <span class="co">#    scheduler.step() # Or scheduler.step(avg_epoch_val_loss) for ReduceLROnPlateau</span></span>
<span id="cb42-89"><a href="#cb42-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-90"><a href="#cb42-90" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- Print Epoch Summary ---</span></span>
<span id="cb42-91"><a href="#cb42-91" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Summary:"</span>)</span>
<span id="cb42-92"><a href="#cb42-92" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Avg Training Loss: </span><span class="sc">{</span>avg_epoch_train_loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb42-93"><a href="#cb42-93" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Avg Validation Loss: </span><span class="sc">{</span>avg_epoch_val_loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb42-94"><a href="#cb42-94" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Validation Accuracy: </span><span class="sc">{</span>avg_epoch_val_accuracy<span class="sc">:.2f}</span><span class="ss">%"</span>)</span>
<span id="cb42-95"><a href="#cb42-95" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">30</span>)</span>
<span id="cb42-96"><a href="#cb42-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-97"><a href="#cb42-97" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Finished Training"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="key-differences-training-vs.-validation-mode" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="key-differences-training-vs.-validation-mode"><strong>Key Differences: Training vs.&nbsp;Validation Mode</strong></h4>
<p>Notice the crucial differences when running the validation loop:</p>
<ul>
<li><p><code>model.train()</code> vs.&nbsp;<code>model.eval()</code>: These methods switch the behavior of certain layers. <code>model.train()</code> enables dropout and makes BatchNorm use batch statistics. <code>model.eval()</code> disables dropout and makes BatchNorm use its learned running statistics. It’s essential to switch modes correctly.</p></li>
<li><p><strong>Gradient Calculation</strong>: We wrap the validation loop in with <code>torch.no_grad()</code>:. This tells PyTorch not to track operations for gradient calculation, which saves significant memory and computation time, as gradients are not needed for evaluation.</p></li>
<li><p><strong>Optimizer Steps</strong>: We do not call <code>optimizer.zero_grad()</code> or <code>optimizer.step()</code> during validation because we are only evaluating the model, not updating its weights.</p></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick Thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why is it important to call <code>model.eval()</code> before running the validation loop? What might happen if you forget and leave the model in train() mode during validation?</p>
<p><em>Hint: Consider layers like Dropout and Batch Normalization.</em></p>
</div>
</div>
</section>
<section id="monitoring-training" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="monitoring-training"><strong>Monitoring Training</strong></h4>
<p>The average training loss, validation loss, and validation accuracy (or other relevant metrics) calculated each epoch are exactly what you would plot to monitor your training progress, just like the conceptual loss curves discussed in the “Building Blocks” lecture. These plots help you diagnose issues like overfitting (validation loss increasing while training loss decreases) or underfitting (both losses high) and decide when to stop training (e.g., using “early stopping” when validation performance plateaus or worsens).</p>
<p>This complete training loop structure is the foundation for teaching your PyTorch models. While variations exist, these core steps provide a solid starting point for almost any supervised learning task.</p>
</section>
</section>
</section>
<section id="evaluating-a-model-in-pytorch-metrics-test-loop" class="level2" data-number="7.11">
<h2 data-number="7.11" class="anchored" data-anchor-id="evaluating-a-model-in-pytorch-metrics-test-loop"><span class="header-section-number">7.11</span> Evaluating a Model in PyTorch (Metrics &amp; Test Loop)</h2>
<p>In the “Building Blocks” lecture, we discussed the <strong>Inference</strong> phase and the importance of <strong>Evaluating Performance</strong> using metrics beyond just the loss function. While the validation loss calculated during training gives us a good indicator of generalization, a more formal evaluation using task-specific metrics on unseen data (validation or test sets) is crucial.</p>
<section id="why-evaluate" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="why-evaluate"><strong>Why Evaluate?</strong></h4>
<p>Evaluation helps us:</p>
<ul>
<li><strong>Assess Generalization:</strong> Understand how well the model performs on data it wasn’t trained on.</li>
<li><strong>Compare Models:</strong> Objectively compare different architectures or hyperparameters.</li>
<li><strong>Make Decisions:</strong> Decide if the model meets the requirements for its intended application or if further training/tuning is needed.</li>
<li><strong>Report Performance:</strong> Provide unbiased performance metrics (especially using the final test set).</li>
</ul>
</section>
<section id="evaluation-mode-model.eval-and-torch.no_grad" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="evaluation-mode-model.eval-and-torch.no_grad"><strong>Evaluation Mode: <code>model.eval()</code> and <code>torch.no_grad()</code></strong></h4>
<p>As highlighted in the Training Loop section, before performing evaluation or inference, you <strong>must</strong> remember to:</p>
<ol type="1">
<li><strong>Set the model to evaluation mode:</strong> <code>model.eval()</code>
<ul>
<li>This changes the behavior of layers like Dropout (disables it) and Batch Normalization (uses running statistics instead of batch statistics). Failing to do this can lead to inconsistent and worse results.</li>
</ul></li>
<li><strong>Disable gradient computation:</strong> <code>with torch.no_grad():</code>
<ul>
<li>This tells PyTorch not to track gradients, saving memory and computation, as they are not needed for just making predictions.</li>
</ul></li>
</ol>
</section>
<section id="the-evaluation-loop-structure" class="level3" data-number="7.11.1">
<h3 data-number="7.11.1" class="anchored" data-anchor-id="the-evaluation-loop-structure"><span class="header-section-number">7.11.1</span> The Evaluation Loop Structure</h3>
<p>The loop structure for evaluation (on a validation or test set) is very similar to the validation phase shown in the training loop section.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume model, criterion, device, and a DataLoader (e.g., val_loader or test_loader) are defined</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co"># model.to(device) # Ensure model is on the correct device</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Evaluation Phase ---</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()  <span class="co"># 1. Set model to evaluation mode!</span></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>all_targets <span class="op">=</span> []</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>all_predictions <span class="op">=</span> []</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>eval_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Evaluating..."</span>)</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad(): <span class="co"># 2. Disable gradient calculations!</span></span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> inputs, targets <span class="kw">in</span> val_loader: <span class="co"># Or test_loader</span></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 3. Move data to device</span></span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> inputs.to(device)</span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a>        targets <span class="op">=</span> targets.to(device)</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 4. Forward pass</span></span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(inputs) </span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># (Optional) Calculate loss on the batch</span></span>
<span id="cb43-23"><a href="#cb43-23" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(outputs, targets)</span>
<span id="cb43-24"><a href="#cb43-24" aria-hidden="true" tabindex="-1"></a>        eval_loss <span class="op">+=</span> loss.item()</span>
<span id="cb43-25"><a href="#cb43-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-26"><a href="#cb43-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 5. Store predictions and targets for metric calculation</span></span>
<span id="cb43-27"><a href="#cb43-27" aria-hidden="true" tabindex="-1"></a>        <span class="co">#    (Convert to CPU if using external libraries like scikit-learn)</span></span>
<span id="cb43-28"><a href="#cb43-28" aria-hidden="true" tabindex="-1"></a>        <span class="co">#    For classification, store predicted indices or probabilities</span></span>
<span id="cb43-29"><a href="#cb43-29" aria-hidden="true" tabindex="-1"></a>        <span class="co">#    For regression, store predicted values</span></span>
<span id="cb43-30"><a href="#cb43-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-31"><a href="#cb43-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Example for classification:</span></span>
<span id="cb43-32"><a href="#cb43-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># _, predicted_indices = torch.max(outputs.data, 1)</span></span>
<span id="cb43-33"><a href="#cb43-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># all_predictions.append(predicted_indices.cpu()) </span></span>
<span id="cb43-34"><a href="#cb43-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># all_targets.append(targets.cpu())</span></span>
<span id="cb43-35"><a href="#cb43-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-36"><a href="#cb43-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Example for regression:</span></span>
<span id="cb43-37"><a href="#cb43-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># all_predictions.append(outputs.cpu())</span></span>
<span id="cb43-38"><a href="#cb43-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># all_targets.append(targets.cpu())</span></span>
<span id="cb43-39"><a href="#cb43-39" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb43-40"><a href="#cb43-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Concatenate all batches</span></span>
<span id="cb43-41"><a href="#cb43-41" aria-hidden="true" tabindex="-1"></a><span class="co"># all_predictions = torch.cat(all_predictions)</span></span>
<span id="cb43-42"><a href="#cb43-42" aria-hidden="true" tabindex="-1"></a><span class="co"># all_targets = torch.cat(all_targets)</span></span>
<span id="cb43-43"><a href="#cb43-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-44"><a href="#cb43-44" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. Calculate overall metrics after the loop</span></span>
<span id="cb43-45"><a href="#cb43-45" aria-hidden="true" tabindex="-1"></a>avg_eval_loss <span class="op">=</span> eval_loss <span class="op">/</span> <span class="bu">len</span>(val_loader)</span>
<span id="cb43-46"><a href="#cb43-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Average Evaluation Loss: </span><span class="sc">{</span>avg_eval_loss<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb43-47"><a href="#cb43-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-48"><a href="#cb43-48" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Calculate Task-Specific Metrics (see below) --- </span></span>
<span id="cb43-49"><a href="#cb43-49" aria-hidden="true" tabindex="-1"></a><span class="co"># accuracy = ...</span></span>
<span id="cb43-50"><a href="#cb43-50" aria-hidden="true" tabindex="-1"></a><span class="co"># precision = ... </span></span>
<span id="cb43-51"><a href="#cb43-51" aria-hidden="true" tabindex="-1"></a><span class="co"># recall = ...</span></span>
<span id="cb43-52"><a href="#cb43-52" aria-hidden="true" tabindex="-1"></a><span class="co"># mae = ...</span></span>
<span id="cb43-53"><a href="#cb43-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-54"><a href="#cb43-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Finished Evaluation"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="calculating-evaluation-metrics" class="level3" data-number="7.11.2">
<h3 data-number="7.11.2" class="anchored" data-anchor-id="calculating-evaluation-metrics"><span class="header-section-number">7.11.2</span> Calculating Evaluation Metrics</h3>
<p>The core difference during evaluation is calculating meaningful performance metrics based on the collected <code>outputs</code> and <code>targets</code>. The choice of metrics depends heavily on your task:</p>
<section id="common-classification-metrics" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="common-classification-metrics"><strong>Common Classification Metrics</strong></h4>
<ul>
<li><p><strong>Accuracy</strong>: The most straightforward metric – the proportion of correctly classified samples.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Inside Evaluation (after loop, assuming classification) ---</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="co"># total_samples = len(all_targets)</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="co"># correct_predictions = (all_predictions == all_targets).sum().item()</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="co"># accuracy = 100.0 * correct_predictions / total_samples</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Accuracy: {accuracy:.2f}%")</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><strong>Precision</strong>, <strong>Recall</strong>, <strong>F1-Score</strong>: Crucial for understanding model performance, especially with imbalanced datasets.</p>
<ul>
<li>Precision: Of the samples predicted as positive, how many actually were positive? <span class="math inline">\(\frac{TP}{TP + FP}\)</span></li>
<li>Recall (Sensitivity): Of all the actual positive samples, how many did the model find? <span class="math inline">\(\frac{TP}{TP + FN}\)</span></li>
<li>F1-Score: The harmonic mean of Precision and Recall, providing a single balanced score.</li>
</ul></li>
<li><p><strong>Confusion Matrix</strong>: A table showing counts of true vs.&nbsp;predicted classes, useful for identifying specific confusion patterns between classes.</p></li>
<li><p><strong>AUC (Area Under the ROC Curve)</strong>: Measures the ability of the model to distinguish between classes.</p></li>
</ul>
</section>
<section id="common-regression-metrics" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="common-regression-metrics"><strong>Common Regression Metrics</strong></h4>
<ul>
<li><p><strong>Mean Squared Error (MSE) / Root Mean Squared Error (RMSE)</strong>: Average squared difference between predicted and true values. RMSE is the square root of MSE, putting the error back into the original units.</p></li>
<li><p><strong>Mean Absolute Error (MAE)</strong>: Average absolute difference. Less sensitive to outliers than MSE.</p></li>
<li><p><strong>R-squared (R²)</strong>: Coefficient of determination, indicating the proportion of variance in the target variable predictable from the input features.</p></li>
</ul>
</section>
<section id="using-libraries-for-metrics" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="using-libraries-for-metrics"><strong>Using Libraries for Metrics</strong></h4>
<p>Calculating many metrics (especially precision, recall, F1, AUC) correctly can be tricky. It’s highly recommended to use established libraries:</p>
<ul>
<li><p><strong>torchmetrics</strong> <a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>: A PyTorch-native library designed for efficient metric calculation, handling distributed training scenarios as well.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example using torchmetrics (install first: pip install torchmetrics)</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="co"># See docs: https://torchmetrics.readthedocs.io/en/stable/</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchmetrics</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Before the evaluation loop ---</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the metric object (e.g., for multi-class accuracy)</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Move the metric object to the same device as your model and data!</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>metric <span class="op">=</span> torchmetrics.classification.Accuracy(</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>            task<span class="op">=</span><span class="st">"multiclass"</span>,</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>            num_classes<span class="op">=</span>NUM_CLASSES <span class="co"># Replace NUM_CLASSES with your actual number</span></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>        ).to(device)</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Inside the evaluation loop (within torch.no_grad()) ---</span></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a><span class="co"># After getting model 'outputs' and 'targets' on the correct device</span></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a><span class="co"># metric.update(outputs, targets) # Update the metric state with batch results</span></span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a><span class="co"># --- After the evaluation loop ---</span></span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the final metric over all batches</span></span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a><span class="co"># final_accuracy = metric.compute()</span></span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Accuracy (torchmetrics): {final_accuracy:.4f}")</span></span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a><span class="co"># metric.reset() # Reset metric state if you plan to reuse it</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><strong>scikit-learn.metrics</strong> <a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>: A widely used library. Requires converting PyTorch tensors to NumPy arrays (<code>.cpu().numpy()</code>) first.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example using scikit-learn (install first: pip install scikit-learn)</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="co"># See docs: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, precision_recall_fscore_support</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="co"># --- After the evaluation loop ---</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure predictions and targets are numpy arrays on the CPU</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="co"># all_predictions_np = all_predictions.cpu().numpy()</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a><span class="co"># all_targets_np = all_targets.cpu().numpy()</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="co"># accuracy = accuracy_score(all_targets_np, all_predictions_np)</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate precision, recall, and F1-score</span></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a><span class="co"># The 'average' parameter determines how scores are calculated for multi-class problems:</span></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a><span class="co">#   - 'weighted': Calculates metrics for each class and averages them,</span></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a><span class="co">#                 weighted by the number of true instances for each class (support).</span></span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a><span class="co">#                 Good for imbalanced datasets if you care about overall weighted performance.</span></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a><span class="co">#   - 'macro': Calculates metrics for each class and finds their unweighted mean.</span></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a><span class="co">#              Treats all classes equally, regardless of size.</span></span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a><span class="co">#   - 'micro': Calculates metrics globally by counting total true positives,</span></span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a><span class="co">#              false negatives, and false positives across all classes.</span></span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a><span class="co">#              Often equivalent to accuracy.</span></span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a><span class="co">#   - None: Returns the scores for each class individually.</span></span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a>precision, recall, f1, _ <span class="op">=</span> precision_recall_fscore_support(</span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a>                            all_targets_np,</span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a>                            all_predictions_np,</span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a>                            average<span class="op">=</span><span class="st">'weighted'</span> <span class="co"># Choose average method</span></span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a>                        )</span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy (sklearn): </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Precision (weighted): </span><span class="sc">{</span>precision<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Recall (weighted): </span><span class="sc">{</span>recall<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"F1 Score (weighted): </span><span class="sc">{</span>f1<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Quick Thought
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why might accuracy alone be a misleading metric for evaluating a classifier trained on a highly imbalanced dataset (e.g., 99% of samples are class A, 1% are class B)? Which other metrics (Precision, Recall, F1) would give a better picture of performance on the rare class B?</p>
<p><em>Hint: A model predicting class A always would have high accuracy.</em></p>
</div>
</div>
</section>
<section id="the-final-test-set" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="the-final-test-set"><strong>The Final Test Set</strong></h4>
<p>Remember the distinction between validation and test sets. The validation set is used <em>during</em> development to tune hyperparameters (like learning rate, model architecture choices) and for early stopping. The <strong>test set</strong> should be held aside and used only <em>once</em> at the very end of your project to get an unbiased estimate of your final model’s performance on completely unseen data.</p>
<p>Proper evaluation provides crucial insights into your model’s capabilities and limitations, guiding further development and deployment decisions.</p>
</section>
</section>
</section>
<section id="saving-and-loading-models" class="level2" data-number="7.12">
<h2 data-number="7.12" class="anchored" data-anchor-id="saving-and-loading-models"><span class="header-section-number">7.12</span> Saving and Loading Models</h2>
<p>Training a deep learning model can take a significant amount of time and computational resources. Once you have a trained model that performs well, you’ll definitely want to save it!</p>
<section id="why-save-and-load" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="why-save-and-load"><strong>Why Save and Load?</strong></h4>
<ul>
<li><strong>Resume Training:</strong> Save checkpoints during long training runs so you can resume later if interrupted.</li>
<li><strong>Avoid Retraining:</strong> Load a previously trained model for inference or further fine-tuning.</li>
<li><strong>Share Models:</strong> Share your trained model weights with others.</li>
<li><strong>Deployment:</strong> Deploy your model for real-world applications.</li>
</ul>
</section>
<section id="what-to-save-the-state_dict" class="level4 unnumbered">
<h4 class="unnumbered anchored" data-anchor-id="what-to-save-the-state_dict"><strong>What to Save? The <code>state_dict</code></strong></h4>
<p>PyTorch models have an internal state dictionary (<code>state_dict</code>) that contains all their learnable parameters (weights and biases) and potentially persistent buffers (like the running mean/variance in BatchNorm layers).</p>
<p>While you <em>can</em> save the entire model object using <code>torch.save(model, PATH)</code>, this is <strong>generally not recommended</strong> because it binds the saved file to the specific code structure used when saving. It can easily break if you refactor your code or use it in a different project.</p>
<p>The <strong>recommended and most common practice</strong> is to save only the model’s <code>state_dict</code>. This is more lightweight, portable, and less likely to break.</p>
</section>
<section id="saving-the-state_dict" class="level3" data-number="7.12.1">
<h3 data-number="7.12.1" class="anchored" data-anchor-id="saving-the-state_dict"><span class="header-section-number">7.12.1</span> Saving the <code>state_dict</code></h3>
<p>This saves only the model’s learned parameters.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume 'model' is your trained nn.Module instance</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume 'PATH' is the desired file path, e.g., 'my_model_weights.pth' or '.pt'</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Saving the state_dict</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>PATH <span class="op">=</span> <span class="st">"my_trained_model.pth"</span></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>torch.save(model.state_dict(), PATH) </span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Model state_dict saved to </span><span class="sc">{</span>PATH<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The common extension for PyTorch models is <code>.pth</code> or <code>.pt</code>. There are some <a href="https://github.com/pytorch/pytorch/issues/14864">discussions</a> about just using <code>.pt</code> because <code>.pth</code> is a special extension for Python.</p>
</div>
</div>
</section>
<section id="loading-the-state_dict" class="level3" data-number="7.12.2">
<h3 data-number="7.12.2" class="anchored" data-anchor-id="loading-the-state_dict"><span class="header-section-number">7.12.2</span> Loading the <code>state_dict</code></h3>
<p>To load the parameters, you <strong>must first create an instance of the same model architecture</strong> you used during training. Then, you load the saved <code>state_dict</code> into it.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume 'YourModelClass' is the class definition for your model</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Make sure the class definition is available!</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Instantiate the model structure</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>model_loaded <span class="op">=</span> YourModelClass(<span class="op">*</span>args, <span class="op">**</span>kwargs) <span class="co"># Use same args as original model</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Load the saved state_dict</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>PATH <span class="op">=</span> <span class="st">"my_trained_model.pth"</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>state_dict <span class="op">=</span> torch.load(PATH) </span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Load the state_dict into the model instance</span></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>model_loaded.load_state_dict(state_dict)</span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a><span class="co"># By default, load_state_dict uses strict=True, meaning the keys in the</span></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a><span class="co"># state_dict must exactly match the keys returned by the model's state_dict() method.</span></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Setting strict=False can be useful in some transfer learning scenarios</span></span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a><span class="co"># if you only want to load partial weights, but requires caution.</span></span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. CRUCIAL: Set the model to evaluation mode if using for inference</span></span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a>model_loaded.<span class="bu">eval</span>()</span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Model state_dict loaded successfully."</span>)</span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Now you can use model_loaded for inference:</span></span>
<span id="cb48-24"><a href="#cb48-24" aria-hidden="true" tabindex="-1"></a><span class="co"># with torch.no_grad():</span></span>
<span id="cb48-25"><a href="#cb48-25" aria-hidden="true" tabindex="-1"></a><span class="co">#    predictions = model_loaded(some_input_data.to(device))</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Remember to call <code>model.eval()</code> after loading the weights if you intend to use the model for inference, to ensure layers like Dropout and BatchNorm are in the correct mode.</p>
</div>
</div>
</section>
<section id="saving-checkpoints-for-resuming-training" class="level3" data-number="7.12.3">
<h3 data-number="7.12.3" class="anchored" data-anchor-id="saving-checkpoints-for-resuming-training"><span class="header-section-number">7.12.3</span> Saving Checkpoints for Resuming Training</h3>
<p>Sometimes, you need to save more than just the model weights to resume training effectively. A common practice is to save a checkpoint dictionary containing:</p>
<ul>
<li>The model’s <code>state_dict</code>.</li>
<li>The optimizer’s <code>state_dict</code> (to resume optimization state like momentum).</li>
<li>The current epoch number.</li>
<li>The last recorded loss.</li>
<li>Any other necessary information (e.g., <code>lr_scheduler.state_dict()</code>).</li>
</ul>
<div class="sourceCode" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Example: Saving a Checkpoint ---</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume epoch, loss, optimizer are defined</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>checkpoint <span class="op">=</span> {</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'epoch'</span>: epoch,</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'model_state_dict'</span>: model.state_dict(),</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'optimizer_state_dict'</span>: optimizer.state_dict(),</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'loss'</span>: loss,</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add anything else needed: 'scheduler_state_dict': scheduler.state_dict(), etc.</span></span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>CHECKPOINT_PATH <span class="op">=</span> <span class="ss">f"model_epoch_</span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">.pth"</span></span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>torch.save(checkpoint, CHECKPOINT_PATH)</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Checkpoint saved to </span><span class="sc">{</span>CHECKPOINT_PATH<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Example: Loading a Checkpoint to Resume Training ---</span></span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a><span class="co"># model = YourModelClass(*args, **kwargs)</span></span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a><span class="co"># optimizer = optim.Adam(model.parameters(), lr=...) # Create optimizer *before* loading state</span></span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a><span class="co"># CHECKPOINT_PATH = "model_epoch_X.pth" # Path to the checkpoint file</span></span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a><span class="co"># checkpoint = torch.load(CHECKPOINT_PATH)</span></span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a><span class="co"># model.load_state_dict(checkpoint['model_state_dict'])</span></span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a><span class="co"># optimizer.load_state_dict(checkpoint['optimizer_state_dict'])</span></span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a><span class="co"># start_epoch = checkpoint['epoch'] + 1 # Resume from next epoch</span></span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a><span class="co"># last_loss = checkpoint['loss']</span></span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a><span class="co"># # Load scheduler state if saved: scheduler.load_state_dict(...)</span></span>
<span id="cb49-28"><a href="#cb49-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-29"><a href="#cb49-29" aria-hidden="true" tabindex="-1"></a><span class="co"># model.train() # Set model to train mode to resume training</span></span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a><span class="co"># # Or model.eval() if loading just for evaluation</span></span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Checkpoint loaded. Resuming from epoch {start_epoch}")</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="handling-devices-cpugpu" class="level3" data-number="7.12.4">
<h3 data-number="7.12.4" class="anchored" data-anchor-id="handling-devices-cpugpu"><span class="header-section-number">7.12.4</span> Handling Devices (CPU/GPU)</h3>
<p>By default, <code>torch.save</code> saves tensors on the device they currently reside on. To make your saved models more portable (e.g., load a GPU-trained model on a CPU-only machine), it’s good practice to save the <code>state_dict</code> after moving the model to the CPU.</p>
<p>When loading, use the <code>map_location</code> argument in <code>torch.load</code> to specify where you want the tensors to be loaded.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Saving for Portability (Recommended) ---</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Move model to CPU before getting state_dict</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>torch.save(model.to(<span class="st">'cpu'</span>).state_dict(), PATH)</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Loading with map_location ---</span></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Load onto CPU explicitly</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>state_dict_cpu <span class="op">=</span> torch.load(PATH, map_location<span class="op">=</span>torch.device(<span class="st">'cpu'</span>))</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a><span class="co"># model.load_state_dict(state_dict_cpu)</span></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Load onto the current 'device' (GPU if available, else CPU)</span></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a><span class="co"># device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</span></span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a><span class="co"># state_dict_mapped = torch.load(PATH, map_location=device)</span></span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a><span class="co"># model = YourModelClass(...) # Instantiate model</span></span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a><span class="co"># model.load_state_dict(state_dict_mapped) # Load state dict</span></span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a><span class="co"># model.to(device) # Ensure model is on the correct device</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>For more details and advanced scenarios, refer to the official <a href="https://pytorch.org/tutorials/beginner/saving_loading_models.html">PyTorch documentation on saving and loading models</a>.</p>
</div>
</div>
<p>Saving and loading models, especially using the <code>state_dict</code>, is a fundamental skill for any PyTorch practitioner, enabling persistence, sharing, and deployment.</p>
</section>
</section>
<section id="common-pitfalls-and-best-practices" class="level2" data-number="7.13">
<h2 data-number="7.13" class="anchored" data-anchor-id="common-pitfalls-and-best-practices"><span class="header-section-number">7.13</span> Common Pitfalls and Best Practices</h2>
<p>As you start building and training models with PyTorch, you might run into a few common challenges. Here are some of the most common pitfalls and best practices to keep in mind:</p>
<ol type="1">
<li><p><strong>Pitfall: Tensor Shape Mismatches</strong></p>
<ul>
<li><p><strong>Problem:</strong> Layers expect inputs of specific dimensions (e.g., <code>nn.Linear</code> expects <code>(BatchSize, InFeatures)</code>, <code>nn.Conv2d</code> expects <code>(BatchSize, InChannels, Height, Width)</code>). Feeding a tensor with an incorrect shape will cause runtime errors. This often happens when flattening convolutional outputs before a linear layer or forgetting the batch dimension.</p></li>
<li><p><strong>Best Practice:</strong></p>
<ul>
<li><strong>Print Shapes Frequently:</strong> Sprinkle <code>print(tensor.shape)</code> throughout your model’s <code>forward</code> method during debugging to track how dimensions change.</li>
<li><strong>Read Documentation:</strong> Carefully check the expected input/output shapes for each PyTorch layer you use.</li>
<li><strong>Use <code>torch.flatten(x, 1)</code> or <code>x.view(x.size(0), -1)</code>:</strong> Be mindful when reshaping/flattening. Using <code>view</code> with <code>-1</code> infers one dimension, which is handy but ensure the other dimensions are correct.</li>
</ul></li>
</ul></li>
<li><p><strong>Pitfall: Device Mismatches (CPU vs.&nbsp;GPU)</strong></p>
<ul>
<li><p><strong>Problem:</strong> Trying to perform an operation involving tensors located on different devices (e.g., input data on CPU, model on GPU) results in a runtime error.</p></li>
<li><p><strong>Best Practice:</strong></p>
<ul>
<li><strong>Define <code>device</code> Early:</strong> Use the <code>device = torch.device(...)</code> pattern shown previously.</li>
<li><strong>Move Model:</strong> Move your model to the <code>device</code> <em>once</em> (<code>model.to(device)</code>).</li>
<li><strong>Move Data in Loop:</strong> Consistently move input data and targets to the <em>same</em> <code>device</code> inside your training/evaluation loop (<code>inputs.to(device)</code>, <code>targets.to(device)</code>).</li>
<li><strong>Check <code>.device</code>:</strong> When debugging, check the <code>.device</code> attribute of tensors involved in the failing operation.</li>
</ul></li>
</ul></li>
<li><p><strong>Pitfall: Missmatching Data Types</strong></p>
<ul>
<li><p><strong>Problem:</strong> Some loss functions expect a different data type than the one provided (e.g., using <code>torch.float32</code> targets with <code>BCEWithLogitsLoss</code> that expects <code>torch.float64</code> targets). Operations on tensors of different data types can lead to unexpected results or errors.</p></li>
<li><p><strong>Best Practice:</strong> Check the data type of the tensors consistently especially when the operation is your own.</p></li>
</ul></li>
<li><p><strong>Pitfall: Forgetting <code>optimizer.zero_grad()</code></strong></p>
<ul>
<li><p><strong>Problem:</strong> PyTorch accumulates gradients by default (adds them to the <code>.grad</code> attribute on each <code>.backward()</code> call). If you forget <code>optimizer.zero_grad()</code> at the start of your training loop iteration, gradients from previous batches will interfere with the current update, leading to incorrect training.</p></li>
<li><p><strong>Best Practice:</strong> Make it a habit: <strong>Always</strong> call <code>optimizer.zero_grad()</code> right at the beginning of your training loop iteration before the forward pass.</p></li>
</ul></li>
<li><p><strong>Pitfall: Forgetting <code>loss.backward()</code> or <code>optimizer.step()</code></strong></p>
<ul>
<li><p><strong>Problem:</strong> Forgetting <code>loss.backward()</code> means no gradients are computed. Forgetting <code>optimizer.step()</code> means gradients are computed but the model’s weights are never updated. In either case, the model doesn’t learn.</p></li>
<li><p><strong>Best Practice:</strong> Ensure the standard training sequence is followed within the loop: <code>zero_grad()</code> -&gt; <code>forward</code> -&gt; <code>calculate loss</code> -&gt; <code>backward()</code> -&gt; <code>step()</code>.</p></li>
</ul></li>
<li><p><strong>Pitfall: Incorrect Evaluation Mode (<code>model.eval()</code>, <code>torch.no_grad()</code>)</strong></p>
<ul>
<li><p><strong>Problem:</strong> Forgetting <code>model.eval()</code> during validation/testing means layers like Dropout and BatchNorm behave as they do in training, leading to inaccurate performance assessment. Forgetting <code>with torch.no_grad():</code> means unnecessary computation and memory usage for tracking gradients.</p></li>
<li><p><strong>Best Practice:</strong> Always call <code>model.eval()</code> before evaluation and wrap the evaluation loop in <code>with torch.no_grad():</code>. Remember to call <code>model.train()</code> when switching back to training.</p></li>
</ul></li>
<li><p><strong>Pitfall: Incorrect Loss Function Inputs/Targets</strong></p>
<ul>
<li><p><strong>Problem:</strong> Feeding inputs or targets with incorrect shapes, data types, or formats to the loss function (e.g., probabilities instead of logits for <code>BCEWithLogitsLoss</code>, one-hot encoded targets for <code>CrossEntropyLoss</code>, wrong <code>dtype</code> for targets).</p></li>
<li><p><strong>Best Practice:</strong> Carefully read the documentation for your chosen loss function. Pay close attention to:</p>
<ul>
<li>Expected input format (logits vs.&nbsp;probabilities).</li>
<li>Expected target format (class indices vs.&nbsp;probabilities/labels).</li>
<li>Expected target <code>dtype</code> (<code>torch.long</code> for indices, <code>torch.float</code> for BCE targets).</li>
<li>Expected input/target shapes.</li>
</ul></li>
</ul></li>
<li><p><strong>Pitfall: Unintentionally Breaking the Computation Graph</strong></p>
<ul>
<li><p><strong>Problem:</strong> Performing operations that prevent Autograd from tracking history correctly, often by converting a tensor that requires gradients to NumPy too early, or using non-PyTorch operations mid-graph where gradients are needed.</p></li>
<li><p><strong>Best Practice:</strong> Keep computations within PyTorch tensors as long as gradients are required. Use <code>.detach()</code> explicitly when you need a tensor’s value without its history, or use the <code>.item()</code> method to get the Python scalar value from a single-element tensor <em>after</em> the backward pass or within a <code>no_grad()</code> block.</p></li>
</ul></li>
<li><p><strong>Pitfall: Memory Issues (Especially on GPU)</strong></p>
<ul>
<li><p><strong>Problem:</strong> Running out of GPU memory (CUDA Out of Memory error). Often caused by using excessively large batch sizes, large models, or holding onto unnecessary tensors and their computation history.</p></li>
<li><p><strong>Best Practice:</strong></p>
<ul>
<li>Reduce <code>batch_size</code>.</li>
<li>Use <code>with torch.no_grad():</code> during evaluation.</li>
<li>Use <code>del tensor_variable</code> if large intermediate tensors are no longer needed.</li>
<li>Use <code>.detach()</code> on tensors where history is no longer required.</li>
<li>Consider gradient accumulation or model parallelism for very large models (more advanced).</li>
<li>Monitor memory usage (<code>torch.cuda.memory_allocated()</code>, <code>torch.cuda.memory_summary()</code>).</li>
</ul></li>
</ul></li>
<li><p><strong>Best Practice: Debugging</strong></p>
<ul>
<li>Don’t underestimate simple <code>print()</code> statements to check tensor shapes, dtypes, devices, and values at various points.</li>
<li>Use Python’s standard debugger (<code>pdb</code> or IDE debuggers) – PyTorch’s dynamic nature makes this very effective. Set breakpoints and inspect tensors.</li>
</ul></li>
<li><p><strong>Best Practice: Start Simple and Iterate</strong></p>
<ul>
<li>When building a new model or trying a new technique, start with a very small version of your dataset and a simple model architecture to verify the code runs end-to-end without errors.</li>
<li>Gradually increase complexity, checking results along the way.</li>
</ul></li>
</ol>
<p>Being aware of these common points can help you troubleshoot more effectively and build your PyTorch skills faster. Every developer encounters these issues, so persistence and careful debugging are key!</p>
</section>
<section id="conclusion-bringing-concepts-to-code" class="level2" data-number="7.14">
<h2 data-number="7.14" class="anchored" data-anchor-id="conclusion-bringing-concepts-to-code"><span class="header-section-number">7.14</span> Conclusion: Bringing Concepts to Code</h2>
<p>Congratulations! You’ve successfully navigated the core components of PyTorch, bridging the gap between the fundamental concepts of deep learning and their practical implementation in a powerful framework.</p>
<p>Let’s quickly recap the key PyTorch tools and techniques we’ve explored, seeing how they map back to the deep learning building blocks:</p>
<ol type="1">
<li><p><strong>PyTorch Fundamentals:</strong> We learned what PyTorch is and why it’s useful, focusing on <strong>Tensors</strong> as the core data structure (representing our <strong>Data</strong>) and <strong>Autograd</strong> as the engine for automatic gradient calculation (powering <strong>Backpropagation</strong> for Optimization).</p></li>
<li><p><strong>Data Handling Pipeline:</strong> We saw how <code>Dataset</code>, <code>Transforms</code>, and <code>DataLoader</code> work together to efficiently load, preprocess, augment, and batch our <strong>Data</strong>, preparing it for the model.</p></li>
<li><p><strong>Model Definition:</strong> We explored how to define <strong>Models</strong> using <code>nn.Module</code>, common <code>nn.Layers</code>, and containers like <code>nn.Sequential</code>, translating conceptual architectures into code. We also saw how to leverage <strong>Pre-trained Models</strong> from <code>torchvision.models</code> for Transfer Learning.</p></li>
<li><p><strong>Training Components:</strong> We learned how to instantiate <strong>Loss Functions</strong> (<code>nn.CrossEntropyLoss</code>, <code>nn.MSELoss</code>, etc.) from <code>torch.nn</code> to measure error, and how to use <strong>Optimizers</strong> (<code>torch.optim</code>) like Adam or SGD to update model parameters based on gradients.</p></li>
<li><p><strong>The Workflow:</strong> We put everything together in the <strong>Training Loop</strong>, saw how to <strong>Evaluate</strong> model performance using metrics, and learned the practical necessity of <strong>Saving and Loading</strong> models. We also discussed common pitfalls and best practices to help smooth your development process.</p></li>
</ol>
<p>Understanding these PyTorch components gives you the foundational toolkit needed to implement and experiment with a wide variety of neural networks. You’ve seen how the abstract concepts of data flow, error calculation, and gradient-based learning become concrete operations within this framework.</p>
<p><strong>Next Steps: Hands-On Labs!</strong></p>
<p>We’ve covered a lot of ground conceptually. The best way to solidify this knowledge is through practice! In the upcoming <strong>hands-on labs</strong>, you’ll apply everything we’ve discussed! Get ready to dive into the code and bring these powerful ideas to life!</p>
<div style="display: flex; justify-content: center; align-items: center; width: 100%;">
    <div class="tenor-gif-embed" data-postid="18688447" data-share-method="host" data-aspect-ratio="0.84375" data-width="60%">
        <a href="https://tenor.com/view/lets-do-this-gif-18688447">Lets Do This Meme</a>
        from <a href="https://tenor.com/search/lets+do+this-memes">Lets Do This Memes</a>
    </div>
    <script type="text/javascript" async="" src="https://tenor.com/embed.js"></script>
</div>


</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p><a href="https://pytorch.org">https://pytorch.org</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a href="https://pytorch.org">https://pytorch.org</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><a href="https://pytorch.org/vision/stable/index.html">https://pytorch.org/vision/stable/index.html</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><a href="https://pytorch.org/text/stable/index.html">https://pytorch.org/text/stable/index.html</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p><a href="https://pytorch.org/audio/stable/index.html">https://pytorch.org/audio/stable/index.html</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p><a href="https://pytorch.org/vision/main/models.html">https://pytorch.org/vision/stable/models.html</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p><a href="https://discuss.pytorch.org">https://discuss.pytorch.org</a><a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p><a href="https://huggingface.co">https://huggingface.co/</a><a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch-dtype">PyTorch data types</a><a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p><a href="https://pytorch.org/vision/main/datasets.html">torchvision.datasets</a><a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p><a href="https://pytorch.org/docs/stable/nn.html">torch.nn</a><a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p><a href="https://huggingface.co/docs/transformers/en/index">Hugging Face Transformers</a><a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p><a href="https://lightning.ai/docs/torchmetrics/stable/">torchmetrics</a><a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p><a href="https://scikit-learn.org/stable/api/sklearn.metrics.html">scikit-learn.metrics</a><a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../sections/the-building-blocks-of-nn-and-dl.html" class="pagination-link" aria-label="The Building Blocks of Neural Networks and Deep Learning">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The Building Blocks of Neural Networks and Deep Learning</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../sections/hands-on-lab-pytorch.html" class="pagination-link" aria-label="Hands-On Lab: PyTorch">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Hands-On Lab: PyTorch</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<!-- Default Statcounter code for cyber2a online course
http://cyber2a.github.io/cyber2a-course/ -->
<script type="text/javascript">
    var sc_project=13129980; 
    var sc_invisible=1; 
    var sc_security="fa33fcfd"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async=""></script>
    <noscript><div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img class="statcounter" src="https://c.statcounter.com/13129980/0/fa33fcfd/1/" alt="Web Analytics" referrerpolicy="no-referrer-when-downgrade"></a></div></noscript>
    <!-- End of Statcounter Code -->




</body></html>