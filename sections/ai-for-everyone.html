<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; AI for Everyone: An Introductory Overview – Cyber2A: AI for Arctic Research</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../sections/ai-ready-data-in-arctic-research.html" rel="next">
<link href="../sections/breaking-the-ice-with-ai-in-arctic-science.html" rel="prev">
<link href="../images/index/arcticlogo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-5fd9db47a040b21ac2cac9a0b3b722ba.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../sections/breaking-the-ice-with-ai-in-arctic-science.html"><b>Day 1: Introduction to AI and Arctic Science</b></a></li><li class="breadcrumb-item"><a href="../sections/ai-for-everyone.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI for Everyone</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Cyber2A: AI for Arctic Research</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/cyber2a/cyber2a-course/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Overview</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 1: Introduction to AI and Arctic Science</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/breaking-the-ice-with-ai-in-arctic-science.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Breaking the Ice with AI in Arctic Science</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-for-everyone.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI for Everyone</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-ready-data-in-arctic-research.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">AI-Ready Data in Arctic Research</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/data-annotation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Data Annotation: The Foundation of Deep Learning Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-data-annotation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Hands-On Lab: Data Annotation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 2: AI Fundamentals and Techniques</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/the-building-blocks-of-nn-and-dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The Building Blocks of Neural Networks and Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/intro-to-pytorch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to PyTorch: Core Functionalities and Advantages</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-pytorch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Hands-On Lab: PyTorch</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/permafrost-discovery-gateway.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Permafrost Discovery Gateway</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-ethics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">AI Ethics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 3: Advanced AI Workflows and Models</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/guest-lecture-yili-arts-dataset.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Guest Lecture - Unveiling the ARTS Dataset for a Thawing Frontier</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/exploring-advanced-neural-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Exploring Advanced Neural Networks: Instance Segmentation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/intro-to-dl-libraries-for-image-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Introduction to Deep Learning Libraries for Image Analysis</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 4: Workflows and Foundation Models</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-workflows-and-mlops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">AI Workflows and MLOps: From Development to Deployment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-ai-workflows.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Hands-On Lab: AI Workflows</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/foundation-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Foundation Models: The Cornerstones of Modern AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-foundation-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Hands-On Lab: Foundation Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/reproducibility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Reproducibility</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 5: AI Frontiers</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/the-fun-and-frontiers-of-ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">The Fun and Frontiers of AI: Innovation, Imagination, Interaction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#goals" id="toc-goals" class="nav-link active" data-scroll-target="#goals">Goals</a></li>
  <li><a href="#the-foundations-of-intelligence" id="toc-the-foundations-of-intelligence" class="nav-link" data-scroll-target="#the-foundations-of-intelligence"><span class="header-section-number">2.1</span> The Foundations of Intelligence</a></li>
  <li><a href="#types-of-artificial-intelligence" id="toc-types-of-artificial-intelligence" class="nav-link" data-scroll-target="#types-of-artificial-intelligence"><span class="header-section-number">2.2</span> Types of Artificial Intelligence</a></li>
  <li><a href="#machine-learning" id="toc-machine-learning" class="nav-link" data-scroll-target="#machine-learning"><span class="header-section-number">2.3</span> Machine Learning</a></li>
  <li><a href="#neural-networks" id="toc-neural-networks" class="nav-link" data-scroll-target="#neural-networks"><span class="header-section-number">2.4</span> Neural Networks</a></li>
  <li><a href="#backpropagation" id="toc-backpropagation" class="nav-link" data-scroll-target="#backpropagation"><span class="header-section-number">2.5</span> Backpropagation</a></li>
  <li><a href="#deep-learning" id="toc-deep-learning" class="nav-link" data-scroll-target="#deep-learning"><span class="header-section-number">2.6</span> Deep Learning</a></li>
  <li><a href="#the-future-of-ai-in-arctic-science" id="toc-the-future-of-ai-in-arctic-science" class="nav-link" data-scroll-target="#the-future-of-ai-in-arctic-science"><span class="header-section-number">2.7</span> The Future of AI in Arctic Science</a></li>
  <li><a href="#exercise-nn-playground" id="toc-exercise-nn-playground" class="nav-link" data-scroll-target="#exercise-nn-playground"><span class="header-section-number">2.8</span> Exercise: NN Playground</a></li>
  <li><a href="#do-you-have-any-questions" id="toc-do-you-have-any-questions" class="nav-link" data-scroll-target="#do-you-have-any-questions">Do You Have Any Questions?</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../sections/breaking-the-ice-with-ai-in-arctic-science.html"><b>Day 1: Introduction to AI and Arctic Science</b></a></li><li class="breadcrumb-item"><a href="../sections/ai-for-everyone.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI for Everyone</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI for Everyone: An Introductory Overview</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<style>
figcaption {
  font-size: 0.5em;
}
.tiny.figcaption {
    font-size: 0.1em;
}
.column-margin {
 figcaption {
    font-size: 0.5em;
 }
}
</style>
<section id="goals" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="goals">Goals</h2>
<p>In this chapter, we introduce artificial intelligence to a non-specialist audience. We cover key terminology and the basic principles of intelligence, artificial intelligence, and machine learning. By the end of the chapter, participants will have a solid foundation for the subsequent chapters.</p>
</section>
<section id="the-foundations-of-intelligence" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="the-foundations-of-intelligence"><span class="header-section-number">2.1</span> The Foundations of Intelligence</h2>
<p>Before reading the definition, take a moment to consider: In your own words, what is AI?</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What is AI?
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Artificial Intelligence (AI)</strong> is the field concerned with building computer systems that perform tasks typically requiring cognitive functions associated with human intelligence, such as pattern recognition, learning from data, and making predictions.</p>
</div>
</div>
<p>For a time, one of the goals of AI was to pass the Turing test. The first program often considered to pass a variation of the Turing test was Eugene Goostman, which simulated a 13-year-old boy from Odessa, Ukraine. It passed the Turing test in 2014. Modern chatbots, such as ChatGPT-4, arguably can easily pass the Turing test.<span class="citation" data-cites="jackson2025ai"><a href="../references.html#ref-jackson2025ai" role="doc-biblioref">[1]</a></span> However, as early as the 1980s, philosophers like John Searle argued that passing the Turing test does not prove that a machine is intelligent. This concern is increasingly relevant today. Searle often illustrated his argument with the <strong>Chinese Room thought experiment</strong>.</p>
<ol type="1">
<li>Imagine a person who knows no Chinese locked in a room.</li>
<li>Outside, native Chinese speakers pass written questions into the room.</li>
<li>Inside, the person uses a large rulebook to match the input characters with appropriate responses.</li>
<li>The person inside then passes the answers back out.</li>
</ol>
<p>To outsiders, the room appears to “understand” Chinese, yet the person inside has no comprehension of the language’s meaning. Searle argued that a computer running a program is analogous to the person following the rulebook: it manipulates syntax without understanding semantics. Thus, behavioral imitation alone is not evidence of true intelligence.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/ai-for-all/chinese_room.jpeg" class="img-fluid figure-img"></p>
<figcaption>Figure 2.1.1: Source <span class="citation" data-cites="jackson2025ai"><a href="../references.html#ref-jackson2025ai" role="doc-biblioref">[1]</a></span> The Chinese Room Argument.</figcaption>
</figure>
</div>
<p>Whether one finds Searle convincing, the example highlights a gap between performance and actual intelligence.</p>
<p><strong>Artificial General Intelligence</strong></p>
<p>Most modern AIs are narrow, or “weak” AIs. The opposite concept, originally envisioned as “strong AI,” is now referred to as Artificial General Intelligence (AGI). AGI is often described as human-like intelligence.</p>
<p>But that raises a big question! What exactly is <strong>human intelligence</strong>?</p>
<p>Generally speaking, human intelligence is the capacity to learn from experience, identify patterns, handle abstract concepts, and apply knowledge to shape the environment. Yet, these are only functional descriptions. The core, or what many consider a distinguishing feature, is the presence of self-awareness and a subjective feel of an experience. But the evolutional reason for thier existence remains controversial: why does self-awareness matter for cognition, and what evolutionary advantage does subjective experience provide?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/ai-for-all/qualia.jpeg" class="img-fluid figure-img"></p>
<figcaption>Figure 2.1.2: The Hard Problem of Consciousness.</figcaption>
</figure>
</div>
<p>In the philosophy of mind, this phenomenon is referred to as <em>qualia</em>, and there is still no conclusive scientific answer to why qualia exist. Some argue that consciousness or self-awareness is an emergent property, and it appears when the system becomes complex enough; others propose that it is fundamental. These questions are all part of the Hard Problem of Consciousness. Interested readers can explore scientific <a href="https://en.wikipedia.org/wiki/Models_of_consciousness#Neuroscience">theories of consciousness</a>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What is an Intelligent Agent?
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Intelligent Agent</strong> is an entity that can perceive and interact with its environment autonomously.</p>
</div>
</div>
<p>Humans can be seen as one type of intelligent agent, maintaining internal bodily processes and responding to environmental changes. Several attempts have been made to define general intelligence in terms of cognitive abilities. One such theory is the Cattell-Horn-Carroll (CHC) theory, which divides general intelligence into four core abilities: motor control, sensory perception, focused attention, and knowledge. Cattell-Horn-Carroll</p>
<div class="cell" data-fig-width="6.5" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TB
    Title(["   **Cattell–Horn–Carroll &lt;br/&gt; Theory**  "])

    Title --&gt; GI("**General**&lt;br&gt;**Intelligence**")
    GI("**General&lt;br&gt;Intelligence**"):::main

    GI --&gt; MC("**Motor Control**")
    GI --&gt; SP("**Sensory Perception**")
    GI --&gt; FA["**Focused Attention**"]
    GI --&gt; K("**Knowledge**")
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>Studying intelligence and consciousness presents a fascinating yet complex set of problems. For now, let’s narrow our focus and ask a simpler question:</p>
<p><strong>How do humans think?</strong></p>
<p><em>Behaviorism</em></p>
<p>Before the 1950s, psychology was dominated by behaviorism, which held that internal mental processes were either unknowable or scientifically irrelevant. Instead, behaviorists focused on mapping observable stimuli to observable responses.</p>
<p><em>Cognitive Revolution</em></p>
<p>During the cognitive revolution of the 1950s–1970s, researchers inspired by digital computers began proposing explicit rule-based models of thinking, often using if/then representations—a so-called symbolic approach (e.g., “If I drink tons of coffee, I’ll be jittery”).</p>
<p><em>Probabilistic Reasoning</em></p>
<p>Starting in the late 1970s, a new perspective emerged: psychologists noticed that humans often think experientially. For example, based on today’s cloud cover and similar past experiences, one might infer a high probability of rain and decide to carry an umbrella. Geoffrey Hinton, who won the Nobel Prize in 2024, was a pioneer in this field. He demonstrated that such experiential reasoning can be modeled using probabilistic computations, laying the foundation for modern machine learning algorithms.</p>
<p><img src="../images/ai-for-all/hinton.png" class="img-fluid"></p>
</section>
<section id="types-of-artificial-intelligence" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="types-of-artificial-intelligence"><span class="header-section-number">2.2</span> Types of Artificial Intelligence</h2>
<p>Before we jump into machine learning in depth, it is important to highlight that there are several distinct approaches to developing AI. In this course, we will focus primarily on ML, especially neural networks, as they currently dominate the field. However, not all AI techniques rely on machine learning principles. Just as human reasoning includes multiple modes, such as probabilistic, inference, and symbolic logic, the development of AGI will require combining a variety of paradigms.</p>
<table class="table-striped table-hover table-primary caption-top table">
<colgroup>
<col style="width: 38%">
<col style="width: 61%">
</colgroup>
<thead>
<tr class="header">
<th>AI Technique</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Symbolic (Logic-Based)</td>
<td>Uses logical rules and symbolic representations to encode and manipulate knowledge. Focuses on deductive reasoning.</td>
</tr>
<tr class="even">
<td>Genetic (Evolutionary)</td>
<td>Optimization algorithms inspired by natural selection.</td>
</tr>
<tr class="odd">
<td>Fuzzy Logic</td>
<td>A form of logic that works with “degrees of truth”, making it useful for uncertain or ambiguous scenarios.</td>
</tr>
<tr class="even">
<td>Knowledge Representation and Reasoning (KR&amp;R)</td>
<td>Structures information using ontologies, semantic networks, and formal logic to support reasoning tasks.</td>
</tr>
<tr class="odd">
<td>Bayesian Networks</td>
<td>Probabilistic graphical models that capture dependencies between variables, enabling inference under uncertainty.</td>
</tr>
</tbody>
</table>
<p><br> Real-world systems, such as self-driving cars and voice assistants, are typically hybrids. They combine deep learning for perception, symbolic reasoning for structured knowledge, and probabilistic filtering for uncertainty management. This integration helps meet critical requirements for safety, robustness, and interpretability.</p>
</section>
<section id="machine-learning" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="machine-learning"><span class="header-section-number">2.3</span> Machine Learning</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What is ML?
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Machine Learning (ML)</strong> is a subfield of AI focused on algorithms that enable computers to learn patterns from data and build probabilistic models.</p>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-for-all/deep_learning3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure 2.3.1: Organogram of AI algorithms."><img src="../images/ai-for-all/deep_learning3.png" class="img-fluid figure-img" style="width:100.0%" alt="Figure 2.3.1: Organogram of AI algorithms."></a></p>
<figcaption>Figure 2.3.1: Organogram of AI algorithms.</figcaption>
</figure>
</div>
<p><strong>Supervised Learning</strong> involves learning from labeled data, where models directly learn from input-output pairs. These models are generally simpler in terms of training and achieve high performance. With a labelled dataset, you already know the correct output for every input, so you can optimise model parameters to fit the answer. We will explore them in-depth through the course.</p>
<p><strong>Semi-Supervised Learning</strong> combines a small amount of labeled data with a large amount of unlabeled data, often using auto-labeling techniques. Examples include self-training models, where a model iteratively labels data to improve, and Graph Neural Networks (GNNs), which are useful for understanding relationships between data points.</p>
<p><strong>Unsupervised Learning</strong> relies on unlabeled data, focusing on identifying patterns or structures. Popular models include Autoencoders, Generative Adversarial Networks (GANs), and Restricted Boltzmann Machines (RBMs).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-for-all/ML_types.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure 2.3.2: Types of Machine Learning."><img src="../images/ai-for-all/ML_types.png" class="img-fluid figure-img" style="width:70.0%" alt="Figure 2.3.2: Types of Machine Learning."></a></p>
<figcaption>Figure 2.3.2: Types of Machine Learning.</figcaption>
</figure>
</div>
</section>
<section id="neural-networks" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="neural-networks"><span class="header-section-number">2.4</span> Neural Networks</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What is ANN?
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Artificial Neural Network (ANN)</strong> is a computational model that transforms and interprets input data through layers. Analogous to biological neural networks composed of interconnected neurons, an ANN consists of nodes (basic processing units) arranged in connected layers.</p>
</div>
</div>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-for-all/neural_network1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure 2.4.1: Source [@norvig2004ai] The parts of a neuron: a cell body with a nucleus, branching dendrites, and a long axon connecting with thousands of other neurons at synapses."><img src="../images/ai-for-all/neural_network1.png" class="img-fluid figure-img" style="width:100.0%" alt="Figure 2.4.1: Source [2] The parts of a neuron: a cell body with a nucleus, branching dendrites, and a long axon connecting with thousands of other neurons at synapses."></a></p>
<figcaption>Figure 2.4.1: Source <span class="citation" data-cites="norvig2004ai"><a href="../references.html#ref-norvig2004ai" role="doc-biblioref">[2]</a></span> <strong>The parts of a neuron</strong>: a cell body with a nucleus, branching dendrites, and a long axon connecting with thousands of other neurons at synapses.</figcaption>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-for-all/neural_networks2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure 2.4.2: Structure of a neural network: Ramón y Cajal’s drawing of the cells of the chick cerebellum, from Estructura de los centros nerviosos de las aves, Madrid, 1905"><img src="../images/ai-for-all/neural_networks2.png" class="img-fluid figure-img" style="width:100.0%" alt="Figure 2.4.2: Structure of a neural network: Ramón y Cajal’s drawing of the cells of the chick cerebellum, from Estructura de los centros nerviosos de las aves, Madrid, 1905"></a></p>
<figcaption>Figure 2.4.2: <strong>Structure of a neural network</strong>: Ramón y Cajal’s drawing of the cells of the chick cerebellum, from Estructura de los centros nerviosos de las aves, Madrid, 1905</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>Neural Networks Elements</strong></p>
<p>The principle “neurons that fire together, wire together” <span class="citation" data-cites="hebb1949"><a href="../references.html#ref-hebb1949" role="doc-biblioref">[3]</a></span> captures the idea that the strength of neuronal connections adjusts based on experience. Artificial neural networks mimic this by assigning each connection a weight that training continually adjusts. Larger weights reinforce patterns the network finds useful.</p>
<p><a href="../images/ai-for-all/ann_bnn.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="../images/ai-for-all/ann_bnn.png" class="img-fluid" style="width:100.0%"></a></p>
<p>Each node multiplies its inputs by their weights, adds the results, and feeds that sum into an activation function. The activation function decides if, and how strongly, the signal moves on to the next layer. When it does, we say the neuron is “activated.”</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Weights
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Weights are parameters that transform input data as it passes through the network. They set the strength of connections between nodes, with each weight controlling how much influence one node exerts on another. During training, the network adjusts these weights to reduce prediction errors.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Activation Function
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The activation function computes the output of each neuron. It does the non-linear transformation to the input, making it capable to learn and performing more complex tasks.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Input Layer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Information from the outside world enters the artificial neural network from the input layer. Input nodes provide a connection between the input data and the hidden layers.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Output Layer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The output layer produces the network’s final prediction. Every ANN has at minimum an input layer and an output layer. Adding hidden layers in between usually makes the model much more powerful, because they introduce non-linear transformations.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Hidden Layer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Hidden layers are all the layers between the input and the output. Each one takes the previous layer’s output vector (its “representation”) and converts it into a new vector. More hidden layers mean a deeper neural network. If there is only one or a few we call the network shallow.</p>
</div>
</div>
</div>
<p>The Perceptron <span class="citation" data-cites="rosenblatt1958perceptron"><a href="../references.html#ref-rosenblatt1958perceptron" role="doc-biblioref">[4]</a></span>, one of the earliest and simplest neural network models, was invented in 1957 by psychologist Frank Rosenblatt. Rosenblatt’s Perceptron was a physical machine with retina-like sensors as inputs, wires acting as the hidden layers, and a binary output system.</p>
<p><a href="../images/ai-for-all/rosenblatt.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="../images/ai-for-all/rosenblatt.png" class="img-fluid" style="width:100.0%"></a></p>
</section>
<section id="backpropagation" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="backpropagation"><span class="header-section-number">2.5</span> Backpropagation</h2>
<p>Initially, neural networks were quite shallow feed-forward networks. Adding more hidden layers made training them difficult. However, in the 1980s—often referred to as the rebirth of AI—the invention of the <strong>backpropagation</strong> algorithm revolutionized the field.</p>
<p>It allowed for efficient error correction across layers, making it possible to train much deeper networks than before.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What is backpropagation?
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Backpropagation</strong> is an algorithm that calculates the error at the output layer of a neural network and then “back propagates” this error through the network, layer by layer. It updates the connections (weights) between neurons to reduce the error, allowing the model to improve its accuracy during training.</p>
</div>
</div>
<div class="columns">
<div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-for-all/backpropagation1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Figure 2.5.1: Backpropagation flow. A two-layer network showing the forward pass (blue arrows) that produces the output and the back-propagation pass (green/red arrows) that carries the error signal back through the layers to update each weight"><img src="../images/ai-for-all/backpropagation1.png" class="img-fluid figure-img" style="width:100.0%" alt="Figure 2.5.1: Backpropagation flow. A two-layer network showing the forward pass (blue arrows) that produces the output and the back-propagation pass (green/red arrows) that carries the error signal back through the layers to update each weight"></a></p>
<figcaption>Figure 2.5.1: Backpropagation flow. A two-layer network showing the forward pass (blue arrows) that produces the output and the back-propagation pass (green/red arrows) that carries the error signal back through the layers to update each weight</figcaption>
</figure>
</div>
</div><div class="column" style="width:50%;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-for-all/backpropagation.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Figure 2.5.2: A gif visualization of a 784-input, three-hidden-layer perceptron as it processes a single example: bright lines represent strong positive weights, darker/red lines strong negative weights, giving an intuitive sense of how information flows through the network’s layers. Source (3Blue1Brown)"><img src="../images/ai-for-all/backpropagation.gif" class="img-fluid figure-img" style="width:80.0%" alt="Figure 2.5.2: A gif visualization of a 784-input, three-hidden-layer perceptron as it processes a single example: bright lines represent strong positive weights, darker/red lines strong negative weights, giving an intuitive sense of how information flows through the network’s layers. Source (3Blue1Brown)"></a></p>
<figcaption>Figure 2.5.2: A gif visualization of a 784-input, three-hidden-layer perceptron as it processes a single example: bright lines represent strong positive weights, darker/red lines strong negative weights, giving an intuitive sense of how information flows through the network’s layers. Source (3Blue1Brown)</figcaption>
</figure>
</div>
</div>
</div>
<p>Thus, the backpropagation algorithm enabled the training of neural networks with multiple layers, laying the foundation for the field of <strong>deep learning</strong>.</p>
</section>
<section id="deep-learning" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="deep-learning"><span class="header-section-number">2.6</span> Deep Learning</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Deep Learning
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Deep Learning (DL)</strong> is a subset of ML that uses multilayered neural networks, called deep neural networks.</p>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-for-all/deep_learning2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Figure 2.6.1: (a) A shallow model, such as linear regression, has short computation paths between input and output. (b) A decision list network has some long paths for some possible input values, but most paths are short. (c) A deep learning network has longer computation paths, allowing each variable to interact with all the others. Source: Artificial Intelligence - A Modern Approach. [@norvig2004ai]"><img src="../images/ai-for-all/deep_learning2.png" class="img-fluid figure-img" style="width:100.0%" alt="Figure 2.6.1: (a) A shallow model, such as linear regression, has short computation paths between input and output. (b) A decision list network has some long paths for some possible input values, but most paths are short. (c) A deep learning network has longer computation paths, allowing each variable to interact with all the others. Source: Artificial Intelligence - A Modern Approach. [2]"></a></p>
<figcaption>Figure 2.6.1: (a) A shallow model, such as linear regression, has short computation paths between input and output. (b) A decision list network has some long paths for some possible input values, but most paths are short. (c) A deep learning network has longer computation paths, allowing each variable to interact with all the others. Source: Artificial Intelligence - A Modern Approach. <span class="citation" data-cites="norvig2004ai"><a href="../references.html#ref-norvig2004ai" role="doc-biblioref">[2]</a></span></figcaption>
</figure>
</div>
<p>Despite advances in backpropagation, deep learning, computing power, and optimization, neural networks still face the problem known as <em>catastrophic forgetting</em> — losing old knowledge when trained on new tasks. Current AI models are often “frozen” and specialized, needing complete retraining for updates, unlike even simple animals that can continuously learn without forgetting <span class="citation" data-cites="bennett2023history"><a href="../references.html#ref-bennett2023history" role="doc-biblioref">[5]</a></span>. This limitation is one of the reasons that led to the development of specialized deep learning models, each with unique architectures tailored to specific tasks. Let’s explore how each of these models can be applied in scientific research!</p>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="Convolutional Neural Networks">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Convolutional Neural Networks
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Convolutional Neural Networks (CNN)</strong> are artificial neural networks designed to process structured data like images. Originally inspired by the mammalian visual cortex, CNNs attempt to mimic how our brains process visual information in layers. First, brains interpret basic shapes like lines and edges and then move to more complex structures, like recognizing a dog ear or the whole animal. CNNs are typically trained using a supervised learning approach.</p>
<p>CNNs simulate this by using small, repeated filters, or <em>kernels</em>, that scan parts of an image to find basic shapes, edges, and textures, regardless of their location. This scanning process, called <em>convolution</em>, enables early CNN layers to detect simple patterns (like lines) and deeper layers to identify more complex shapes or objects.</p>
<p><strong>Application</strong>: CNNs are highly effective for image-related tasks, making them ideal for analyzing satellite or drone imagery in ecology and arctic science, identifying structures in biomedical imaging, and classifying galaxies in astrophysics. In permafrost mapping, CNNs help with segmenting thaw features and permafrost extent from satellite imagery, producing pixel‑wise probability maps.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-for-all/cnn.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Figure 2.6.2: Source (Bennett, 2023) [@bennett2023history] Convolutional Neural Networks"><img src="../images/ai-for-all/cnn.png" class="img-fluid figure-img" style="width:100.0%" alt="Figure 2.6.2: Source (Bennett, 2023) [5] Convolutional Neural Networks"></a></p>
<figcaption>Figure 2.6.2: Source (Bennett, 2023) <span class="citation" data-cites="bennett2023history"><a href="../references.html#ref-bennett2023history" role="doc-biblioref">[5]</a></span> Convolutional Neural Networks</figcaption>
</figure>
</div>
<p><strong>Limitations of CNNs</strong></p>
<p>Ironically, though CNNs were inspired by the mammalian visual system, they struggle with tasks that even simpler animals like fish handle easily. CNNs have trouble with rotated or differently angled objects. The current workaround is to have variations of object images in training data with all kinds of different angles <span class="citation" data-cites="bennett2023history"><a href="../references.html#ref-bennett2023history" role="doc-biblioref">[5]</a></span>.</p>
<p>While CNNs follow a layered structure, recent research reveals that the brain’s visual processing is more flexible and not as hierarchical as once believed. Our visual system can “skip” layers or process information in parallel, allowing simultaneous handling of different types of visual input across various brain regions.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="Recurrent Neural Networks">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Recurrent Neural Networks
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Recurrent Neural Networks (RNN)</strong> are artificial neural networks designed to process sequential data. By incorporating cycles in their computation graph, RNNs can “remember” previous inputs, making them especially useful for tasks where context is important.</p>
<p><strong>Application</strong>: These models are commonly used for time series data, such as weather forecasting, monitoring ecological changes over time, and analyzing temporal patterns in genomic data.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-for-all/rnn.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="Figure 2.6.3: Recurrent Neural Network. Source: dataaspirant.com"><img src="../images/ai-for-all/rnn.png" class="img-fluid figure-img" style="width:70.0%" alt="Figure 2.6.3: Recurrent Neural Network. Source: dataaspirant.com"></a></p>
<figcaption>Figure 2.6.3: Recurrent Neural Network. Source: dataaspirant.com</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="Reinforcement Learning">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Reinforcement Learning
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Reinforcement Learning (RL)</strong> is a learning technique in which an agent interacts with the environment and periodically receives rewards (reinforcements) or penalties to achieve a goal.</p>
<p>With supervised learning, an agent learns by passively observing example input/output pairs provided by a “teacher.” Reinforcement Learning introduces <em>AI agents</em> that can actively learn from their own experience in a given environment.<span class="citation" data-cites="norvig2004ai"><a href="../references.html#ref-norvig2004ai" role="doc-biblioref">[2]</a></span></p>
<p>The schematic shown in the figure illustrates the basic RL loop. The agent interacts with the environment by taking actions, which affect the environment’s state. The environment responds by updating the state and producing a reward signal. An interpreter component observes the outcome and translates it into a state and reward signal for the agent. This feedback loop allows the agent to learn and adapt its behavior over time.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-for-all/rl.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="Figure 2.6.4: Reinforcement Learning"><img src="../images/ai-for-all/rl.png" class="float-right img-fluid figure-img" style="width:50.0%" alt="Figure 2.6.4: Reinforcement Learning"></a></p>
<figcaption>Figure 2.6.4: Reinforcement Learning</figcaption>
</figure>
</div>
<p><strong>Applications</strong>: RL is applied in robotics and can also assist with experiment simulation in science, environmental monitoring, autonomous driving, and creating AI opponents in gaming. Imagine an autonomous rover (or drone) tasked with surveying melt patterns on sea-ice floes.</p>
<p>One type of RL is the Actor-Critic model, which divides the learning process into two roles: the Actor, who explores the environment and makes decisions, and the Critic, who evaluates these actions. The Critic provides feedback on the quality of each action, helping the Actor balance exploration (trying new actions) with exploitation (choosing actions with known rewards). Recent research has explored various algorithms to model curiosity in artificial agents <span class="citation" data-cites="curiosityalgorithm2022"><a href="../references.html#ref-curiosityalgorithm2022" role="doc-biblioref">[6]</a></span> <span class="citation" data-cites="wang2024curiosity"><a href="../references.html#ref-wang2024curiosity" role="doc-biblioref">[7]</a></span>.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note no-icon callout-titled" title="Large Language Models">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Large Language Models
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Large Language Models (LLM)</strong> are a type of neural network that has revolutionized natural language processing (NLP). Trained on massive datasets, these models can generate human-like text, translate languages, create various forms of content, and answer questions informatively (e.g., GPT-3, Gemini, Llama).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-for-all/llm.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13" title="Figure 2.6.5: Large Language Models. Source: Artificial Intelligence - A Modern Approach. [@norvig2004ai]"><img src="../images/ai-for-all/llm.png" class="img-fluid figure-img" style="width:70.0%" alt="Figure 2.6.5: Large Language Models. Source: Artificial Intelligence - A Modern Approach. [2]"></a></p>
<figcaption>Figure 2.6.5: Large Language Models. Source: Artificial Intelligence - A Modern Approach. <span class="citation" data-cites="norvig2004ai"><a href="../references.html#ref-norvig2004ai" role="doc-biblioref">[2]</a></span></figcaption>
</figure>
</div>
<p><strong>Transformer</strong> is a neural-network architecture introduced in 2017 that relies on a mechanism called self-attention. It supports most modern large language models (LLMs). Unlike previous models like Recurrent Neural Networks (RNNs) that processed language sequentially, Transformers use self-attention to assess relationships between all words in a sentence simultaneously. This allows them to dynamically focus on different parts of the input text and weigh the importance of each word in relation to others. This allows them to understand context and meaning with much better accuracy.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-for-all/llm2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14" title="Figure 2.6.6: Evolution of Natural Languge Processing. Source[@norvig2004ai]"><img src="../images/ai-for-all/llm2.png" class="img-fluid figure-img" style="width:80.0%" alt="Figure 2.6.6: Evolution of Natural Languge Processing. Source[2]"></a></p>
<figcaption>Figure 2.6.6: Evolution of Natural Languge Processing. Source<span class="citation" data-cites="norvig2004ai"><a href="../references.html#ref-norvig2004ai" role="doc-biblioref">[2]</a></span></figcaption>
</figure>
</div>
<p>The success of LLMs has driven AI’s recent surge in popularity and research. Between 2010 and 2022, the volume of AI-related publications nearly tripled, climbing from about 88,000 in 2010 to over 240,000 by 2022. Likewise, AI patent filings have skyrocketed, increasing from roughly 3,500 in 2010 to over 190,000 in 2022. In the first half of 2024 alone, AI and machine learning companies in the United States attracted $38.6 billion in investment out of a total of $93.4 billion. <span class="citation" data-cites="pitchbook2024aiml"><a href="../references.html#ref-pitchbook2024aiml" role="doc-biblioref">[8]</a></span></p>
</div>
</div>
</div>
</section>
<section id="the-future-of-ai-in-arctic-science" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="the-future-of-ai-in-arctic-science"><span class="header-section-number">2.7</span> The Future of AI in Arctic Science</h2>
<p>AI is transforming the scientific method by supporting each step of scientific discovery. Let’s consider how various AI techniques can be applied at each stage of the scientific process:</p>
<ul>
<li><strong>Observation</strong>: Using computer vision for data collection.</li>
<li><strong>Hypothesis</strong>: Clustering data with unsupervised learning.</li>
<li><strong>Experiment</strong>: Simulating environments through reinforcement learning.</li>
<li><strong>Data Analysis</strong>: Simplifying and classifying data using neural networks.</li>
<li><strong>Conclusion</strong>: Combining LLMs with KR&amp;R to generate complex findings and insights.</li>
</ul>
<p><img src="../images/ai-for-all/ai_and_science.png" class="img-fluid"></p>
<ul>
<li>AI already accelerates Arctic science: computer-vision models detect thaw features and permafrost extent; clustering algorithms flag anomalies; neural networks compress and classify multimodal data; and LLMs combined with knowledge graphs help researchers draw conclusions. These tools help turn petabytes of imagery and sensor data into testable hypotheses and valuable insights.</li>
</ul>
<p>It’s important to note that, regardless of model type, high-quality data is essential for accurate AI predictions and insights. In the next sessions, we’ll explore practical tips for working with well-prepared, high-quality data.</p>
</section>
<section id="exercise-nn-playground" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="exercise-nn-playground"><span class="header-section-number">2.8</span> Exercise: NN Playground</h2>
<p>Let’s build intuition by experimenting with a neural network simulator for approximately 10 minutes.</p>
<div class="callout callout-style-simple callout-note no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<p>Web-based app, no setup or account required: <a href="https://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.06707&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false">playground.tensorflow.org</a></p>
</div>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-for-all/nn_playground.gif" class="lightbox" data-gallery="quarto-lightbox-gallery-15" title="."><img src="../images/ai-for-all/nn_playground.gif" class="img-fluid figure-img" style="width:80.0%" alt="."></a></p>
<figcaption>.</figcaption>
</figure>
</div>
<p>TensorFlow Playground is an example of a feed-forward network, where data flows only from the input layer to the output layer without feedback loops. Training a neural network involves automatically adjusting its internal parameters so that the network maps inputs to desired outputs with minimal error. As you press the play button, you can see the number of epochs increase. In an Artificial Neural Network, an <em>epoch</em> represents one complete pass through the training dataset.</p>
<ul class="task-list">
<li><label><input type="checkbox">Adjust the <strong>ratio of training to test data</strong> split. Does the quality of the output vary?</label></li>
</ul>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Orange indicates <span style="color:orange">negative</span> values, while blue represents <span style="color:blue">positive</span> values. Typically, an 80/20 split for training and testing data is used. Smaller datasets may need a 90% training portion for more examples, while larger datasets can reduce training data to increase test samples. Background colors illustrate the network’s predictions, with more intense colors representing higher confidence in its prediction.</p>
</div>
</div>
</div>
<ul class="task-list">
<li><label><input type="checkbox">Experiment with noise and <strong>batch size</strong> parameters. How does the output change?</label></li>
</ul>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-17-contents" aria-controls="callout-17" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-17" class="callout-17-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Background colors illustrate the network’s predictions, with more intense colors representing higher confidence in its prediction. Adding noise to the training data simulates variability or imperfections often found in real-world datasets. This noise may include measurement errors or irrelevant features. By training with noisy data, the model becomes less sensitive to outliers and irrelevant fluctuations, improving generalization to new inputs.</p>
</div>
</div>
</div>
<ul class="task-list">
<li><label><input type="checkbox">Add or remove <strong>hidden layers</strong>. Notice how it affects the neural network’s performance?</label></li>
</ul>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>A deeper network can model more complex patterns, but it also increases the number of parameters and the training time. It raises the risk of overfitting, where training metrics improve while validation metrics stall or deteriorate. In general, you should choose the shallowest model that reaches your target performance without overfitting.</p>
</div>
</div>
</div>
<ul class="task-list">
<li><label><input type="checkbox">Change the number of <strong>neurons</strong> in the hidden layers. Can you see any impact on model predictions?</label></li>
</ul>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-19-contents" aria-controls="callout-19" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-19" class="callout-19-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Start with one hidden layer and one or two neurons, observing predictions (orange vs.&nbsp;blue background) against actual data points (orange vs.&nbsp;blue dots). With very few neurons, the model cannot capture complex nonlinear relationships, resulting in overly simplistic predictions. Increasing the number of neurons and layers allows the network to represent more complex decision boundaries, improving the match between predictions and actual data.</p>
</div>
</div>
</div>
<ul class="task-list">
<li><label><input type="checkbox">Manually adjust the <strong>weight</strong>. Did you notice the thickness of the line changed?</label></li>
</ul>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Line thickness shows the strength of the connection between nodes. The thinner the line, the less effect they have on each other, and vice versa. If the line turns red, that means the weight is negative; it pushes the next neuron down instead of up. Sort of suppresses the next neuron’s firing.</p>
</div>
</div>
</div>
<ul class="task-list">
<li><label><input type="checkbox">Change the <strong>learning rate</strong> to observe its effect on training speed and accuracy.</label></li>
</ul>
<div class="callout callout-style-default callout-caution no-icon callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-21-contents" aria-controls="callout-21" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Answer
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-21" class="callout-21-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The learning rate is a key setting or hyperparameter that controls how much a model adjusts its weights during training. A higher rate speeds up learning but risks overshooting the optimal solution. The optimal solution would be the best set of weights that makes the model’s error as small as possible, and the predictions that are accurate. At the same time, a lower rate makes learning more precise but slower. It’s one of the most crucial settings when building a neural network. Because every weight update in a neural-network optimizer is scaled by the learning rate, so that a single number effectively sets how “faster” models learns</p>
</div>
</div>
</div>
<ul class="task-list">
<li><p><label><input type="checkbox">Try various <strong>activation functions</strong> to see how they influence model performance.</label></p></li>
<li><p><label><input type="checkbox">Experiment with different problem types (e.g., classification vs.&nbsp;regression) and analyze the outcomes.</label></p></li>
</ul>
</section>
<section id="do-you-have-any-questions" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="do-you-have-any-questions">Do You Have Any Questions?</h2>
<p>Email: <a href="alyonak@nceas.ucsb.edu">alyonak@nceas.ucsb.edu</a><br>
Website: <a href="http://alyonakosobokova.com">alyonakosobokova.com</a><br>
YouTube: <a href="https://youtube.com/@dorkmattergirl">Dork Matter Girl</a></p>


<div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-jackson2025ai" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">T. Jackson, <em>Artificial intelligence</em>. New Burlington, 2025, p. 176.</div>
</div>
<div id="ref-norvig2004ai" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">P. Norvig and S. J. Russell, <em>Artificial intelligence: A modern approach</em>, 3rd ed. Pearson, 2004. Available: <a href="https://books.google.com/books/about/Artificial_Intelligence.html?id=8jZBksh-bUMC">https://books.google.com/books/about/Artificial_Intelligence.html?id=8jZBksh-bUMC</a></div>
</div>
<div id="ref-hebb1949" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">D. O. Hebb, <em>The organization of behavior: A neuropsychological theory</em>. New York: Wiley, 1949. Available: <a href="https://en.wikipedia.org/wiki/The_Organization_of_Behavior">https://en.wikipedia.org/wiki/The_Organization_of_Behavior</a></div>
</div>
<div id="ref-rosenblatt1958perceptron" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">F. Rosenblatt, <span>“The perceptron: A probabilistic model for information storage and organization in the brain,”</span> <em>Psychological Review</em>, vol. 65, no. 6, pp. 386–408, 1958, doi: <a href="https://doi.org/10.1037/H0042519">10.1037/H0042519</a>.</div>
</div>
<div id="ref-bennett2023history" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">M. Bennett, <em>A brief history of intelligence: Evolution, AI, and the five breakthroughs that made our brains</em>, Hardcover. Harper, 2023.</div>
</div>
<div id="ref-curiosityalgorithm2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">D. Kawahara, S. Ozeki, and I. Mizuuchi, <span>“A curiosity algorithm for robots based on the free energy principle,”</span> pp. 53–59, 2022, doi: <a href="https://doi.org/10.1109/SII52469.2022.9708819">10.1109/SII52469.2022.9708819</a>.</div>
</div>
<div id="ref-wang2024curiosity" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">T. Wang, F. Wang, Z. Xie, and F. Qin, <span>“Curiosity model policy optimization for robotic manipulator tracking control with input saturation in uncertain environment,”</span> <em>Frontiers in Neurorobotics</em>, vol. 18, 2024, doi: <a href="https://doi.org/10.3389/fnbot.2024.1376215">10.3389/fnbot.2024.1376215</a>.</div>
</div>
<div id="ref-pitchbook2024aiml" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">Inc. PitchBook Data, <span>“Artificial intelligence &amp; machine learning report, Q2 2024,”</span> PitchBook, 2024. Available: <a href="https://pitchbook.com/news/reports/q2-2024-artificial-intelligence-machine-learning-report">https://pitchbook.com/news/reports/q2-2024-artificial-intelligence-machine-learning-report</a></div>
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../sections/breaking-the-ice-with-ai-in-arctic-science.html" class="pagination-link" aria-label="Breaking the Ice with AI in Arctic Science">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Breaking the Ice with AI in Arctic Science</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../sections/ai-ready-data-in-arctic-research.html" class="pagination-link" aria-label="AI-Ready Data in Arctic Research">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">AI-Ready Data in Arctic Research</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<!-- Default Statcounter code for cyber2a online course
http://cyber2a.github.io/cyber2a-course/ -->
<script type="text/javascript">
    var sc_project=13129980; 
    var sc_invisible=1; 
    var sc_security="fa33fcfd"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async=""></script>
    <noscript><div class="statcounter"><a title="Web Analytics" href="https://statcounter.com/" target="_blank"><img class="statcounter" src="https://c.statcounter.com/13129980/0/fa33fcfd/1/" alt="Web Analytics" referrerpolicy="no-referrer-when-downgrade"></a></div></noscript>
    <!-- End of Statcounter Code -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>