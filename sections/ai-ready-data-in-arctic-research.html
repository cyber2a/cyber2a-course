<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; AI-Ready Data in Arctic Research – Cyber2A: AI for Arctic Research</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../sections/data-annotation.html" rel="next">
<link href="../sections/ai-for-everyone.html" rel="prev">
<link href="../images/index/arcticlogo.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../sections/breaking-the-ice-with-ai-in-arctic-science.html"><b>Day 1: Introduction to AI and Arctic Science</b></a></li><li class="breadcrumb-item"><a href="../sections/ai-ready-data-in-arctic-research.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">AI-Ready Data in Arctic Research</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Cyber2A: AI for Arctic Research</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/cyber2a/cyber2a-course/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course Overview</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 1: Introduction to AI and Arctic Science</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/breaking-the-ice-with-ai-in-arctic-science.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Breaking the Ice with AI in Arctic Science</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-for-everyone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI for Everyone</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-ready-data-in-arctic-research.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">AI-Ready Data in Arctic Research</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/data-annotation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Data Annotation: The Foundation of Deep Learning Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-data-annotation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Hands-On Lab: Data Annotation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 2: AI Fundamentals and Techniques</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/the-building-blocks-of-nn-and-dl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The Building Blocks of Neural Networks and Deep Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/intro-to-pytorch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to PyTorch: Core Functionalities and Advantages</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-pytorch.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Hands-On Lab: PyTorch</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/permafrost-discovery-gateway.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Permafrost Discovery Gateway</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-ethics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">AI Ethics</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 3: Advanced AI Workflows and Models</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/guest-lecture-yili-arts-dataset.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Guest Lecture - Unveiling the ARTS Dataset for a Thawing Frontier</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/exploring-advanced-neural-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Exploring Advanced Neural Networks: Semantic Segmentation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/intro-to-dl-libraries-for-image-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Introduction to Deep Learning Libraries for Image Analysis</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-mmsegmentation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Hands-On Lab: MMSegmentation</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 4: Workflows and Foundation Models</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/ai-workflows-and-mlops.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">AI Workflows and MLOps: From Development to Deployment</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-ai-workflows.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Hands-On Lab: AI Workflows</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/foundation-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Foundation Models: The Cornerstones of Modern AI</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/hands-on-lab-foundation-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Hands-On Lab: Foundation Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/reproducibility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Reproducibility</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text"><b>Day 5: AI Frontiers</b></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/the-fun-and-frontiers-of-ai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">The Fun and Frontiers of AI: Innovation, Imagination, Interaction</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#goal" id="toc-goal" class="nav-link active" data-scroll-target="#goal">Goal</a></li>
  <li><a href="#are-we-ready-for-ai" id="toc-are-we-ready-for-ai" class="nav-link" data-scroll-target="#are-we-ready-for-ai"><span class="header-section-number">3.1</span> Are we ready for AI?</a></li>
  <li><a href="#open-data-foundations" id="toc-open-data-foundations" class="nav-link" data-scroll-target="#open-data-foundations"><span class="header-section-number">3.2</span> Open Data Foundations</a></li>
  <li><a href="#arctic-data-center" id="toc-arctic-data-center" class="nav-link" data-scroll-target="#arctic-data-center"><span class="header-section-number">3.3</span> Arctic Data Center</a></li>
  <li><a href="#dataone" id="toc-dataone" class="nav-link" data-scroll-target="#dataone"><span class="header-section-number">3.4</span> DataONE</a></li>
  <li><a href="#metadata-harmonization" id="toc-metadata-harmonization" class="nav-link" data-scroll-target="#metadata-harmonization"><span class="header-section-number">3.5</span> Metadata harmonization</a></li>
  <li><a href="#croissant-metadata-for-machine-learning" id="toc-croissant-metadata-for-machine-learning" class="nav-link" data-scroll-target="#croissant-metadata-for-machine-learning"><span class="header-section-number">3.6</span> Croissant metadata for machine learning</a></li>
  <li><a href="#data-quality-1" id="toc-data-quality-1" class="nav-link" data-scroll-target="#data-quality-1"><span class="header-section-number">3.7</span> Data Quality</a></li>
  <li><a href="#esip-ai-readiness-checklist" id="toc-esip-ai-readiness-checklist" class="nav-link" data-scroll-target="#esip-ai-readiness-checklist"><span class="header-section-number">3.8</span> ESIP AI-Readiness Checklist</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../sections/breaking-the-ice-with-ai-in-arctic-science.html"><b>Day 1: Introduction to AI and Arctic Science</b></a></li><li class="breadcrumb-item"><a href="../sections/ai-ready-data-in-arctic-research.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">AI-Ready Data in Arctic Research</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">AI-Ready Data in Arctic Research</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="goal" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="goal">Goal</h2>
<p>This session dives into the concept of ‘AI-ready data’ in Arctic science and geoscience, highlighting the importance of suitable data for AI applications. Participants will learn about creating and managing metadata and organizing data repositories. We’ll discuss best practices for data preparation and structuring for AI processing. By the end, participants will clearly understand AI-ready data characteristics and the steps to transform raw data for AI applications.</p>
</section>
<section id="are-we-ready-for-ai" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="are-we-ready-for-ai"><span class="header-section-number">3.1</span> Are we ready for AI?</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What is AI-Ready Data?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Data that are <strong>accessible</strong>, preferably <strong>open</strong>, and <strong>well-documented</strong>, making them easily <strong>interpretable</strong> and <strong>machine-readable</strong> to simplify <strong>reuse</strong>.</p>
</div>
</div>
<p>This is really a variant on Analysis Ready Data (ARD), or, more recently, “Analysis Ready, Cloud Optimized (ARCO)” data.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-ready/mahecha_data_cube.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Mahecha et al.&nbsp;2020. [@mahecha_earth_2020] Visualization of the implemented Earth system data cube. The figure shows from the top left to bottom right the variables sensible heat (H), latent heat (LE), gross primary production (GPP), surface moisture (SM), land surface temperature (LST), air temperature (Tair), cloudiness (C), precipitation (P), and water vapour (V). The resolution in space is 0.25° and 8 d in time, and we are inspecting the time from May 2008 to May 2010; the spatial range is from 15° S to 60° N, and 10° E to 65° W."><img src="../images/ai-ready/mahecha_data_cube.png" class="img-fluid figure-img" style="width:90.0%" alt="Mahecha et al.&nbsp;2020. [1] Visualization of the implemented Earth system data cube. The figure shows from the top left to bottom right the variables sensible heat (H), latent heat (LE), gross primary production (GPP), surface moisture (SM), land surface temperature (LST), air temperature (Tair), cloudiness (C), precipitation (P), and water vapour (V). The resolution in space is 0.25° and 8 d in time, and we are inspecting the time from May 2008 to May 2010; the spatial range is from 15° S to 60° N, and 10° E to 65° W."></a></p>
<figcaption>Mahecha et al.&nbsp;2020. <span class="citation" data-cites="mahecha_earth_2020"><a href="../references.html#ref-mahecha_earth_2020" role="doc-biblioref">[1]</a></span> Visualization of the implemented Earth system data cube. The figure shows from the top left to bottom right the variables sensible heat (H), latent heat (LE), gross primary production (GPP), surface moisture (SM), land surface temperature (LST), air temperature (Tair), cloudiness (C), precipitation (P), and water vapour (V). The resolution in space is 0.25° and 8 d in time, and we are inspecting the time from May 2008 to May 2010; the spatial range is from 15° S to 60° N, and 10° E to 65° W.</figcaption>
</figure>
</div>
<p>Working with <code>xarray</code> and <code>zarr</code>, one can access many multi-petabyte earth systems datasets like CMIP6 (Coupled Model Intercomparison Project Phase 6) and ERA5 (Earth Re). For an overview of Zarr, see the Arctic Data Center Scalable Computing course <a href="https://learning.nceas.ucsb.edu/2024-03-arctic/sections/zarr.html">chapter on Zarr</a>.</p>
<p>Take, for example, the ERA5 reanalysis dataset <span class="citation" data-cites="noauthor_era5_nodate"><a href="../references.html#ref-noauthor_era5_nodate" role="doc-biblioref">[2]</a></span>, which is normally downloadable in bulk from the Copernicus Data Service. <a href="https://github.com/google-research/arco-era5">ARCO-ERA5</a> is an Analysis Ready, Cloud Optimized variant of ERA5 which has been reprocessed into a consistent 0.25° global grid, and chunked and saved in Zarr format with extensive metadata such that spatial and temporal subsets are easily extracted. Hosted on the Google Cloud Storage service in a public bucket (<code>gcp-public-data-arco-era5</code>), anyone can easily access slices of this massive multi-petabyte dataset from anywhere on the Internet, and can be doing analysis in seconds. Let’s take a quick peek at this massive dataset:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xarray</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>ds <span class="op">=</span> xarray.open_zarr(</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3'</span>,</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    chunks<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    storage_options<span class="op">=</span><span class="bu">dict</span>(token<span class="op">=</span><span class="st">'anon'</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>ds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><a href="../images/ai-ready/era5-zarr-arco.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="../images/ai-ready/era5-zarr-arco.png" class="img-fluid" style="width:100.0%"></a></p>
<p>With one line of code, we accessed 273 climate variables (e.g., <code>2m_temperature</code>, <code>evaporation</code>, <code>forecast_albedo</code>) spanning 8 decades at hourly time scales. And while this dataset is massive, we can explore it from the comfort of our laptop (not all at once, for which we would need a bigger machine!).</p>
<p>So, there’s nothing really special about AI-Ready data, in that a lot of the core requirements for Analysis Ready Data are exactly what are needed for AI modeling as well. Labeling is probably the main difference. Neverthless, many groups have gotten motivated by the promise of AI, and particularly machine learning, across disciplines. For example, the federal government has been ramping up readiness for AI across many agencies. In 2019, the White House Office of Science Technology and Policy (OSTP) started an AI-Readiness matrix, which was followed shortly by the National AI Initiative Act in 2020 <span class="citation" data-cites="long_ai-ready_2023"><a href="../references.html#ref-long_ai-ready_2023" role="doc-biblioref">[3]</a></span>.</p>
<p><a href="https://bipartisan-policy-center.imgix.net/wp-content/uploads/2023/02/AI-Ready-Open-Data.jpg?auto=compress,format&amp;q=90&amp;ixlib=imgixjs-3.4.2&amp;w=4088" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://bipartisan-policy-center.imgix.net/wp-content/uploads/2023/02/AI-Ready-Open-Data.jpg?auto=compress,format&amp;q=90&amp;ixlib=imgixjs-3.4.2&amp;w=4088" class="img-fluid" style="width:100.0%"></a></p>
<p>For example, management agencies have started entire new programs to prepare data and staff for the introduction of AI and machine learning into their processes. One such program with a focus on AI-Ready data is NOAA’s Center for Artificial Intelligence (NCAI).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-ready/noaa-ncai.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="NOAA NCAI"><img src="../images/ai-ready/noaa-ncai.png" class="img-fluid figure-img" style="width:100.0%" alt="NOAA NCAI"></a></p>
<figcaption><a href="https://www.noaa.gov/ai">NOAA NCAI</a></figcaption>
</figure>
</div>
<p>In beginning to define AI-Ready data for NOAA, <a href="https://www.star.nesdis.noaa.gov/star/documents/meetings/2020AI/presentations/202010/20201022_Christensen.pdf">Christensen et al.&nbsp;2020</a> defined several axes for evaluation, including data quality, data acess, and data documentation. We’ll be dinving into many of these today and over the course of the week.</p>
<div>

</div>
<div class="quarto-layout-panel" data-layout="[1,1,1]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Data Quality
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Completeness</li>
<li>Consistency</li>
<li>Lack of bias</li>
<li>Timeliness</li>
<li>Provenance and Integrity</li>
</ul>
</div>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Data Access
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Formats</li>
<li>Delivery options</li>
<li>Usage rights</li>
<li>Security / privacy</li>
</ul>
</div>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Data Documentation
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Dataset Metadata</li>
<li>Data dictionary</li>
<li>Identifier</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="open-data-foundations" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="open-data-foundations"><span class="header-section-number">3.2</span> Open Data Foundations</h2>
<p>Preservation and open data access are the foundation of Analysis-Ready and AI-ready data. While all modeling and analysis requires access to data, the ability for AI to encompass massive swaths of information and combine disparate data streams makes open data incredibly valuable. And while the open data movement has seen massive growth and adoption, it’s an unfortunate fact that most research data collected today are still not published and accessible, and challenges to the realization of open data outlined by Reichman et al.&nbsp;(2011) are still prominent today <span class="citation" data-cites="reichman_challenges_2011"><a href="../references.html#ref-reichman_challenges_2011" role="doc-biblioref">[4]</a></span>.</p>
</section>
<section id="arctic-data-center" class="level2 page-columns page-full" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="arctic-data-center"><span class="header-section-number">3.3</span> Arctic Data Center</h2>
<p>Nevertheless, progress has been made. The National Science Foundation <a href="https://www.nsf.gov/pubs/2022/nsf22106/nsf22106.jsp">Office of Polar Programs Data, Code, and Sample Management Policy (DCL 22-106)</a> embraces the need to preserve, document, and share the data and results from NSF-funded research, and since 2016 has funded the Arctic Data Center to provide services supporting reseach community data needs. The center provides <a href="https://arcticdata.io/submit/">data submission guidelines</a> and data curation support to create well-documented, understandable, and reusable data from the myriad projects funded by NSF and globally each year. In short, the Arctic Data Center provides a long-term home for over 7000 open, Arctic datasets that are AI-Ready. Researchers increasingly deposit large datasets from remote sensing campaigns using unmanned aerial vehicles (UAV), field expeditions, and observing networks, all of which are prime content for AI.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><img src="../images/ai-ready/arctic-data-center.png" class="img-fluid"></p>
</div></div><div class="page-columns page-full">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p class="page-columns page-full"><a href="../images/ai-ready/adc-catalog.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-5" title="Arctic Data Center Catalog"><img src="../images/ai-ready/adc-catalog.png" class="img-fluid figure-img column-page-right" style="width:100.0%" alt="Arctic Data Center Catalog"></a></p>
<figcaption>Arctic Data Center Catalog</figcaption>
</figure>
</div>
</div>
<p>In addition to raw observational data and remote sensing imagery, the ADC also stores and distributes model output, labeled training data, and other derived data products. A recent example comes from the Permafrost Discovery Gateway project, in which Neitze et al.&nbsp;used machine learning on multispectral PlanetScope imagery to extract high-resolution geospatial footprints for retrogressive thaw slumps (RTS) and active layer detachment (ALD) slides across the circum-Arctic permafrost region <span class="citation" data-cites="nitze_darts_2024"><a href="../references.html#ref-nitze_darts_2024" role="doc-biblioref">[5]</a></span>. In addition, the dataset includes human-generated training labels, processing code, and model checkpoints – just what is needed for further advances in this critical field of climate research.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><a href="../images/ai-ready/rts-feature.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="../images/ai-ready/rts-feature.png" class="img-fluid" style="width:100.0%"></a></p>
</div></div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-ready/darts-dataset.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="DARTS retrogressive thaw slump dataset doi:10.18739/A2RR1PP44"><img src="../images/ai-ready/darts-dataset.png" class="img-fluid figure-img" style="width:100.0%" alt="DARTS retrogressive thaw slump dataset doi:10.18739/A2RR1PP44"></a></p>
<figcaption>DARTS retrogressive thaw slump dataset <a href="https://doi.org/10.18739/A2RR1PP44">doi:10.18739/A2RR1PP44</a></figcaption>
</figure>
</div>
<p>While this and other valuable data for cross-cutting analysis are available from the Arctic Data Center, there are many other repositories that hold relevant data as well. Regardless of which repository a researher has chosen to share their data, the important thing to remember is to do so – data on your laptop or a University web server are rarely accessible and ready for reuse.</p>
</section>
<section id="dataone" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="dataone"><span class="header-section-number">3.4</span> DataONE</h2>
<p><a href="https://dataone.org">DataONE</a> is a network designed to connect over <a href="https://www.dataone.org/network/">60 global data repositories</a> (and growing) to improve the discoverability and accessiblilty of data from across the world. DataONE provides global data search and discovery by harmonizing myriad metadata standards used across the world, and providing an interoperability API across repositories to make datasets <strong>findable</strong> and programatically <strong>accessible</strong> regardless of where they live.</p>
<p><a href="../images/ai-ready/dataone-network.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8"><img src="../images/ai-ready/dataone-network.png" class="img-fluid" style="width:100.0%"></a></p>
<p>For example, a query across DataONE in 2024 revealed over 4500 datasets held by 16 different repositories, most of which are not specifically tied to Greenland research, per se.</p>
<p><a href="../images/ai-ready/dataone-greenland-datasets.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9"><img src="../images/ai-ready/dataone-greenland-datasets.png" class="img-fluid" style="width:100.0%"></a></p>
<p>Looking across the whole of the Arctic, we found over 98,000 datasets from 39 data repositories. It is notable that only 6 of those repositories are focused on Arctic research (like the Arctic Data Center), while the rest are either general repositories or discipline specific repositories. For example, <a href="https://www.pangaea.de/">Pangaea</a> as a generalist repository has the most datasets with over 10,000, but there are also significant and important data sets on archeology (<a href="https://www.tdar.org/">TDAR</a>), hydrology (<a href="https://www.hydroshare.org/">HydroShare</a>) and geochemistry (<a href="https://www.earthchem.org/">EarthChem</a>).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-ready/dataone-arctic-datasets.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Graph of Arctic Data across DataONE"><img src="../images/ai-ready/dataone-arctic-datasets.png" class="img-fluid figure-img" style="width:100.0%" alt="Graph of Arctic Data across DataONE"></a></p>
<figcaption>Graph of Arctic Data across DataONE</figcaption>
</figure>
</div>
</section>
<section id="metadata-harmonization" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="metadata-harmonization"><span class="header-section-number">3.5</span> Metadata harmonization</h2>
<p>One of the main roles of DataONE is to promote interoperability and improve the quality and discoverability of global data holdings – all of direct benefit to AI Ready data. DataONE promotes the use of detailed, discipline-specific metadata standards that enable researchers to comprehensively document the structure, contents, context, and protocols used when collecting data. For example, a good metadata record records not only the bibliographic information about the Dataset creators, but also documents the spatial and temporal extent of the data, the methods used to collect it, the types of measured properties that were observed or modeled, and other details that are fundamental to the proper interpretation and reuse of the data. Different disciplines focus on different standards: in ecology and environmental science, where biological metadata on taxonomy are important, the <a href="https://eml.ecoinformatics.org">Ecological Metadata Language (EML)</a> is used extensively, whereas in geospatial science where time and space are critical, the emphasis is on the ISO 19115 family of metadata standards. Overall, DataONE supports more than a dozen metadata variants, and can be extended to support more. Across the Arctic, we find datasets that use many different metadata approaches.</p>
<p><a href="../images/ai-ready/dataone-arctic-metadata.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="../images/ai-ready/dataone-arctic-metadata.png" class="img-fluid" style="width:100.0%"></a></p>
<p>DataONE harmonizes these standards by cross-walking them conceptually and making the data available for search through an integrated discovery portal and API. And DataONE promotes semantic labeling of the data as well, particularly for measurement types (e.g., <code>fork length</code> for fish length meeasurements) and dataset classification <span class="citation" data-cites="chong_enhancing_2024"><a href="../references.html#ref-chong_enhancing_2024" role="doc-biblioref">[6]</a></span>. These annotations are indexed against controlled, ontologically-precise term labels that are stored in queryable systems. For example, the <a href="https://bioportal.bioontology.org/ontologies/ECSO/">Ecosystem Ontology (ECSO</a>, the <a href="https://sites.google.com/site/environmentontology/about-envo">Environment Ontology (ENVO)</a>, and many others contain precisely defined terms that are useful for precise dataset labeling to differentiate subtly different terms and concepts.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-ready/dataone-annotation-salmon.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="A sub-Arctic salmon-related dataset [@game_salmon_2018], showing annotations for each of the measured variables in the dataset. Each annotation is to a precisely defined concept or term from a controlled vocabulary, allowing subtle differences in methodology to be distinguished, which helps with both data discovery and proper reuse. The underlying metadata model is machine-readable, allowing search systems, and amchine learning harvesters to make use of this structured label data."><img src="../images/ai-ready/dataone-annotation-salmon.png" class="img-fluid figure-img" style="width:100.0%" alt="A sub-Arctic salmon-related dataset [7], showing annotations for each of the measured variables in the dataset. Each annotation is to a precisely defined concept or term from a controlled vocabulary, allowing subtle differences in methodology to be distinguished, which helps with both data discovery and proper reuse. The underlying metadata model is machine-readable, allowing search systems, and amchine learning harvesters to make use of this structured label data."></a></p>
<figcaption>A sub-Arctic salmon-related dataset <span class="citation" data-cites="game_salmon_2018"><a href="../references.html#ref-game_salmon_2018" role="doc-biblioref">[7]</a></span>, showing annotations for each of the measured variables in the dataset. Each annotation is to a precisely defined concept or term from a controlled vocabulary, allowing subtle differences in methodology to be distinguished, which helps with both data discovery and proper reuse. The underlying metadata model is machine-readable, allowing search systems, and amchine learning harvesters to make use of this structured label data.</figcaption>
</figure>
</div>
</section>
<section id="croissant-metadata-for-machine-learning" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="croissant-metadata-for-machine-learning"><span class="header-section-number">3.6</span> Croissant metadata for machine learning</h2>
<p>While domain-specific metadata dialects continue to proliferate, an increasing number of data repositories support <strong><a href="https://schema.org">schema.org</a></strong> as a <em>lingua franca</em> to describe datasets on the web for discoverability. The <a href="https://science-on-schema.org">Science on Schema.org (SOSO)</a> project provides interoperability guidelines for using schema.org metadata in dataset landing pages, and DataONE supports search across repositories that produce schema.org. That said, the dialect is fairly lightweight, somewhat lossely defined, and therefore permits some ambiguity in usage. But it has the major advantage that, as a graph-based metadata dialect, it can be easily extended to support new terms and use cases.</p>
<p>The <strong>Croissant specification</strong> <span class="citation" data-cites="benjelloun_croissant_2024"><a href="../references.html#ref-benjelloun_croissant_2024" role="doc-biblioref">[8]</a></span> extends schema.org with more precise and structured metadata to enable machine-interpretation and use of datasets across multiple tools. While the vocabulary is not as rich as, for example, the ISO 19115 metadata for geospatial metadata, it does provide a more strict structural definition of data types and contents that plain schema.org. A quote from the specification illustrates its intended scope <span class="citation" data-cites="benjelloun_croissant_2024"><a href="../references.html#ref-benjelloun_croissant_2024" role="doc-biblioref">[8]</a></span>:</p>
<blockquote class="blockquote">
<p>The Croissant metadata format simplifies how data is used by ML models. It provides a vocabulary for dataset attributes, streamlining how data is loaded across ML frameworks such as PyTorch, TensorFlow or JAX. In doing so, Croissant enables the interchange of datasets between ML frameworks and beyond, tackling a variety of discoverability, portability, reproducibility, and responsible AI (RAI) challenges.</p>
</blockquote>
<p>Croissant has also explicitly defined <a href="https://docs.mlcommons.org/croissant/docs/croissant-spec.html#ml-specific-features">metadata to meet the needs of machine-learning tools and algorithms</a>. For example, Crosissant supports the definition of categorical values, data splits for training, testing, and prediction, labels/annotations, specification of bounding boxes and segmentation masks.</p>
<p><strong>Label Data.</strong> As an example, Crioissant has specific metadata fields designed to capture which fields with the data contain critical label data, which are used by supervised learning workflows. The Croissant metadata class <code>cr:Label</code> can be used in a <code>RecordSet</code> to indicate that a specific field contians labels that apply to the that record.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"@type"</span><span class="fu">:</span> <span class="st">"cr:RecordSet"</span><span class="fu">,</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"@id"</span><span class="fu">:</span> <span class="st">"images"</span><span class="fu">,</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="dt">"field"</span><span class="fu">:</span> <span class="ot">[</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">{</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"@type"</span><span class="fu">:</span> <span class="st">"cr:Field"</span><span class="fu">,</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"@id"</span><span class="fu">:</span> <span class="st">"images/image"</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span><span class="ot">,</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">{</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"@type"</span><span class="fu">:</span> <span class="st">"cr:Field"</span><span class="fu">,</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"@id"</span><span class="fu">:</span> <span class="st">"images/label"</span><span class="fu">,</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>      <span class="dt">"dataType"</span><span class="fu">:</span> <span class="ot">[</span><span class="st">"sc:Text"</span><span class="ot">,</span> <span class="st">"cr:Label"</span><span class="ot">]</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">}</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  <span class="ot">]</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="fu">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The intention is that multiple tools, all supporting the Crosissant metadata model, will be able to exchange ML-related data seamlessly. A number of ML tools support Croissant out-of-the-box, but only a tiny fraction of the datasets available today use this nascent vocabulary. In addition, it lacks the sophistication of Analysis Ready, Cloud Optimized (ARCO) data standards like Zarr that permit seamless access to massive data with minimal overhead. But it has a lot of promise for streamlining AI-Ready data, and can be used on top of exiting standards like Zarr.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="../images/ai-ready/criossant-cross-product.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13" title="Common ML data providers like Hugging Face and Kaggle could use Croissant to produce ML-optimized datasets, which in turn can be seamlessly loaded and used with compatible ML libraries such as TensorFlow and PyTorch. Image credit: [@benjelloun_croissant_2024]"><img src="../images/ai-ready/criossant-cross-product.png" class="img-fluid figure-img" style="width:100.0%" alt="Common ML data providers like Hugging Face and Kaggle could use Croissant to produce ML-optimized datasets, which in turn can be seamlessly loaded and used with compatible ML libraries such as TensorFlow and PyTorch. Image credit: [8]"></a></p>
<figcaption>Common ML data providers like <a href="https://huggingface.co/">Hugging Face</a> and <a href="https://www.kaggle.com/">Kaggle</a> could use Croissant to produce ML-optimized datasets, which in turn can be seamlessly loaded and used with compatible ML libraries such as TensorFlow and PyTorch. Image credit: <span class="citation" data-cites="benjelloun_croissant_2024"><a href="../references.html#ref-benjelloun_croissant_2024" role="doc-biblioref">[8]</a></span></figcaption>
</figure>
</div>
</section>
<section id="data-quality-1" class="level2 page-columns page-full" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="data-quality-1"><span class="header-section-number">3.7</span> Data Quality</h2>
<p>One of the primary determinants of AI-Ready data is whether the data are of sufficient quality for the intended purpose. While the quality of a dataset may have been high for the iniital hypothesis for which it was generated, it might be quite low (e.g., due to biased or selective sampling) at the scales at which machine learning might operate. Consequently, it is fundamentally important to assess the quality of datasets during the planning and execution of an AI project. Questions such as the following would be of prime interest:</p>
<ul>
<li>Does the dataset represent the complete population of interest?</li>
<li>Does training data reflect an unbiased sample of that population?</li>
<li>Are the data well-documented, enabling methodological interpretation?</li>
<li>Did data collection procedures follow standards for responsible AI and ethical reseatch practices?</li>
<li>Are the data <strong>Tidy</strong> (normalized) and structured (see <a href="https://learning.nceas.ucsb.edu/2024-02-arctic/session_07.html">Tidy Data lesson</a>)?</li>
<li>Are geospatial data accessibly structured, with sufficient metadata (e.g., about the Coordinate Reference System)?</li>
<li>…</li>
</ul>
<p><a href="../images/ai-ready/quality-bullseye.png" class="lightbox" data-gallery="quarto-lightbox-gallery-14"><img src="../images/ai-ready/quality-bullseye.png" class="img-fluid" style="width:100.0%"></a></p>
<p>Many of these issues are encompassed by the <strong>FAIR Principles</strong>, which are intended to ensure that published data are Finadable, Accessible, Interoperable, and Reusable <span class="citation" data-cites="wilkinson_fair_2016 wilkinson_design_2018"><a href="../references.html#ref-wilkinson_fair_2016" role="doc-biblioref">[9]</a>, <a href="../references.html#ref-wilkinson_design_2018" role="doc-biblioref">[10]</a></span>. While there are a huge variety of methods to assess data quality in use across disciplines, some groups have started to harmonize rubrics for data quality and how to represent data quality results in metadata records (see <span class="citation" data-cites="peng_harmonizing_2024"><a href="../references.html#ref-peng_harmonizing_2024" role="doc-biblioref">[11]</a></span>).</p>
<p>DataONE is one such group that has operationalized FAIR Assessment <span class="citation" data-cites="peng_harmonizing_2024"><a href="../references.html#ref-peng_harmonizing_2024" role="doc-biblioref">[11]</a></span>. Within the DataONE network, all compatible datasets are evaluated using an automated FAIR rubric which rates the dataset on 52 FAIR checks <span class="citation" data-cites="jones_quantifying_2019 jones_metadig_2016"><a href="../references.html#ref-jones_quantifying_2019" role="doc-biblioref">[12]</a>, <a href="../references.html#ref-jones_metadig_2016" role="doc-biblioref">[13]</a></span>. Each of these checks is atomic, and looks at a small facet of the dataset quality, but combined they give a powerful assessment of dataset readiness for various analytical purposes. And these suites of checks are extensible, so different groups can create suites of automated quality assessment checks that match their needs and recommendations as a community.</p>
<div class="page-columns page-full">
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p class="page-columns page-full"><a href="../images/ai-ready/metadig-report.png" class="lightbox page-columns page-full" data-gallery="quarto-lightbox-gallery-15" title="DataONE FAIR assessment"><img src="../images/ai-ready/metadig-report.png" class="img-fluid figure-img column-page-right" style="width:100.0%" alt="DataONE FAIR assessment"></a></p>
<figcaption>DataONE FAIR assessment</figcaption>
</figure>
</div>
</div>
<p>We see a marked improvement in dataset quality across the FAIR axes as datasets go through our curation process at the Arctic Data Center.</p>
<p>The Arctic Data Center team is currently working to extend this quality assessment suite to deeper data quality checks. Most of the current checks are based on metadata, mainly because these are accessible through the centralized DataONE network, whereas data are distributed throughout the network, and are much larger. The ADC data quality suite will assess generic quality checks and domain-specific quality checks to produce both dataset-level and project-level quality reports. Some of the key types of checks that are posisble with the system include:</p>
<table class="table-striped table-hover table-primary caption-top table">
<thead>
<tr class="header">
<th>Generic Checks</th>
<th>Domain/Discipline Checks</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Domain and range values</td>
<td>Tree diameters don’t get smaller</td>
</tr>
<tr class="even">
<td>Data type conformance</td>
<td>Unit and measurement semantics</td>
</tr>
<tr class="odd">
<td>Data model normal</td>
<td>Species taxonomy consistent</td>
</tr>
<tr class="even">
<td>Checksum matches metadata</td>
<td>Outlier flagging</td>
</tr>
<tr class="odd">
<td>Malware scans</td>
<td>Allometric relations among variables</td>
</tr>
<tr class="even">
<td>Characters match encoding</td>
<td>Calibration and Validation conformance</td>
</tr>
<tr class="odd">
<td>Primary keys unique</td>
<td>Temporal autocorrelation</td>
</tr>
<tr class="even">
<td>Foreign keys valid</td>
<td>Data / model agreement</td>
</tr>
</tbody>
</table>
</section>
<section id="esip-ai-readiness-checklist" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="esip-ai-readiness-checklist"><span class="header-section-number">3.8</span> ESIP AI-Readiness Checklist</h2>
<p>To round out our survey of AI-Readiness in data, let’s look at the <a href="https://esip.figshare.com/articles/online_resource/Checklist_to_Examine_AI-readiness_for_Open_Environmental_Datasets/19983722/1?file=35578457">AI-Readiness Checklist</a> that has been developed by an inter-agency collaboration at the Earth Science Information Partners (ESIP) <span class="citation" data-cites="noauthor_checklist_2022"><a href="../references.html#ref-noauthor_checklist_2022" role="doc-biblioref">[14]</a></span>. This checklist was designed as a way to evaluate the readiness of a data product for use in specific AI workflows, but it is general enough to apply to a wide variety of datasets. In general, the checklist asks questions about four major areas of readiness:</p>
<ul>
<li>Data Preparation</li>
<li>Data Quality</li>
<li>Data Documentation</li>
<li>Data Access</li>
</ul>
<p>The challenge with this checklist and others is that readiness is truly in the eye of the beholder. Each project has unique data needs, and what is a fine dataset for one analytical purpose (e.g., a regional model) may be entirely inadequate for another (e.g., a pan-Arctic model).</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise: Assess Dataset Readiness
</div>
</div>
<div class="callout-body-container callout-body">
<p>There are a huge variety of datasets available from DataONE and the Arctic Data Center, and many other repositories. In this exercise we will do a quick assessment of AI Readiness for the ice wedge polygon permafrost dataset from the Permafrost Discovery Gateway project [<span class="citation" data-cites="nitze_darts_2024"><a href="../references.html#ref-nitze_darts_2024" role="doc-biblioref">[5]</a></span>], using the ESIP AI-Readiness Checklist.</p>
<p>Link to dataset: - <a href="https://doi.org/110.18739/A2KW57K57">doi:10.18739/A2KW57K57</a> - Visualize <a href="https://arcticdata.io/catalog/portals/permafrost?lt=69.73643449765498&amp;ln=-162.22533942712903&amp;ht=1666.4585052745265&amp;hd=313.1881417811606&amp;p=-37.45517854691816&amp;r=359.9984565878772&amp;el=iwp%2Cosm%2Cahri">Permafrost Ice Wedge Polygon data</a> on PDG:</p>
<p>We’re going to break into groups, and each group will work on a portion of the evaluation for the dataset. The groups are:</p>
<ul>
<li>Group A (Preparation)</li>
<li>Group B (Data Quality)</li>
<li>Group C (Data Documentation)</li>
<li>Group D (Data Access)</li>
</ul>
<p>Instructions: - Make a copy of the <a href="https://docs.google.com/spreadsheets/d/1Kvxt7pUBkr4zdewoOXDHozRrtv9PITpbf625Ri6cqTc/edit?gid=1655512527#gid=1655512527">AI-Readiness Checklist spreadsheet</a> - Split into 4 groups and try to quickly answer the questions (we won’t really have time, so don’t get too bogged down)</p>
<p>Questions to consider as you are doing the assessment: - How much time would it take for you to do a true assessment? - How useful would this assessment be to you if it were available for most datasets? - Is there a correct answer to the checklist questions?</p>
</div>
</div>
<p><a href="../images/ai-ready/iwp-pdg.png" class="lightbox" data-gallery="quarto-lightbox-gallery-16"><img src="../images/ai-ready/iwp-pdg.png" class="img-fluid" style="width:100.0%"></a></p>


<div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-mahecha_earth_2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">M. D. Mahecha <em>et al.</em>, <span>“Earth system data cubes unravel global multivariate dynamics,”</span> <em>Earth System Dynamics</em>, vol. 11, no. 1, pp. 201–234, Feb. 2020, doi: <a href="https://doi.org/10.5194/esd-11-201-2020">10.5194/esd-11-201-2020</a>.</div>
</div>
<div id="ref-noauthor_era5_nodate" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline"><span>“<span>ERA5</span> hourly data on single levels from 1940 to present.”</span> doi: <a href="https://doi.org/10.24381/cds.adbb2d47">https://doi.org/10.24381/cds.adbb2d47</a>.</div>
</div>
<div id="ref-long_ai-ready_2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">S. Long and T. Romanoff, <span>“<span>AI</span>-<span>Ready</span> <span>Open</span> <span>Data</span>.”</span> <span>AI</span>-<span>Ready</span> <span>Open</span> <span>Data</span> <span></span> <span>Bipartisan</span> <span>Policy</span> <span>Center</span>, 2023. Accessed: Oct. 19, 2024. [Online]. Available: <a href="https://bipartisanpolicy.org/explainer/ai-ready-open-data/">https://bipartisanpolicy.org/explainer/ai-ready-open-data/</a></div>
</div>
<div id="ref-reichman_challenges_2011" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">O. J. Reichman, M. B. Jones, and M. P. Schildhauer, <span>“Challenges and opportunities of open data in ecology.”</span> <em>Science (New York, N.Y.)</em>, vol. 331, no. 6018, pp. 703–5, Feb. 2011, doi: <a href="https://doi.org/10.1126/science.1197962">10.1126/science.1197962</a>.</div>
</div>
<div id="ref-nitze_darts_2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">I. Nitze <em>et al.</em>, <span>“<span>DARTS</span>: <span>Multi</span>-year database of <span>AI</span> detected retrogressive thaw slumps (<span>RTS</span>) and active layer detachment slides (<span>ALD</span>) in hotspots of the circum-arctic permafrost region - v1,”</span> 2024, doi: <a href="https://doi.org/10.18739/A2RR1PP44">10.18739/A2RR1PP44</a>.</div>
</div>
<div id="ref-chong_enhancing_2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">S. S. Chong, M. Schildhauer, M. O’Brien, B. Mecum, and M. B. Jones, <span>“Enhancing the <span>FAIRness</span> of <span>Arctic</span> <span>Research</span> <span>Data</span> <span>Through</span> <span>Semantic</span> <span>Annotation</span>,”</span> <em>Data Science Journal</em>, vol. 23, no. 1, Jan. 2024, doi: <a href="https://doi.org/10.5334/dsj-2024-002">10.5334/dsj-2024-002</a>.</div>
</div>
<div id="ref-game_salmon_2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">A. D. of F. Game, D. of C. and Fisheries, and A.-Y.-K. Region, <span>“Salmon age, sex, and length data from <span>Arctic</span>-<span>Yukon</span>-<span>Kuskokwim</span> <span>Region</span> of <span>Alaska</span>, 1960-2017,”</span> 2018, doi: <a href="https://doi.org/10.5063/SN07CZ">10.5063/SN07CZ</a>.</div>
</div>
<div id="ref-benjelloun_croissant_2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">O. Benjelloun <em>et al.</em>, <span>“Croissant <span>Format</span> <span>Specification</span>,”</span> <em>Croissant site</em>. 2024. Accessed: Oct. 20, 2024. [Online]. Available: <a href="https://docs.mlcommons.org/croissant/docs/croissant-spec.html">https://docs.mlcommons.org/croissant/docs/croissant-spec.html</a></div>
</div>
<div id="ref-wilkinson_fair_2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">M. D. Wilkinson <em>et al.</em>, <span>“The <span>FAIR</span> <span>Guiding</span> <span>Principles</span> for scientific data management and stewardship,”</span> <em>Scientific Data</em>, vol. 3, p. 160018, Mar. 2016, doi: <a href="https://doi.org/10.1038/sdata.2016.18">10.1038/sdata.2016.18</a>.</div>
</div>
<div id="ref-wilkinson_design_2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">M. D. Wilkinson, S.-A. Sansone, E. Schultes, P. Doorn, L. O. Bonino da Silva Santos, and M. Dumontier, <span>“A design framework and exemplar metrics for <span>FAIRness</span>,”</span> <em>Scientific Data</em>, vol. 5, p. 180118, Jun. 2018, doi: <a href="https://doi.org/10.1038/sdata.2018.118">10.1038/sdata.2018.118</a>.</div>
</div>
<div id="ref-peng_harmonizing_2024" class="csl-entry" role="listitem">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">G. Peng <em>et al.</em>, <span>“Harmonizing quality measures of <span>FAIRness</span> assessment towards machine-actionable quality information,”</span> <em>International Journal of Digital Earth</em>, vol. 17, no. 1, p. 2390431, Dec. 2024, doi: <a href="https://doi.org/10.1080/17538947.2024.2390431">10.1080/17538947.2024.2390431</a>.</div>
</div>
<div id="ref-jones_quantifying_2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">M. Jones, P. Slaughter, and T. Habermann, <span>“Quantifying <span>FAIR</span>: Metadata improvement and guidance in the <span>DataONE</span> repository network.”</span> 2019. doi: <a href="https://doi.org/10.5063/f1kp80gx">https://doi.org/10.5063/f1kp80gx</a>.</div>
</div>
<div id="ref-jones_metadig_2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">M. Jones <em>et al.</em>, <span>“<span>MetaDIG</span>: <span>Engaging</span> <span>Scientists</span> in the <span>Improvement</span> of <span>Metadata</span> and <span>Data</span>,”</span> <em>Figshare</em>, 2016, doi: <a href="https://doi.org/10.6084/m9.figshare.4055808.v1">10.6084/m9.figshare.4055808.v1</a>.</div>
</div>
<div id="ref-noauthor_checklist_2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline"><span>“Checklist to <span>Examine</span> <span>AI</span>-readiness for <span>Open</span> <span>Environmental</span> <span>Datasets</span>,”</span> <em>figshare</em>. Jun. 2022. doi: <a href="https://doi.org/10.6084/m9.figshare.19983722.v1">10.6084/m9.figshare.19983722.v1</a>.</div>
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../sections/ai-for-everyone.html" class="pagination-link" aria-label="AI for Everyone">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI for Everyone</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../sections/data-annotation.html" class="pagination-link" aria-label="Data Annotation: The Foundation of Deep Learning Models">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Data Annotation: The Foundation of Deep Learning Models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"loop":false,"openEffect":"zoom","selector":".lightbox","descPosition":"bottom","closeEffect":"zoom"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>