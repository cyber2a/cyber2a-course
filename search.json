[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cyber2A: AI for Arctic Research",
    "section": "",
    "text": "Course Overview\nAI for Arctic Research represents an introduction to Artificial Intelligence (AI) techniques produced by the Cyber2A project, an innovative training program to empower the Arctic science community with advanced AI-driven data analytics and cyberinfrastructure (CI) skills to tackle the pressing challenges facing the Arctic and thus our planet. Today, Artificial Intelligence has become one of the most powerful tools to analyze Arctic big data and enable new ways of data-driven discovery. However, training on these emerging topics is often missing in current undergraduate and graduate curricula, particularly for active Arctic researchers. This project aims to fill this skills gap in order to foster the growth of an Arctic science workforce with strong data science skills through a series of complementary and mutually reinforcing training activities.\nThe week-long course is designed with a modular curriculum, where each module can be incorporated into learning activities across Universities and other organizations. The curriculum is free to be re-used, licensed under a CC-BY Attribution license and covers 5 main topical areas:\nThe sections presented here fit into a one-week workshop as follows, but the modules can be also used individually:",
    "crumbs": [
      "Course Overview"
    ]
  },
  {
    "objectID": "index.html#session-structure-and-content",
    "href": "index.html#session-structure-and-content",
    "title": "Cyber2A: AI for Arctic Research",
    "section": "Session Structure and Content",
    "text": "Session Structure and Content\nThe course has been designed with several guiding principals in mind.\n\nBalance Theory and Hands-On Work: Spend about one-third of the time on theory and the other two-thirds on hands-on activities.\nBuild Gradually: Start with the basics and build up gradually. Expand both the theory and hands-on tasks as you go along.\nChoose Your Tools: You can use either Jupyter Notebook or VSCode for the hands-on parts of your session. Choose whichever one you’re more comfortable with.\nOpen Data Licensing: Use open data for examples that can be ethically shared and re-used, both within the workshop and when the course materials are used and incorporated into other courses.\nOffer Support: Make sure participants know how to ask for help if they get stuck. Regularly ask participants if they’re keeping up and adjust the pace if needed.\nExtra Resources: Provide additional materials like readings or videos for participants who want to learn more.",
    "crumbs": [
      "Course Overview"
    ]
  },
  {
    "objectID": "index.html#about-this-book",
    "href": "index.html#about-this-book",
    "title": "Cyber2A: AI for Arctic Research",
    "section": "About this book",
    "text": "About this book\nCitation:\n\nWenwen Li, Anna Liljedahl, Matthew B. Jones, Chia-Yu Hsu, Alyona Kosobokova, Jim Regetz, Chandi Witharana, Yili Yang, Ben Galewsky, Minu Mathew, Sandeep Satheesan, Nicole Greco, Kenton McHenry, Carmen Galaz García, Kate Holman Billmeier. 2024. AI for Arctic Research. Arctic Data Center. doi:10.18739/A2222R77V\n\nThe materials in this book are licensed for reuse, and are available from the cyber2a-course github repository. The book is written in Quarto, a cross platform markdown-based platform for writing books and technical materials that works with Python, R, and other languages.\n\nGetting Started: You can find a guide to getting started with Quarto, including editing and previewing content locally with various tools, here.\nQuarto Guide: You can find a comprehensive guide to Quarto here.\nFormat: You can choose to write your content in either Jupyter Notebook (.ipynb) or Markdown files (.qmd). Quarto can render both formats. And both formats can be easily included in other teaching materials.\nEmbed Notebooks: If you choose to write your content in Markdown but have a separate Jupyter Notebook for the hands-on part, you can embed the notebook. Follow the guide here to learn how to do this.",
    "crumbs": [
      "Course Overview"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Cyber2A: AI for Arctic Research",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese course materials were developed with funding for Cyber2A from the National Science Foundation under award # 2230034 to W. Li and M. Jones and award # 2230035 to A. Liljedahl and K. McHenry",
    "crumbs": [
      "Course Overview"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Cyber2A: AI for Arctic Research",
    "section": "License",
    "text": "License\n\nCyber2A: AI for Arctic Research is licensed under CC BY 4.0",
    "crumbs": [
      "Course Overview"
    ]
  },
  {
    "objectID": "sections/breaking-the-ice-with-ai-in-arctic-science.html",
    "href": "sections/breaking-the-ice-with-ai-in-arctic-science.html",
    "title": "1  Breaking the Ice with AI in Arctic Science",
    "section": "",
    "text": "1.1 The changing Arctic\nThe Arctic is one of the Earth’s remaining frontiers that is critical to the Earth’s climate system. Climate warming and change have pushed the Arctic ecosystem to a tipping point: the frozen is becoming unfrozen with subsequent dramatic impact to its terrestrial and coastal landscapes. Permafrost warming and degradation are documented across the Arctic[1], [2], [3], and are coupled with long-term global warming and extremes in air temperature and precipitation [4], [5], [6]. Further, Arctic sea ice is decreasing rapidly [7], which increases coastal erosion rates across the globe [8]. The Arctic region is remote and is experiencing dramatic changes with local and global implications due to the shift from ice to water: altered soil carbon fluxes [9], changes in vegetation cover [10], shifts in animal behavior [11], and challenges to infrastructure [12]. Accordingly, the transformation of ice to water through degrading permafrost and melting sea and lake ice reverberates through the entire Arctic ecosystem and, therefore, enlists the interest of a broad range of earth, engineering, and social science disciplines [13]. Remote sensing of satellite imagery is an important approach in developing Arctic baseline information, monitoring change, and exploring physical processes [14], [15]. Today, there exist important climatic, geological, biological and sociological data that are yet to be exploited by the Arctic science community. To make the best possible use of these data to address the pressing challenges facing the Arctic environment and Arctic people, the more advanced methods and tools that are available need to be applied. AI-driven analytics, especially those incorporating deep machine learning, can process Arctic big data, automatically detect hidden patterns, and derive new knowledge to enable a new wave of data-driven discovery [16].",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Breaking the Ice with AI in Arctic Science</span>"
    ]
  },
  {
    "objectID": "sections/breaking-the-ice-with-ai-in-arctic-science.html#the-changing-arctic",
    "href": "sections/breaking-the-ice-with-ai-in-arctic-science.html#the-changing-arctic",
    "title": "1  Breaking the Ice with AI in Arctic Science",
    "section": "",
    "text": "Arctic mountains",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Breaking the Ice with AI in Arctic Science</span>"
    ]
  },
  {
    "objectID": "sections/breaking-the-ice-with-ai-in-arctic-science.html#ai-for-arctic-challenges",
    "href": "sections/breaking-the-ice-with-ai-in-arctic-science.html#ai-for-arctic-challenges",
    "title": "1  Breaking the Ice with AI in Arctic Science",
    "section": "1.2 AI for Arctic Challenges",
    "text": "1.2 AI for Arctic Challenges\n\n\n\n\n\n\n“AI will be the most transformative technology since electricity.” – Eric Schmidt\n\n\n\n\n\n\n\n\n\n“AI is just another model.” – Unknown\n\n\n\n\n\n\n\n\n\nArtificial Intelligence\n\n\n\n\n\nArtificial Intelligence (AI) in its broadest sense describes the focus on computing systems that exhibit forms of intelligence. Multiple approaches towards AI have been identified, including:\n\nKnowledge Representation and Reasoning to gain a semantic, logical model of a system\nMachine Learning in which statistical models are used for pattern recognition and prediction\nNatural Language Processing for communication in human languages such as English\nExpert Systems using rule-based logical systems for decision-making\nLarge Language Models for filtering and generating language\n…\n\n\n\n\nThe pursuit of AI as a field has been around since the 1956 with the Dartmouth Workshop, but really took a leap forward in the 2010’s with rising performance of computing hardware and new techniques in machine learning, particularly in the field of deep learning. More recently, AI has entered the public consciousness with the promotion of large language models (LLMs) such as the GPT-3 transformer model and related generative AI systems that are based on foundation models and can quickly generate new outputs [17].\n\n\n\n\n\n\n\n\n\nMachine Learning\n\n\n\n\n\nMachine learning (ML) is the subfield of AI concerned with pattern detection using statistical models, which then can be applied to unseen data for prediction and extrapolation without explicit instructions [18]. This mechanistic view of ‘learning’ supports robust evaluation of error and has applications in computer vision, image recognition, speech recognition, text processing and filtering, and many more areas.\n\n\n\nTechniques for machine learning are often divided into three types (supervised, unsupervised, and reinforcement learning). These techiques differ based on the feedback provided to the learning system:\n\nSupervised learning: Training input data are labeled (often manually) by a human, and the algorithm learns by generalizing from these inputs to predict correct outputs\nUnsupervised learning: Without labels, the ML algorithm is designed to detect patterns and structure in the input, often using techniques like gradient descent, clustering, and classification algorithms.\nReinforcement learning: A ML algorithm learns dynamically from interactive input to solve a problem or learn a goal, where correct responses are rewarded (weighted) higher than less correct responses. Learning then becomes an optimization/hill-climbing problem.\n\nThese general approaches all have strengths and weaknesses, and are often used in combination to tackle different aspects of a learning problem.",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Breaking the Ice with AI in Arctic Science</span>"
    ]
  },
  {
    "objectID": "sections/breaking-the-ice-with-ai-in-arctic-science.html#geospatial-ai",
    "href": "sections/breaking-the-ice-with-ai-in-arctic-science.html#geospatial-ai",
    "title": "1  Breaking the Ice with AI in Arctic Science",
    "section": "1.3 Geospatial AI",
    "text": "1.3 Geospatial AI\nIn this course, we will more narrowly focus on geospatial applications of AI, and particularly on the use of deep learning techniques that employ, for example, convolutional neural networks for feature recognition tasks across massive image datasets such as satellite imagery. As we’ll see during the course, advances in computing hardware, and particularly in available Graphical Processing Unit (GPU) performance have enabled massive growth in the scale of models that can be generated. Today, we can train deep learning models on high-resolution, sub-meter scale satellite imagery (e.g., pan-Arctic, 50cm Maxar imagery), and apply the generated models across the Arctic to better understand change at Arctic scales.\nFor one example, Witharana et al. [19] trained a convolutional neural network model on Maxar imagery, and used the trained model to detect permafrost ice-wedges across the entire Arctic at sub-meter scale [20], producing a map of over a billion vector features, and the first-ever permafrost map at this scale.",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Breaking the Ice with AI in Arctic Science</span>"
    ]
  },
  {
    "objectID": "sections/breaking-the-ice-with-ai-in-arctic-science.html#welcome-and-introductions",
    "href": "sections/breaking-the-ice-with-ai-in-arctic-science.html#welcome-and-introductions",
    "title": "1  Breaking the Ice with AI in Arctic Science",
    "section": "1.4 Welcome and Introductions",
    "text": "1.4 Welcome and Introductions\nLet’s kick the week off with a warm welcome and round of introductions. We’ll start with our Cyber2A project instructors and speakers, and then introduce each of our participants. Everyone is here due to a deep interest in finding solutions to challenges in Arctic science, and everyone is on their own personal journey through data and science. To learn a little about one another, let’s share:\n\nName and affiliation\nYour data science background (be brief!)\nOne! thing you’d like to get out of the course\n\n\n\nArtwork by @allison_horst",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Breaking the Ice with AI in Arctic Science</span>"
    ]
  },
  {
    "objectID": "sections/breaking-the-ice-with-ai-in-arctic-science.html#cyber2a-project",
    "href": "sections/breaking-the-ice-with-ai-in-arctic-science.html#cyber2a-project",
    "title": "1  Breaking the Ice with AI in Arctic Science",
    "section": "1.5 Cyber2A project",
    "text": "1.5 Cyber2A project\nDespite the power of these machine learning techniques for Arctic research, the Arcitc community has been somewhat delayed compared to other geoscience disciplines in adopting these techniques.\n\nThe Cyber2A project aims to build an Arctic learning community to stimulate the use of GeoAI through data science education. This short-course represents a first pass at a survey of relevant AI techniques that would be useful across Arctic regions and disciplines. The goal is to produce an online curriculum and materials that can be used for self-paced learning by Arctic researchers, and can be included in University graduate and undergraduate courses. While there are many online tutorials on machine learning and AI, these materials will specifically target the types of data and challenges typically found in Arctic research, and focus in on the techniques that will make data science learning more approachable.\nThis course is also a starting point, and not an endpoint. We welcome feedback, suggestions, revisions, and edits to the materials. We want people to adopt, adapt, and revise the materials, and, importantly, contribute those changes back so that others can benefit from these curricular advances. Look for more from Cyber2A as we continue to engage in promoting the use of GeoAI across the Arctic.",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Breaking the Ice with AI in Arctic Science</span>"
    ]
  },
  {
    "objectID": "sections/breaking-the-ice-with-ai-in-arctic-science.html#references",
    "href": "sections/breaking-the-ice-with-ai-in-arctic-science.html#references",
    "title": "1  Breaking the Ice with AI in Arctic Science",
    "section": "References",
    "text": "References\n\n\n[1] A.\nK. Liljedahl et al., “Pan-Arctic ice-wedge\ndegradation in warming permafrost and its influence on tundra\nhydrology,” Nature Geoscience, vol. 9, no. 4, pp.\n312–318, Apr. 2016, doi: 10.1038/ngeo2674.\n\n\n[2] A.\nA. Vasiliev, D. S. Drozdov, A. G. Gravis, G. V. Malkova, K. E. Nyland,\nand D. A. Streletskiy, “Permafrost degradation in the\nWestern Russian Arctic,”\nEnvironmental Research Letters, vol. 15, no. 4, p. 045001, Apr.\n2020, doi: 10.1088/1748-9326/ab6f12.\n\n\n[3] S.\nL. Smith, H. B. O’Neill, K. Isaksen, J. Noetzli, and V. E. Romanovsky,\n“The changing thermal state of permafrost,” Nature\nReviews Earth & Environment, vol. 3, no. 1, pp. 10–23, Jan.\n2022, doi: 10.1038/s43017-021-00240-1.\n\n\n[4] T.\nA. Douglas, M. R. Turetsky, and C. D. Koven, “Increased rainfall\nstimulates permafrost thaw across a variety of Interior\nAlaskan boreal ecosystems,” npj Climate and\nAtmospheric Science, vol. 3, no. 1, pp. 1–7, Jul. 2020, doi: 10.1038/s41612-020-0130-4.\n\n\n[5] R.\nÍ. Magnússon et al., “Extremely wet summer events enhance\npermafrost thaw for multiple years in Siberian\ntundra,” Nature Communications, vol. 13, no. 1, p. 1556,\nMar. 2022, doi: 10.1038/s41467-022-29248-x.\n\n\n[6] L.\nM. Farquharson, V. E. Romanovsky, W. L. Cable, D. A. Walker, S. V.\nKokelj, and D. Nicolsky, “Climate Change\nDrives Widespread and Rapid\nThermokarst Development in Very\nCold Permafrost in the Canadian\nHigh Arctic,” Geophysical Research\nLetters, vol. 46, no. 12, pp. 6681–6689, 2019, doi: 10.1029/2019GL082187.\n\n\n[7] D.\nNotz and J. Stroeve, “Observed Arctic sea-ice loss\ndirectly follows anthropogenic CO2 emission,”\nScience, vol. 354, no. 6313, pp. 747–750, Nov. 2016, doi: 10.1126/science.aag2345.\n\n\n[8] D.\nM. Nielsen, M. Dobrynin, J. Baehr, S. Razumov, and M. Grigoriev,\n“Coastal Erosion Variability at the\nSouthern Laptev Sea\nLinked to Winter Sea\nIce and the Arctic\nOscillation,” Geophysical Research Letters,\nvol. 47, no. 5, p. e2019GL086876, 2020, doi: 10.1029/2019GL086876.\n\n\n[9] L.\nBruhwiler, F.-J. W. Parmentier, P. Crill, M. Leonard, and P. I. Palmer,\n“The Arctic Carbon Cycle\nand Its Response to Changing\nClimate,” Current Climate Change Reports,\nvol. 7, no. 1, pp. 14–34, Mar. 2021, doi: 10.1007/s40641-020-00169-5.\n\n\n[10] T.\nK. F. Campbell, T. C. Lantz, R. H. Fraser, and D. Hogan, “High\nArctic Vegetation Change\nMediated by Hydrological\nConditions,” Ecosystems, vol. 24, no. 1,\npp. 106–121, Jan. 2021, doi: 10.1007/s10021-020-00506-7.\n\n\n[11] S.\nC. Davidson et al., “Ecological insights from three\ndecades of animal movement tracking across a changing\nArctic,” Science, vol. 370, no. 6517, pp.\n712–715, Nov. 2020, doi: 10.1126/science.abb7080.\n\n\n[12] L.\nSuter, D. Streletskiy, and N. Shiklomanov, “Assessment of the cost\nof climate change impacts on critical infrastructure in the circumpolar\nArctic,” Polar Geography, vol. 42, no. 4,\npp. 267–286, Oct. 2019, doi: 10.1080/1088937X.2019.1686082.\n\n\n[13] M.\nL. Druckenmiller et al., “The\nArctic,” Bulletin of the American Meteorological\nSociety, vol. 102, no. 8, pp. S263–S316, Aug. 2021, doi: 10.1175/BAMS-D-21-0086.1.\n\n\n[14] M.\nPhilipp, A. Dietz, S. Buchelt, and C. Kuenzer, “Trends in\nSatellite Earth Observation for\nPermafrost Related\nAnalyses—A Review,”\nRemote Sensing, vol. 13, no. 6, p. 1217, Jan. 2021, doi: 10.3390/rs13061217.\n\n\n[15] “Changing state of Arctic\nsea ice across all seasons - IOPscience.” Accessed:\nOct. 18, 2024. [Online]. Available: https://iopscience.iop.org/article/10.1088/1748-9326/aade56\n\n\n[16] “AI in\nAnalytics: Top Use\nCases and Tools.” Accessed: Oct. 18,\n2024. [Online]. Available: https://www.marketingaiinstitute.com/blog/how-to-use-artificial-intelligence-for-analytics\n\n\n[17] M.\nI. Jordan and T. M. Mitchell, “Machine learning:\nTrends, perspectives, and prospects,”\nScience, vol. 349, no. 6245, pp. 255–260, Jul. 2015, doi: 10.1126/science.aaa8415.\n\n\n[18] A.\nVaswani et al., “Attention is all you need,” in\nAdvances in neural information processing systems, I. Guyon, U.\nV. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R.\nGarnett, Eds., Curran Associates, Inc., 2017. Available: https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n\n\n[19] C.\nWitharana et al., “An\nObject-Based Approach for\nMapping Tundra\nIce-Wedge Polygon\nTroughs from Very High\nSpatial Resolution Optical\nSatellite Imagery,” Remote\nSensing, vol. 13, no. 4, p. 558, Jan. 2021, doi: 10.3390/rs13040558.\n\n\n[20] C.\nWitharana et al., “Ice-wedge polygon detection in\nsatellite imagery from pan-Arctic regions,\nPermafrost Discovery Gateway,\n2001-2021,” 2023, doi: 10.18739/A2KW57K57.",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Breaking the Ice with AI in Arctic Science</span>"
    ]
  },
  {
    "objectID": "sections/ai-for-everyone.html",
    "href": "sections/ai-for-everyone.html",
    "title": "2  AI for Everyone",
    "section": "",
    "text": "2.1 Learning Objectives\nThis session introduces AI to a non-specialist audience, ensuring participants can understand essential concepts. The focus is on key terminology and principles of machine learning (ML), deep learning (DL), and neural networks (NN). By the end of this session, participants will have foundational knowledge of AI concepts to engage with more advanced topics.",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>AI for Everyone</span>"
    ]
  },
  {
    "objectID": "sections/ai-for-everyone.html#table-of-contents",
    "href": "sections/ai-for-everyone.html#table-of-contents",
    "title": "2  AI for Everyone",
    "section": "2.2 Table of Contents",
    "text": "2.2 Table of Contents\n\nWhat is AI? History and Challenges\nTypes and Techniques\nWorking with Data\nThe Role of AI in Modern Research\nThe Future of AI & Science\nHands-On: Setting up the Coding Environment",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>AI for Everyone</span>"
    ]
  },
  {
    "objectID": "sections/ai-for-everyone.html#what-is-ai",
    "href": "sections/ai-for-everyone.html#what-is-ai",
    "title": "2  AI for Everyone",
    "section": "2.3 What is AI?",
    "text": "2.3 What is AI?\nArtificial Intelligence (AI) refers to computer systems capable of performing tasks requiring cognitive functions, such as recognizing patterns, learning from data, and making predictions.\nBut what is human intelligence? Well, we don’t really know…\nLet’s focus on a simpler question. \nWe think experientially or in other words, probabilistically.",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>AI for Everyone</span>"
    ]
  },
  {
    "objectID": "sections/ai-for-everyone.html#ai-types-and-techniques",
    "href": "sections/ai-for-everyone.html#ai-types-and-techniques",
    "title": "2  AI for Everyone",
    "section": "2.4 AI Types and Techniques",
    "text": "2.4 AI Types and Techniques\n\n2.4.1 Machine Learning (ML)\n\n\nSupervised Learning: Training on labeled data.\nUnsupervised Learning: Discovering patterns within unlabeled data.\nSemi-Supervised: Training on autogenerated labeles.\nReinforcement Learning (RL): An agent learns by interacting with an environment, commonly used in robotics.\n\n\n\n2.4.2 Neural Networks (NN)\nNeural Networks are loosely inspired by the brain’s structure, NNs consist of interconnected nodes (neurons) that process information. NN Playground:\n   \n\n\n2.4.3 Deep Learning\n   \n\nConvolutional Neural Networks (CNN) are specialized for processing structured data, like images.\nLarge Language Models (LLM) are neural networks that understand and generate human language (e.g., GPT-3).\nRecurrent Neural Networks (RNN) handle sequential data by remembering previous inputs,. They are used for tasks like speech recognition and time series.",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>AI for Everyone</span>"
    ]
  },
  {
    "objectID": "sections/ai-for-everyone.html#data",
    "href": "sections/ai-for-everyone.html#data",
    "title": "2  AI for Everyone",
    "section": "2.5 Data",
    "text": "2.5 Data\n“Garbage in, garbage out”, or quality data leads to accurate models.\n\nStructured Data: Clearly defined types (e.g., temperature readings).\nUnstructured Data: Complex formats (e.g., satellite imagery), requiring preprocessing.\n\nKey takeaway: Data is the foundation for accurate predictions and insights in AI.",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>AI for Everyone</span>"
    ]
  },
  {
    "objectID": "sections/ai-for-everyone.html#rapid-surge-in-ai-talk-why-now",
    "href": "sections/ai-for-everyone.html#rapid-surge-in-ai-talk-why-now",
    "title": "2  AI for Everyone",
    "section": "2.6 Rapid Surge in AI Talk: Why Now?",
    "text": "2.6 Rapid Surge in AI Talk: Why Now?\n\n2.6.1 Brief History:\n\n1986: Backpropagation was introduced by Geoffrey Hinton and colleagues, revolutionizing neural networks by enabling them to adjust weights and improve through learning. This breakthrough laid the foundation for modern deep learning.\n2017: The Transformer architecture was introduced, which transformed natural language processing (NLP) using an attention mechanism. It allowed models to weigh the importance of words in a sequence and process entire sentences in parallel, significantly improving efficiency and accuracy.\n2018-2020: The combination of backpropagation, advanced computing power (GPUs, cloud technology), and the availability of large datasets led to the rise of Large Language Models (LLMs) like GPT-3, with 175 billion parameters, capable of generating human-like text and answering questions.\n\nKey takeaway: The transformer model paved the way for advanced LLMs like GPT-3, driving the current AI surge. Advancements in computing power allowed these models to process massive datasets quickly, enabling them to generate highly accurate predictions, perform complex tasks, and revolutionize fields such as language processing, automation, and research.",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>AI for Everyone</span>"
    ]
  },
  {
    "objectID": "sections/ai-for-everyone.html#the-future-of-ai-in-science",
    "href": "sections/ai-for-everyone.html#the-future-of-ai-in-science",
    "title": "2  AI for Everyone",
    "section": "2.7 The Future of AI in Science",
    "text": "2.7 The Future of AI in Science\n\nScientific Method and AI:\n\nObservation: AI aids data collection (e.g., computer vision).\nHypothesis: Unsupervised learning clusters data.\nExperiment: Reinforcement learning simulates environments.\nConclusion: AI can analyze data and validate hypotheses. AI helps identify patterns in data and can support every step of the scientific method, from observation to conclusion.",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>AI for Everyone</span>"
    ]
  },
  {
    "objectID": "sections/ai-for-everyone.html#additional-resources",
    "href": "sections/ai-for-everyone.html#additional-resources",
    "title": "2  AI for Everyone",
    "section": "2.8 Additional Resources",
    "text": "2.8 Additional Resources\nBooks: - Ray Kurzweil, How to Create a Mind (2012) - Max Bennett, A Brief History of Intelligence (2023)    Videos: - 3Blue1Brown’s Neural Networks Playlist\nPapers: - Jakob Uszkoreit, The Transformer (2017)",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>AI for Everyone</span>"
    ]
  },
  {
    "objectID": "sections/ai-for-everyone.html#do-you-have-any-questions",
    "href": "sections/ai-for-everyone.html#do-you-have-any-questions",
    "title": "2  AI for Everyone",
    "section": "2.9 Do You Have Any Questions?",
    "text": "2.9 Do You Have Any Questions?\nFeel free to reach out! /n - Email: alyonak@nceas.ucsb.edu - Website: alonakosobokova.com - YouTube: Dork Matter Girl",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>AI for Everyone</span>"
    ]
  },
  {
    "objectID": "sections/ai-ready-data-in-arctic-research.html",
    "href": "sections/ai-ready-data-in-arctic-research.html",
    "title": "3  AI-Ready Data in Arctic Research: Principles and Practices",
    "section": "",
    "text": "Goal\nThis session provides an understanding of ‘AI-ready data’ in Arctic science and geoscience, highlighting the importance of suitable data for AI applications. Participants will learn about creating and managing metadata and organizing data repositories. We’ll discuss best practices for data preparation and structuring for AI processing. By the end, participants will clearly understand AI-ready data characteristics and the steps to transform raw data for AI applications.",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>AI-Ready Data in Arctic Research: Principles and Practices</span>"
    ]
  },
  {
    "objectID": "sections/ai-ready-data-in-arctic-research.html#key-elements",
    "href": "sections/ai-ready-data-in-arctic-research.html#key-elements",
    "title": "3  AI-Ready Data in Arctic Research: Principles and Practices",
    "section": "Key Elements",
    "text": "Key Elements\nAI-ready data definition, data suitability importance, metadata management, data repository organization, data preparation practices, raw data transformation",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>AI-Ready Data in Arctic Research: Principles and Practices</span>"
    ]
  },
  {
    "objectID": "sections/data-annotation.html",
    "href": "sections/data-annotation.html",
    "title": "4  Data Annotation: The Foundation of Deep Learning Models",
    "section": "",
    "text": "Goal\nThis session explores the critical role of training data in deep learning, focusing on data annotation methods, tools, and strategies for acquiring high-quality data. Participants will learn how well-annotated data supports effective deep learning models, understanding the challenges and best practices in data annotation. By the end, participants will be equipped to prepare their datasets for deep learning.",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Annotation: The Foundation of Deep Learning Models</span>"
    ]
  },
  {
    "objectID": "sections/data-annotation.html#key-elements",
    "href": "sections/data-annotation.html#key-elements",
    "title": "4  Data Annotation: The Foundation of Deep Learning Models",
    "section": "Key Elements",
    "text": "Key Elements\nTraining data’s role, annotation methods/tools, annotated data’s importance, annotation challenges, annotation best practices, dataset preparation",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Annotation: The Foundation of Deep Learning Models</span>"
    ]
  },
  {
    "objectID": "sections/hands-on-lab-data-annotation.html",
    "href": "sections/hands-on-lab-data-annotation.html",
    "title": "5  Hands-On Lab: Data Annotation",
    "section": "",
    "text": "Goal\nThis hands-on lab session is designed to give participants practical experience in data annotation for deep learning. Participants will apply the methods, tools, and best practices discussed in the previous session, working directly with datasets to annotate data effectively.",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Hands-On Lab: Data Annotation</span>"
    ]
  },
  {
    "objectID": "sections/hands-on-lab-data-annotation.html#key-elements",
    "href": "sections/hands-on-lab-data-annotation.html#key-elements",
    "title": "5  Hands-On Lab: Data Annotation",
    "section": "Key Elements",
    "text": "Key Elements\nUse of annotation methods and tools, direct dataset interaction",
    "crumbs": [
      "<b>Day 1: Introduction to AI and Arctic Science</b>",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Hands-On Lab: Data Annotation</span>"
    ]
  },
  {
    "objectID": "sections/the-building-blocks-of-nn-and-dl.html",
    "href": "sections/the-building-blocks-of-nn-and-dl.html",
    "title": "6  The Building Blocks of Neural Networks and Deep Learning",
    "section": "",
    "text": "6.1 Overview\nThis session aims to provide a comprehensive introduction to the fundamental components of neural networks and deep learning. Participants will explore the architecture of neural networks, including layers, neurons, weights, and activation functions, as well as the principles behind training models, such as loss functions and optimizers. The goal is to equip participants with a solid understanding of how neural networks are constructed and how they learn, paving the way for deeper dives into specific neural network models and applications in future sessions.",
    "crumbs": [
      "<b>Day 2: AI Fundamentals and Techniques</b>",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Building Blocks of Neural Networks and Deep Learning</span>"
    ]
  },
  {
    "objectID": "sections/the-building-blocks-of-nn-and-dl.html#outline",
    "href": "sections/the-building-blocks-of-nn-and-dl.html#outline",
    "title": "6  The Building Blocks of Neural Networks and Deep Learning",
    "section": "6.2 Outline",
    "text": "6.2 Outline\n\nFundamentals of neural network: history and evolution\nCore components: neurons, layers, and weights\nArchitecture of neural networks: layers and activation functions\nTraining neural networks: loss functions and optimizers\nConclusion and Q&A",
    "crumbs": [
      "<b>Day 2: AI Fundamentals and Techniques</b>",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Building Blocks of Neural Networks and Deep Learning</span>"
    ]
  },
  {
    "objectID": "sections/the-building-blocks-of-nn-and-dl.html#reference",
    "href": "sections/the-building-blocks-of-nn-and-dl.html#reference",
    "title": "6  The Building Blocks of Neural Networks and Deep Learning",
    "section": "6.3 Reference",
    "text": "6.3 Reference\n\nhttps://cs231n.stanford.edu",
    "crumbs": [
      "<b>Day 2: AI Fundamentals and Techniques</b>",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>The Building Blocks of Neural Networks and Deep Learning</span>"
    ]
  },
  {
    "objectID": "sections/intro-to-pytorch.html",
    "href": "sections/intro-to-pytorch.html",
    "title": "7  Introduction to PyTorch: Core Functionalities and Advantages",
    "section": "",
    "text": "7.1 Goal\nThis session introduces PyTorch, one of the most popular deep learning frameworks, known for its flexibility and ease of use. Participants will gain hands-on experience with PyTorch’s core functionalities and apply them to a sample dataset, setting the stage for a subsequent hands-on session. The goal is to arm participants with the essential knowledge and confidence required to begin utilizing PyTorch in their deep learning endeavors, ensuring they’re well-prepared for practical application and further exploration.",
    "crumbs": [
      "<b>Day 2: AI Fundamentals and Techniques</b>",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introduction to PyTorch: Core Functionalities and Advantages</span>"
    ]
  },
  {
    "objectID": "sections/intro-to-pytorch.html#outline",
    "href": "sections/intro-to-pytorch.html#outline",
    "title": "7  Introduction to PyTorch: Core Functionalities and Advantages",
    "section": "7.2 Outline",
    "text": "7.2 Outline\n\nIntroduction to PyTorch\nUnderstanding PyTorch’s core functionalities\nWorking with data in PyTorch\nBuilding a simple neural network in PyTorch\nTraining a model\nEvaluating a model\nConclusion and preparing for hands-on session",
    "crumbs": [
      "<b>Day 2: AI Fundamentals and Techniques</b>",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introduction to PyTorch: Core Functionalities and Advantages</span>"
    ]
  },
  {
    "objectID": "sections/intro-to-pytorch.html#reference",
    "href": "sections/intro-to-pytorch.html#reference",
    "title": "7  Introduction to PyTorch: Core Functionalities and Advantages",
    "section": "7.3 Reference",
    "text": "7.3 Reference\n\nhttps://pytorch.org\nhttps://pytorch.org/tutorials/",
    "crumbs": [
      "<b>Day 2: AI Fundamentals and Techniques</b>",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Introduction to PyTorch: Core Functionalities and Advantages</span>"
    ]
  },
  {
    "objectID": "sections/hands-on-lab-pytorch.html",
    "href": "sections/hands-on-lab-pytorch.html",
    "title": "8  Hands-On Lab: PyTorch",
    "section": "",
    "text": "8.1 Overview\nThis hands-on lab session is designed to provide participants with practical experience using PyTorch to build, train, and evaluate neural network models. Participants will work through guided exercises that reinforce the concepts introduced in the previous session, applying PyTorch to real-world datasets relevant to Arctic research. By the end of this session, participants will have a solid understanding of how to implement deep learning models using PyTorch, empowering them to tackle their own projects with confidence.",
    "crumbs": [
      "<b>Day 2: AI Fundamentals and Techniques</b>",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hands-On Lab: PyTorch</span>"
    ]
  },
  {
    "objectID": "sections/hands-on-lab-pytorch.html#outline",
    "href": "sections/hands-on-lab-pytorch.html#outline",
    "title": "8  Hands-On Lab: PyTorch",
    "section": "8.2 Outline",
    "text": "8.2 Outline\n\nRecap of PyTorch core functionalities\nGuided exercise 1: working with real-world datasets\nGuided exercise 2: building a simple neural network\nGuided exercise 3: training and evaluating the model\nTroubleshooting and optimization tips\nConclusion and Q&A",
    "crumbs": [
      "<b>Day 2: AI Fundamentals and Techniques</b>",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hands-On Lab: PyTorch</span>"
    ]
  },
  {
    "objectID": "sections/hands-on-lab-pytorch.html#reference",
    "href": "sections/hands-on-lab-pytorch.html#reference",
    "title": "8  Hands-On Lab: PyTorch",
    "section": "8.3 Reference",
    "text": "8.3 Reference\n\nhttps://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\nhttps://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\nhttps://pytorch.org/tutorials/beginner/vt_tutorial.html",
    "crumbs": [
      "<b>Day 2: AI Fundamentals and Techniques</b>",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Hands-On Lab: PyTorch</span>"
    ]
  },
  {
    "objectID": "sections/permafrost-discovery-gateway.html",
    "href": "sections/permafrost-discovery-gateway.html",
    "title": "9  Permafrost Discovery Gateway",
    "section": "",
    "text": "We have more satellite imagery data than what we know what to do with. There are many people with different knowledges and common passions for permafrost-affected landscapes. At the same time, Alaska and the Arctic at large are starving for basic geospatial information about it’s permafrost-affected landscape and infrastructure and people may have a hard time finding others to help make visions come true. The Permafrost Discovery Gateway (PDG) is an online free tool meant to empower a) researchers to produce and do science with big geospatial data (think sub-meter resolution maps across Alaska and the entire Arctic) and b) agencies and community leaders in land and infrastructure management that involves permafrost. PDG currently offers easy visual exploration via a regular web-browser of datasets that otherwise crush traditional GIS software due to the file size. In the works are, for example, new big datasets of permafrost thaw features and infrastructure, partial dataset download tool, the incorporation of statistical summaries and AI tools that help the user find interesting stories in the big data products, plug-and-play workflows to help you develop your own big dataset, and the monitoring of permafrost thaw near-real time. The PDG can become a gateway where data and people can connect, where technology enables anyone with an internet connection, no matter your technical skills and resources, to connect, explore, and together create.",
    "crumbs": [
      "<b>Day 2: AI Fundamentals and Techniques</b>",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Permafrost Discovery Gateway</span>"
    ]
  },
  {
    "objectID": "sections/ai-ethics.html",
    "href": "sections/ai-ethics.html",
    "title": "10  AI Ethics",
    "section": "",
    "text": "Goal\nReview FAIR and CARE Principles, and their relevance to data ethics. Examine how ethical considerations are shared and considered at the Arctic Data Center. Discuss ethical considerations in machine learning.",
    "crumbs": [
      "<b>Day 2: AI Fundamentals and Techniques</b>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>AI Ethics</span>"
    ]
  },
  {
    "objectID": "sections/ai-ethics.html#introduction",
    "href": "sections/ai-ethics.html#introduction",
    "title": "10  AI Ethics",
    "section": "10.1 Introduction",
    "text": "10.1 Introduction\nArtificial Intelligence (AI) can be thought of as the development of computer systems that can perform tasks we usually think require human intelligence, such as image recognition, language translation, or autonomous movement. The rapid development and adoption of AI tools in the past years, particularly machine learning algorithms, has revolutionized how big datasets are analyzed, transforming decision-making in all sectors of society. However, frameworks to examine the ethical considerations of AI are just emerging, and careful consideration of how to best develop and apply AI systems is essential to the responsible use of these new, rapidly changing tools. In this section, we will give an overview of the FAST Principles put forward by the Alan Turing Institute in their guide for the responsible design and implementation of AI systems (Leslie, 2019).\n\n10.1.1 The FAST Principles\nFAST stands for Fairness, Accountability, Sustainability, and Transparency. The FAST principles aim to guide the ethical development of AI projects from their inception to deployment. The continuous involvement and commitment of software developers, domain experts, technical leads, project managers, rightsholders, and collaborators involved in the AI project is crucial to implement these principles successfully. The following is a brief overview of each of the FAST principles, we greatly encourage you to read through the Alan Turing Institute guide to learn more!\n\n\n\nLeslie, 2019\n\n\n\n\n10.1.2 Fairness\nBias can enter at any point of a research project, from data collection and preprocessing, to model design and implementation. This is because AI projects, as any other, are created by human beings who (even with the best of intentions) can introduce error, prejudice, or misjudgement into a system. Fairness refers to the active minimization of bias and commitment to not harm others through the outcomes of an AI system. The FAST principles (Leslie, 2019) suggest the following baseline for fairness:\n\nThe designers and users of AI systems ensure that the decisions and behaviours of their models do not generate discriminatory or inequitable impacts on affected individuals and communities. This entails that these designers and users ensure that the AI systems they are developing and deploying:\n\nAre trained and tested on properly representative, relevant, accurate, and generalisable datasets (Data Fairness)\nHave model architectures that do not include target variables, features, processes, or analytical structures (correlations, interactions, and inferences) which are unreasonable, morally objectionable, or unjustifiable (Design Fairness)\nDo not have discriminatory or inequitable impacts on the lives of the people they affect (Outcome Fairness)\nAre deployed by users sufficiently trained to implement them responsibly and without bias (Implementation Fairness)\n\n\n\n\n\n\n\n\nReal-life Example : Insufficient Radar Network\n\n\n\n\n\nThe following figure (McGovern et al., 2022) shows coverage of the national Doppler weather network (green and yellow circles) over a demographic map of the Black population in the southeast US. This would be an example of an issue in data fairness, since radar coverage does not represent the population uniformly, leaving out areas with higher Black population. Problems with outcome fairness could ensue if this non-representative biases an AI model to under-predict weather impacts in such populations.\n\n\n\nMcGovern et al., 2022 by courtesy of Jack Sillin (CC BY 4.0).\n\n\n\n\n\n\n\n10.1.3 Accountability\nAccountability in AI projects stems from the shared view that isolated AI models used to automate decisions are not morally responsible in the same way as a decision-making human. As outputs from AI models are increasingly used to make decisions that affect the environment and human lives, there is a critical need for competent human authorities to offer explanations and justifications for the development process, outputs, and ensuing decisions made by AI systems. Such answerability assignments can be challenging, as AI implementations are often the product of big development teams where the responsibility to answer for a project’s outcome may not be delineated, creating an issue known as “the problem of many hands.” The FAST principles encourage the following accountability implementation:\nAccountability by Design: All AI systems must be designed to facilitate end-to-end answerability and auditability. This requires both responsible humans-in-the-loop across the entire design and implementation chain as well as activity monitoring protocols that enable end-to-end oversight and review.\n\n\n\n\n\n\nReal-life Example: AI for natural disasters response\n\n\n\n\n\nAccountability and the ability to audit AI methods can be crucial when model outputs support critical decision-making, such as in natural disasters. In 2021, a New York Times investigation (Fink, 2021) covered a private company’s premature release of outputs about neighborhoods most affected by potential earthquakes in Seattle. While the initial release erroneously did not show threats for non-residential areas, ensuing updated versions showed non-compatible predictions again. Although the company acknowledged that its AI models would not replace the first responder’s judgment, the lack of audibility and opacity in the model development hindered accountability for any party, ultimately eroding the public confidence in the tools and leading to a loss of public resources.\n\n\n\n\n\n\n10.1.4 Sustainability\nSustainability in the FAST principles includes continuous assessment of the social impacts of an AI system and technical sustainability of the AI model. In the first consideration, the FAST principles advocate for performing a Stakeholder Impact Assessment (SIA) at different stages to help build confidence in the project and uncover unexpected risks or biases, among other benefits. The Alan Turing Institute guide shares a prototype of an SIA (Leslie, 2019). The core of technical sustainability is creating safe, accurate, reliable, secure, and robust AI systems. To achieve these technical goals, teams must implement thorough testing, performance metrics, uncertainty quantification, and be aware of changes to the underlying distribution of data, among other essential practices.\n\n\n\n\n\n\nReal-life Example: SpaceCows\n\n\n\n\n\nThe SpaceCows project (Shepherd, 2021; ABC Australia, 2024) in northern Australia is a collaboration between scientists, industry leaders, and local indigenous communities developing AI centered platforms to analyze GPS tracking data collected from feral cows alongside satellite imagery and weather data. Indigenous knowledge and traditional land owners have been at the center of the development, providing guidance and ultimately benefiting from the AI tools to protect their land and cultural sites.\n\n\n\nImportant indigenous cultural sites can be damaged by feral cattle. Image from CSIRO, SpaceCows: Using AI to tackle feral herds in the Top End.\n\n\nVideos with more information on SpaceCows:\nCSIRO rolls out world’s largest remote ‘space cows’ herd management system\nSpaceCows: Using AI to tackle feral herds in the Top End\n\n\n\n\n\n10.1.5 Transparency\nUnder the FAST principles, transparency in AI projects refers to transparency about how an AI project was designed and implemented and the content and justification of the outcome produced by the AI model. To ensure process transparency, the project should show how the design and implementation included ethical, safety, and fairness considerations throughout the project. To clarify the content and explain the outcomes of an AI system, the project should offer plain language, non-technical explanations accessible to non-specialists that convey how and why a model performed the way it did. In this direction, it is essential to avoid a ‘mathematical glass box’ where the code and mathematics behind the algorithm are openly available, but there is a lack of rationale about how or why the model goes from input to output. Finally, the explanations about how the outcomes were produced should become the basis to justify the outcomes in terms of ethical permissibility, fairness, and trustworthiness. A careful consideration of the balance between the sustainability and transparency principles is necessary when dealing with protected or private data.\n\n\n\n\n\n\nReal-life Example: France’s Digital Republic Act\n\n\n\n\n\nThe concern for transparency in using personal data is an active space for debate. In 2018, the French government passed a law to protect citizens’ privacy, establishing the citizen’s “right to an explanation” regarding, among other things, how an algorithm contributed to decisions on their persona and which data was processed (Edwards and Veale, 2017; Lo Piano, 2020). Overall, this legislation aims to create a fairer and more transparent digital environment where everyone can enjoy equal opportunities.\n\n\n\nPhoto by Google DeepMind\n\n\n\n\n\n\n\n10.1.6 Conclusion\nAs new AI developments and applications rapidly emerge and transform everyday life, we need to pause and ensure these technologies are fair, sustainable, and transparent. We must acknowledge human responsibility in designing and implementing AI systems to use these novel tools fairly and with accountability. Finally, we acknowledge that the information covered here is a lightning introduction to AI’s ethical considerations and implications. Whether you are a researcher interested in using AI for the first time or a seasoned ML practitioner, we urge you to dive into the necessary and ever-expanding AI ethics work to learn how to best incorporate these concepts into your work.",
    "crumbs": [
      "<b>Day 2: AI Fundamentals and Techniques</b>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>AI Ethics</span>"
    ]
  },
  {
    "objectID": "sections/ai-ethics.html#references",
    "href": "sections/ai-ethics.html#references",
    "title": "10  AI Ethics",
    "section": "10.2 References",
    "text": "10.2 References\nEdwards, Lilian, and Michael Veale. (2017). Enslaving the algorithm: From a  right to an explanationn to a  right to better decisionss?. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.3052831.\nFink, Sheri. (2019). “This High-Tech Solution to Disaster Response May Be Too Good to Be True.” The New York Times. www.nytimes.com/2019/08/09/us/emergency-response-disaster-technology.html.\nLeslie, D. (2019). Understanding artificial intelligence ethics and safety: A guide for the responsible design and implementation of AI systems in the public sector. The Alan Turing Institute. https://doi.org/10.5281/zenodo.3240529\nLo Piano, S. (2020). Ethical principles in machine learning and artificial intelligence: cases from the field and possible ways forward. Humanit Soc Sci Commun 7, 9. https://doi.org/10.1057/s41599-020-0501-9\nMcGovern, A., Ebert-Uphoff, I., Gagne, D. J., & Bostrom, A. (2022). Why we need to focus on developing ethical, responsible, and trustworthy artificial intelligence approaches for environmental science. Environmental Data Science, 1, e6. doi:10.1017/eds.2022.5\nShepard, Tory. (2021) Indigenous Rangers to Use SpaceCows Program to Protect Sacred Sites and Rock Art from Feral Herds.” The Guardian, Guardian News and Media. www.theguardian.com/australia-news/2021/sep/15/indigenous-rangers-to-use-spacecows-program-to-protect-sacred-sites-and-rock-art-from-feral-herds.\n(2021). SpaceCows: Using AI to Tackle Feral Herds in the Top End. CSIRO. www.csiro.au/en/news/all/news/2021/september/spacecows-using-ai-to-tackle-feral-herds-in-the-top-end.",
    "crumbs": [
      "<b>Day 2: AI Fundamentals and Techniques</b>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>AI Ethics</span>"
    ]
  },
  {
    "objectID": "sections/ai-ethics.html#further-reading",
    "href": "sections/ai-ethics.html#further-reading",
    "title": "10  AI Ethics",
    "section": "10.3 Further Reading",
    "text": "10.3 Further Reading\nAcademic Data Science Alliance (ADSA) (2024) The Data Sciene Ethos https://ethos.academicdatascience.org\nChen, W., & Quan-Haase, A. (2020) Big Data Ethics and Politics: Towards New Understandings. Social Science Computer Review. https://journals.sagepub.com/doi/10.1177/0894439318810734\nCrawford, K., & Paglen, T. (2019) Excavating AI: The Politics of Training Sets for Machine Learning. https://excavating.ai/\nGray, J., & Witt, A. (2021) A feminist data ethics of care framework for machine learning: The what, why, who and how. First Monday, 26(12), Article number: 11833",
    "crumbs": [
      "<b>Day 2: AI Fundamentals and Techniques</b>",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>AI Ethics</span>"
    ]
  },
  {
    "objectID": "sections/guest-lecture-yili-arts-dataset.html",
    "href": "sections/guest-lecture-yili-arts-dataset.html",
    "title": "11  Guest Lecture - Unveiling the ARTS Dataset for a Thawing Frontier",
    "section": "",
    "text": "11.1 Overview\nIn this session, we will introduce and explore the Arctic Retrogressive Thaw Slump (ARTS) dataset. We aim to illuminate the background and motivation behind the ARTS dataset, detail its design elements including functions, metadata, and usage, and underscore its defining features such as scalability, scientific integrity, and the potential for community contribution.",
    "crumbs": [
      "<b>Day 3: Advanced AI Workflows and Models</b>",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Guest Lecture - Unveiling the ARTS Dataset for a Thawing Frontier</span>"
    ]
  },
  {
    "objectID": "sections/guest-lecture-yili-arts-dataset.html#outline",
    "href": "sections/guest-lecture-yili-arts-dataset.html#outline",
    "title": "11  Guest Lecture - Unveiling the ARTS Dataset for a Thawing Frontier",
    "section": "11.2 Outline",
    "text": "11.2 Outline\n\nBackground and motivation of the Arctic\nRetrogressive Thaw Slump (ARTS) data set.\nSource data for the ARTS data set\nDesign of the data set - functions, metadata, usage\nFeatures of the data set - scalable, scientific, contributable\nData Curation Framework - standards, protocols\nThe ARTS repository - user and contributor guideline\nQuestions and discussions",
    "crumbs": [
      "<b>Day 3: Advanced AI Workflows and Models</b>",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Guest Lecture - Unveiling the ARTS Dataset for a Thawing Frontier</span>"
    ]
  },
  {
    "objectID": "sections/guest-lecture-yili-arts-dataset.html#reference",
    "href": "sections/guest-lecture-yili-arts-dataset.html#reference",
    "title": "11  Guest Lecture - Unveiling the ARTS Dataset for a Thawing Frontier",
    "section": "11.3 Reference",
    "text": "11.3 Reference\n\nhttps://github.com/whrc/ARTS",
    "crumbs": [
      "<b>Day 3: Advanced AI Workflows and Models</b>",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Guest Lecture - Unveiling the ARTS Dataset for a Thawing Frontier</span>"
    ]
  },
  {
    "objectID": "sections/exploring-advanced-neural-networks.html",
    "href": "sections/exploring-advanced-neural-networks.html",
    "title": "12  Exploring Advanced Neural Networks: Semantic Segmentation",
    "section": "",
    "text": "12.1 Overview\nThis session focuses on advanced neural networks, specifically targeting semantic segmentation. Participants will delve into models such as Fully Convolutional Networks (FCNs) and U-Net, learning how these networks are structured, how they function, and how they can be applied to accurately segment and label each pixel of an image according to the object it represents. The goal is to deepen participants’ understanding of the technical foundations and practical applications of semantic segmentation, equipping them with the skills needed for hands-on implementation and exploration of its real-world utility, particularly in the context of Arctic research.",
    "crumbs": [
      "<b>Day 3: Advanced AI Workflows and Models</b>",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Exploring Advanced Neural Networks: Semantic Segmentation</span>"
    ]
  },
  {
    "objectID": "sections/exploring-advanced-neural-networks.html#outline",
    "href": "sections/exploring-advanced-neural-networks.html#outline",
    "title": "12  Exploring Advanced Neural Networks: Semantic Segmentation",
    "section": "12.2 Outline",
    "text": "12.2 Outline\n\nIntroduction to semantic segmentation\nOverview of key models: Fully Convolutional Networks (FCNs) and U-Net\nDetailed architecture and functionality\nApplications in Arctic research: case studies\nConclusion and Q&A",
    "crumbs": [
      "<b>Day 3: Advanced AI Workflows and Models</b>",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Exploring Advanced Neural Networks: Semantic Segmentation</span>"
    ]
  },
  {
    "objectID": "sections/exploring-advanced-neural-networks.html#reference",
    "href": "sections/exploring-advanced-neural-networks.html#reference",
    "title": "12  Exploring Advanced Neural Networks: Semantic Segmentation",
    "section": "12.3 Reference",
    "text": "12.3 Reference\n\nRonneberger, Olaf, Philipp Fischer, and Thomas Brox. “U-net: Convolutional networks for biomedical image segmentation.” Medical image computing and computer-assisted intervention–MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18. Springer International Publishing, 2015. https://arxiv.org/abs/1505.04597\nMinaee, Shervin, et al. “Image segmentation using deep learning: A survey.” IEEE transactions on pattern analysis and machine intelligence 44.7 (2021): 3523-3542. http://www.arxiv.org/abs/2001.05566",
    "crumbs": [
      "<b>Day 3: Advanced AI Workflows and Models</b>",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Exploring Advanced Neural Networks: Semantic Segmentation</span>"
    ]
  },
  {
    "objectID": "sections/intro-to-dl-libraries-for-image-analysis.html",
    "href": "sections/intro-to-dl-libraries-for-image-analysis.html",
    "title": "13  Introduction to Deep Learning Libraries for Image Analysis",
    "section": "",
    "text": "13.1 Overview\nThis session introduces participants to MMSegmentation, a specialized deep learning library designed for semantic segmentation tasks. Participants will explore the unique capabilities of MMSegmentation in handling sophisticated image analysis projects. The session will cover how to navigate the library, implement advanced features, and apply them to real-world datasets, particularly in the context of Arctic research. While the focus will be on MMSegmentation, Detectron2 will also be mentioned as another powerful tool for image analysis. By the end of this session, participants will have a theoretical understanding of MMSegmentation and be prepared for a more extensive hands-on lab session.",
    "crumbs": [
      "<b>Day 3: Advanced AI Workflows and Models</b>",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduction to Deep Learning Libraries for Image Analysis</span>"
    ]
  },
  {
    "objectID": "sections/intro-to-dl-libraries-for-image-analysis.html#outline",
    "href": "sections/intro-to-dl-libraries-for-image-analysis.html#outline",
    "title": "13  Introduction to Deep Learning Libraries for Image Analysis",
    "section": "13.2 Outline",
    "text": "13.2 Outline\n\nIntroduction to MMSegmentation: features and capabilities\nNavigating MMSegmentation: tools and techniques\nImplementing semantic segmentation with MMSegmentation\nPractical applications in Arctic research\nBrief overview of Detectron2 for comparison\nConclusion and Q&A",
    "crumbs": [
      "<b>Day 3: Advanced AI Workflows and Models</b>",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduction to Deep Learning Libraries for Image Analysis</span>"
    ]
  },
  {
    "objectID": "sections/intro-to-dl-libraries-for-image-analysis.html#reference",
    "href": "sections/intro-to-dl-libraries-for-image-analysis.html#reference",
    "title": "13  Introduction to Deep Learning Libraries for Image Analysis",
    "section": "13.3 Reference",
    "text": "13.3 Reference\n\nhttps://github.com/open-mmlab/mmsegmentation\nhttps://github.com/facebookresearch/detectron2 (for further exploration)",
    "crumbs": [
      "<b>Day 3: Advanced AI Workflows and Models</b>",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduction to Deep Learning Libraries for Image Analysis</span>"
    ]
  },
  {
    "objectID": "sections/hands-on-lab-mmsegmentation.html",
    "href": "sections/hands-on-lab-mmsegmentation.html",
    "title": "14  Hands-On Lab: MMSegmentation",
    "section": "",
    "text": "14.1 Overview\nThis hands-on lab session provides participants with practical experience using MMSegmentation to perform semantic segmentation tasks. Participants will engage in guided exercises that build on the concepts introduced in the previous session, applying MMSegmentation to real-world datasets relevant to Arctic research. By the end of this session, participants will have gained the practical skills necessary to implement and fine-tune semantic segmentation models using MMSegmentation, enabling them to effectively apply these techniques in their own research projects.",
    "crumbs": [
      "<b>Day 3: Advanced AI Workflows and Models</b>",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Hands-On Lab: MMSegmentation</span>"
    ]
  },
  {
    "objectID": "sections/hands-on-lab-mmsegmentation.html#outline",
    "href": "sections/hands-on-lab-mmsegmentation.html#outline",
    "title": "14  Hands-On Lab: MMSegmentation",
    "section": "14.2 Outline",
    "text": "14.2 Outline\n\nRecap of MMSegmentation core functionalities\nGuided exercise 1: preparing and loading data\nGuided exercise 2: building and training a semantic segmentation model\nGuided exercise 3: evaluating and fine-tuning the model\nWorking with real-world datasets: Arctic research applications\nTroubleshooting and optimization tips\nConclusion and Q&A",
    "crumbs": [
      "<b>Day 3: Advanced AI Workflows and Models</b>",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Hands-On Lab: MMSegmentation</span>"
    ]
  },
  {
    "objectID": "sections/hands-on-lab-mmsegmentation.html#reference",
    "href": "sections/hands-on-lab-mmsegmentation.html#reference",
    "title": "14  Hands-On Lab: MMSegmentation",
    "section": "14.3 Reference",
    "text": "14.3 Reference\n\nhttps://mmsegmentation.readthedocs.io/en/latest/user_guides/index.html",
    "crumbs": [
      "<b>Day 3: Advanced AI Workflows and Models</b>",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Hands-On Lab: MMSegmentation</span>"
    ]
  },
  {
    "objectID": "sections/ai-workflows-and-mlops.html",
    "href": "sections/ai-workflows-and-mlops.html",
    "title": "15  AI Workflows and MLOps: From Development to Deployment",
    "section": "",
    "text": "15.1 Instructors\nBen Galewsky, Sr. Research Software Engineer National Center for Supercomputing Applications (NCSA) University of Illinois Urbana-Champaign",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>AI Workflows and MLOps: From Development to Deployment</span>"
    ]
  },
  {
    "objectID": "sections/ai-workflows-and-mlops.html#overview",
    "href": "sections/ai-workflows-and-mlops.html#overview",
    "title": "15  AI Workflows and MLOps: From Development to Deployment",
    "section": "15.2 Overview",
    "text": "15.2 Overview\nMachine learning models have become a vital tool for most branches of science. The process and tools for training these models on the lab’s desktop is often fragile, slow, and not reproducible. In this workshop, we will introduce the concept of MLOps, which is a set of practices that aims to streamline the process of developing, training, and deploying machine learning models. We will use the popular open source MLOps tool, MLflow, to demonstrate how to track experiments, package code, and deploy models. We will also introduce Garden, a tool that allows researchers to publish ML Models as citable objects.",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>AI Workflows and MLOps: From Development to Deployment</span>"
    ]
  },
  {
    "objectID": "sections/ai-workflows-and-mlops.html#outline",
    "href": "sections/ai-workflows-and-mlops.html#outline",
    "title": "15  AI Workflows and MLOps: From Development to Deployment",
    "section": "15.3 Outline",
    "text": "15.3 Outline\n\nIntroduction to MLOps\nIntroduction to MLflow\nTracking experiments with MLflow\nPackaging code with MLflow\nDeploying models with MLflow\nPublishing models with Garden",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>AI Workflows and MLOps: From Development to Deployment</span>"
    ]
  },
  {
    "objectID": "sections/ai-workflows-and-mlops.html#reference",
    "href": "sections/ai-workflows-and-mlops.html#reference",
    "title": "15  AI Workflows and MLOps: From Development to Deployment",
    "section": "15.4 Reference",
    "text": "15.4 Reference\n\nMLflow\nGarden",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>AI Workflows and MLOps: From Development to Deployment</span>"
    ]
  },
  {
    "objectID": "sections/foundation-models.html",
    "href": "sections/foundation-models.html",
    "title": "17  Foundation Models: The Cornerstones of Modern AI",
    "section": "",
    "text": "17.1 Overview\nFoundation models (FM) are deep learning models trained on massive raw unlabelled datasets usually through self-supervised learning. FMs enable today’s data scientists to use them as the base and fine-tune using domain specific data to obtain models that can handle a wide range of tasks [1, 6, 7]. In this talk, we provide an introduction to FMs, its history, evolution, and go through its key features and categories, and a few examples. We also briefly discuss how foundation models work. This talk will be a precursor to the hands-on session that follows on the same topic.\nImage source: 2021 paper on foundation models by Stanford researchers [1].\nIn this session, we take a closer look at what constitutes a foundation model, a few examples, and some basic principles around how it works.",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Foundation Models: The Cornerstones of Modern AI</span>"
    ]
  },
  {
    "objectID": "sections/foundation-models.html#outline",
    "href": "sections/foundation-models.html#outline",
    "title": "17  Foundation Models: The Cornerstones of Modern AI",
    "section": "17.2 Outline",
    "text": "17.2 Outline\n\nIntroduction to foundation models, its history and evolution\nKey features of foundation models\nTypes of foundation models: Language, Vision, Generative, and Multimodal\nExamples of foundation models: BERT [3], GPT [4], YOLO [2], SAM [5], DALLE-2\nHow do foundation models work?",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Foundation Models: The Cornerstones of Modern AI</span>"
    ]
  },
  {
    "objectID": "sections/foundation-models.html#reference",
    "href": "sections/foundation-models.html#reference",
    "title": "17  Foundation Models: The Cornerstones of Modern AI",
    "section": "17.3 Reference",
    "text": "17.3 Reference\n\nOn the opportunities and risk of Foundation models\nYou Only Look Once\nBERT\nGPT3\nSegment Anything Model\nNVIDIA blog post on foundation models\nWhat are Foundation Models? - Generative AI",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Foundation Models: The Cornerstones of Modern AI</span>"
    ]
  },
  {
    "objectID": "sections/hands-on-lab-foundation-models.html",
    "href": "sections/hands-on-lab-foundation-models.html",
    "title": "18  Hands-On Lab: Foundation Models",
    "section": "",
    "text": "18.1 Overview\nThe hands-on lab on foundation models will focus on building and applying small-scale foundation models for some example use cases. The main goal of this 1-hour session will be to get more familiarized with foundation models and in interacting with them.",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Hands-On Lab: Foundation Models</span>"
    ]
  },
  {
    "objectID": "sections/hands-on-lab-foundation-models.html#outline",
    "href": "sections/hands-on-lab-foundation-models.html#outline",
    "title": "18  Hands-On Lab: Foundation Models",
    "section": "18.2 Outline",
    "text": "18.2 Outline\n\nImage Segmentation using Segment Anything Model (SAM)\nChatbot using LLMs + RAG",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Hands-On Lab: Foundation Models</span>"
    ]
  },
  {
    "objectID": "sections/hands-on-lab-foundation-models.html#references",
    "href": "sections/hands-on-lab-foundation-models.html#references",
    "title": "18  Hands-On Lab: Foundation Models",
    "section": "18.3 References",
    "text": "18.3 References\n\nSegment Anything\nSegment Anything Notebook",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Hands-On Lab: Foundation Models</span>"
    ]
  },
  {
    "objectID": "sections/reproducibility.html",
    "href": "sections/reproducibility.html",
    "title": "19  Reproducibility",
    "section": "",
    "text": "19.1 Goal\nThis session aims to highlight the importance of reproducibility in AI-driven Arctic research. Participants will learn about the challenges and best practices for ensuring that AI models and their results can be reproduced by other researchers, a cornerstone for building trust and advancing the field. The discussion will cover strategies for documenting experiments, sharing data and code, and using version control systems.",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reproducibility</span>"
    ]
  },
  {
    "objectID": "sections/reproducibility.html#introduction",
    "href": "sections/reproducibility.html#introduction",
    "title": "19  Reproducibility",
    "section": "19.2 Introduction",
    "text": "19.2 Introduction\nReproducibility is not a new topic when it comes to artificial intelligence and machine learning in science, but is more important than ever as AI research is often criticized for not being reproducible. This becomes particularly problematic when validation of a model requires reproducing it.",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reproducibility</span>"
    ]
  },
  {
    "objectID": "sections/reproducibility.html#why-is-reproducibility-important",
    "href": "sections/reproducibility.html#why-is-reproducibility-important",
    "title": "19  Reproducibility",
    "section": "19.3 Why is Reproducibility Important?",
    "text": "19.3 Why is Reproducibility Important?\n\n19.3.1 Reproducible vs. Replicable\nReproducibility is important in science because it allows other researchers to validate the results of a study and/or use the same analysis for processing their data, promoting open science and collaboration.\n\nReproducible means that other researchers can take the same data, run the same analysis, and get the same result.\nReplicable means other researchers can take different data, run the same analysis, and get their own result without errors.",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reproducibility</span>"
    ]
  },
  {
    "objectID": "sections/reproducibility.html#the-reproducibility-checklist",
    "href": "sections/reproducibility.html#the-reproducibility-checklist",
    "title": "19  Reproducibility",
    "section": "19.4 The Reproducibility Checklist",
    "text": "19.4 The Reproducibility Checklist\nThe Reproducibility Checklist was created by Canadian computer scientist, Joelle Pineau, with the goal of facilitating reproducible machine learning algorithms that can be tested and replicated. When publishing your model, it is beneficial to work through this checklist and ensure that you’re including the items on this checklist. The checklist is as follows:\nFor all models and algorithms, check that you include:\n\nA clear description of the mathematical setting, algorithm, and/or model\nAn analysis of the complexity (time, space, sample size) of any algorithm\nA link to a downloadable source code*, with specification of all dependencies, including external libraries\n\nFor any theoretical claim, check that you include:\n\nA statement of the result\nA clear explanation of each assumption\nA complete proof of the claim\n\nFor all figures and tables that include empirical results, check that you include:\n\nA complete description of the data collection process, including sample size\nA link to a downloadable version of the dataset or simulation environment\nAn explanation of any data that was excluded and a description of any preprocessing step\nAn explanation of how samples were allocated for training, validation, and testing\nThe range of hyperparameters considered, method to select the best hyperparameter configuration, and specification of each hyperparameter used to generate results\nThe exact number of evaluation runs\nA description of how experiments were run\nA clear definition of the specific measure of statistics used to report results\nClearly defined error bars\nA description of results with central tendency (e.g., mean) and variation (e.g., standard deviation)\nA description of the computing infrastructure used\n\n*With sensitive data or proprietary code, scientists may not wish to release all of their code and data. In this case, data can be anonymized and/or partial code can be released that won’t run but can be read and reproduced.\nConsider the sensitivity of your data/code when publishing.\n\nSensitive data should be anonymized before publishing\nResearchers or organizations may only release partial code if their code is proprietary\nBe sure that the partial code released can still be read and reproduced",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reproducibility</span>"
    ]
  },
  {
    "objectID": "sections/reproducibility.html#sharing-code",
    "href": "sections/reproducibility.html#sharing-code",
    "title": "19  Reproducibility",
    "section": "19.5 Sharing Code",
    "text": "19.5 Sharing Code\nThe first step to solving the problem of reproducibility is sharing the code that was used to generate the model. This allows other researchers to:\n\nValidate the model\nTrack code construction and see any author annotations\nExpand on published work\n\nDespite this, sharing code does not always mean that models are fully reproducible. Many machine learning models are trained on restricted datasets or require extensive computing power for training the model. Because of this, there are a few additional criteria that improve reproducibility including:\n\nData and metadata availability (must be included without question)\nTransparency of the code you’re using and dependencies needed to run the code\nEasily installable computational analysis tools and pipelines\nInstalled software should behave the same on every machine and should have the same runtime\n\n\n19.5.1 Trips and Tricks to Sharing Code\n\nAvoid using absolute file paths when reading in data (and in general the use of slashes, as these differ between operating systems)\n\n\n\n\nAvoid using an absolute path to read in your data as shown here\n\n\n\nClean your data within your code\nAvoid copy/pasting in a spreadsheet\nAlways keep an unedited version of your raw data\n\nA general guide to publishing reproducible work:",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reproducibility</span>"
    ]
  },
  {
    "objectID": "sections/reproducibility.html#model-repositories",
    "href": "sections/reproducibility.html#model-repositories",
    "title": "19  Reproducibility",
    "section": "19.6 Model Repositories",
    "text": "19.6 Model Repositories\nPyTorch Hub is a pre-trained model repository designed to facilitate reproducibility and enable new research. It is easily usable with Colab and Papers with Code, but models must be trained on openly accessible data.\n\nPapers with Code is an open source hub for publications that include direct links to GitHub code, no account needed to access datasets.",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reproducibility</span>"
    ]
  },
  {
    "objectID": "sections/reproducibility.html#version-control",
    "href": "sections/reproducibility.html#version-control",
    "title": "19  Reproducibility",
    "section": "19.7 Version Control",
    "text": "19.7 Version Control\n\nVersion control is the process of keeping track of every individual change by each contributor that’s saved in a version control framework, or a special database. Keeping a history of these changes to track model performance relative to model parameters saves the time you’d spend retraining the model.\nThe three components of version control in machine learning are:\n\nCode: We recommend writing and storing your model code in the same language as your implementation code to make it easier to maintain all code and dependencies\nData: Versioning should link the data to the appropriate metadata and note any changes in either\nModel: The model connects your code and data with your model parameters and analysis\n\nUsing a version control system ensures easier:\n\nCollaboration\n\nCollaborators can easily pull changes from a shared repository, push their own changes, annotate their code, and revert back to previous versions of their model\n\nVersioning\n\nIf your model breaks, you’ll have a log of any changes that were made, allowing you or others to revert back to a stable version\n\nDependency tracking\n\nYou can test more than one model on different branches or repositories, tune the model parameters and hyperparameters, and monitor the accuracy of each implemented change\n\nModel updates\n\nVersion control allows for incrementally released versions while continuing the development of the next release",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reproducibility</span>"
    ]
  },
  {
    "objectID": "sections/reproducibility.html#summary",
    "href": "sections/reproducibility.html#summary",
    "title": "19  Reproducibility",
    "section": "19.8 Summary",
    "text": "19.8 Summary\nConsider the following to ensure your model is reproducible:\n\nUse the reproducibility checklist for algorithms, theoretical claims, and figures/tables.\nAnonymize any sensitive data and remove proprietary code before publishing\n\nBUT still provide training data and enough code for others to replicate your model\n\nShare data and metadata, be transparent in any dependencies needed to run your model, use easily installable computational analysis tools and pipelines, and ensure installed software behaves the same on every machine (i.e. runtime)\nUse a pre-trained model repository (ex. PyTorch Hub) and publish to open-source journals/websites (ex. Papers with Code)\nPractice efficient version control (recommend GitHub if working with collaborators)",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reproducibility</span>"
    ]
  },
  {
    "objectID": "sections/reproducibility.html#hands-on-activity",
    "href": "sections/reproducibility.html#hands-on-activity",
    "title": "19  Reproducibility",
    "section": "19.9 Hands-On Activity",
    "text": "19.9 Hands-On Activity\nLEGO Metadata: In groups of 3-5 people, take ~15 minutes to create a structure out of LEGO bricks and write instructions for a group who will recreate your structure based on these instructions.\nGroups will then be rotated and given instructions and LEGO pieces from another group where they will have ~15 minutes to attempt to recreate that group’s structure.\nWe will have a closing group discussion about this activity. Some questions include:\n\nWhat were some assumptions you made while writing your instructions?\nWere there any unexpected hurdles you encountered when writing your instructions or trying to replicate another group’s structure?\nWhat did you find most difficult about this activity?\nNow that you see how successful or unsuccessful the other group was in recreating your structure, is there anything you would do differently?\n\nThis activity was adapted from the Lego Metadata for Reproducibility Game Pack (doi: 10.36399/gla.pubs.196477) developed by Mary Donaldson and Matt Mahon at the University of Glasgow.",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reproducibility</span>"
    ]
  },
  {
    "objectID": "sections/reproducibility.html#references-resources",
    "href": "sections/reproducibility.html#references-resources",
    "title": "19  Reproducibility",
    "section": "19.10 References & Resources",
    "text": "19.10 References & Resources\n\nGundersen, Odd Erik, and Sigbjørn Kjensmo. 2018. “State of the Art: Reproducibility in Artificial Intelligence”. Proceedings of the AAAI Conference on Artificial Intelligence 32 (1).\nGundersen, Odd Erik, Yolanda Gil, and David W. Aha. “On Reproducible AI: Towards Reproducible Research, Open Science, and Digital Scholarship in AI Publications.” AI Magazine 39, no. 3 (September 28, 2018): 56–68.\n“How the AI Community Can Get Serious about Reproducibility.” Accessed September 18, 2024.\nAbid, Areeba. “Addressing ML’s Reproducibility Crisis.” Medium, January 7, 2021.\nPyTorch. “Towards Reproducible Research with PyTorch Hub.” Accessed September 18, 2024.\nStojnic, Robert. “ML Code Completeness Checklist.” PapersWithCode (blog), April 8, 2020.\nAkalin, Altuna. “Scientific Data Analysis Pipelines and Reproducibility.” Medium, July 5, 2021.\nHashesh, Ahmed. “Version Control for ML Models: What It Is and How To Implement It.” neptune.ai, July 22, 2022.\nNCEAS Learning Hub\nDonaldson, M. and Mahon, M. 2019. LEGO® Metadata for Reproducibility game pack. Documentation. University of Glasgow.",
    "crumbs": [
      "<b>Day 4: Workflows and Foundation Models</b>",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Reproducibility</span>"
    ]
  }
]